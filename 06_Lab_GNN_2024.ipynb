{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b15f412bb5a74a779ed1d21930ad2c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_090831c5bc3344f0828132081b49f372",
              "IPY_MODEL_54a1852ba4ce4fcbb49911bcd67c1dbf",
              "IPY_MODEL_92e89c3693f743d48f0705b6a67d1342"
            ],
            "layout": "IPY_MODEL_dbb63c456f45406d90349400e3571a98"
          }
        },
        "090831c5bc3344f0828132081b49f372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b2508703f643fb9ec8a761f47c3f60",
            "placeholder": "​",
            "style": "IPY_MODEL_a4cd0459d09c4c1a9a875340121201b2",
            "value": "modules.json: 100%"
          }
        },
        "54a1852ba4ce4fcbb49911bcd67c1dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1851aca5a20c4d7aba247b386ebdec12",
            "max": 248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24f2dbba21854f41919028f54058c48f",
            "value": 248
          }
        },
        "92e89c3693f743d48f0705b6a67d1342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45695d68fa174e34b1cea00e5e1b97ab",
            "placeholder": "​",
            "style": "IPY_MODEL_6e104f04732d41478ea88c75bec251b8",
            "value": " 248/248 [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "dbb63c456f45406d90349400e3571a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02b2508703f643fb9ec8a761f47c3f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cd0459d09c4c1a9a875340121201b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1851aca5a20c4d7aba247b386ebdec12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f2dbba21854f41919028f54058c48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45695d68fa174e34b1cea00e5e1b97ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e104f04732d41478ea88c75bec251b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8ff57c6b89a4104b058ebb5114fb9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87a0db2bc05d4c178316a8adfb3f86ba",
              "IPY_MODEL_2aeeb1cd222c4f758fc2183f933490ac",
              "IPY_MODEL_29715dce7eaf4afdb1dc948e5bad1569"
            ],
            "layout": "IPY_MODEL_10fb5a19c80d4b09ad7b8b0d26ca3b41"
          }
        },
        "87a0db2bc05d4c178316a8adfb3f86ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83611b8f08ac4e0e8d39c4935969a223",
            "placeholder": "​",
            "style": "IPY_MODEL_b07f465a649b44f4978105fdc33f609d",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "2aeeb1cd222c4f758fc2183f933490ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06b8e63fe2940a194ad66780146c628",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf303a9f621146fea2f03a00ffd73c16",
            "value": 122
          }
        },
        "29715dce7eaf4afdb1dc948e5bad1569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c80acfe195499ea7854111b055a866",
            "placeholder": "​",
            "style": "IPY_MODEL_4eccce726e764fa9b463ad823a3ccf78",
            "value": " 122/122 [00:00&lt;00:00, 9.45kB/s]"
          }
        },
        "10fb5a19c80d4b09ad7b8b0d26ca3b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83611b8f08ac4e0e8d39c4935969a223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b07f465a649b44f4978105fdc33f609d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06b8e63fe2940a194ad66780146c628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf303a9f621146fea2f03a00ffd73c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0c80acfe195499ea7854111b055a866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eccce726e764fa9b463ad823a3ccf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddf3e229eca04eadaef0c58ae5f10a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_497a567aecf54da8b3825b16844f63e8",
              "IPY_MODEL_82f950cb3a424247883ec236648bd9d8",
              "IPY_MODEL_7228ef0a9ab2472bb7dc3b6da9ac4bee"
            ],
            "layout": "IPY_MODEL_1550a1610f014a258f42890a2aa51dd4"
          }
        },
        "497a567aecf54da8b3825b16844f63e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e801470eb3a045a28db99022910c7924",
            "placeholder": "​",
            "style": "IPY_MODEL_7f811c9a576d4c81939cd422667dde6f",
            "value": "README.md: 100%"
          }
        },
        "82f950cb3a424247883ec236648bd9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_450085b901754622ac06bb024cd00292",
            "max": 2186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7c7a577ba3144d8a01d610ee4dffbf0",
            "value": 2186
          }
        },
        "7228ef0a9ab2472bb7dc3b6da9ac4bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9bc6f6168847f783b5cd51d8103f3a",
            "placeholder": "​",
            "style": "IPY_MODEL_65cc639053f1426284de90d385c16799",
            "value": " 2.19k/2.19k [00:00&lt;00:00, 177kB/s]"
          }
        },
        "1550a1610f014a258f42890a2aa51dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e801470eb3a045a28db99022910c7924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f811c9a576d4c81939cd422667dde6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "450085b901754622ac06bb024cd00292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c7a577ba3144d8a01d610ee4dffbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de9bc6f6168847f783b5cd51d8103f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65cc639053f1426284de90d385c16799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "296631feff564837ba8e518cb107020e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a7a584c39f84accaf0c6946877225a6",
              "IPY_MODEL_594f714eb4c947098205b08b4221c1bb",
              "IPY_MODEL_9380f6f5cb8a43e4838fb2cf9b0cbeae"
            ],
            "layout": "IPY_MODEL_7c9849c28cf541cfaf75366ef7914724"
          }
        },
        "9a7a584c39f84accaf0c6946877225a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddefca047c9446db9a73797c6ad6552e",
            "placeholder": "​",
            "style": "IPY_MODEL_b22684e0102e4ec080b8b1ace7e3857b",
            "value": "(…)beddings/whitespacetokenizer_config.json: 100%"
          }
        },
        "594f714eb4c947098205b08b4221c1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_512f37cd6dc84966bc43a32fa761a5db",
            "max": 4605941,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b08389d240074913ac3019d2cf0a8fe9",
            "value": 4605941
          }
        },
        "9380f6f5cb8a43e4838fb2cf9b0cbeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e07c0a39745401daed7d175c775403a",
            "placeholder": "​",
            "style": "IPY_MODEL_aea54148ce694d5b9464fc17ab7c40ae",
            "value": " 4.61M/4.61M [00:01&lt;00:00, 3.88MB/s]"
          }
        },
        "7c9849c28cf541cfaf75366ef7914724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddefca047c9446db9a73797c6ad6552e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b22684e0102e4ec080b8b1ace7e3857b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "512f37cd6dc84966bc43a32fa761a5db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b08389d240074913ac3019d2cf0a8fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e07c0a39745401daed7d175c775403a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea54148ce694d5b9464fc17ab7c40ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24957b437c514f9fb21b1327b4e682c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_940b1be26ef4405e9b57b2e649c98523",
              "IPY_MODEL_5bddd78ab45f4376a20817b8364db2d1",
              "IPY_MODEL_b6a75a6865dc45f2b0bfdc6c767071ae"
            ],
            "layout": "IPY_MODEL_dc3b4cba81534eb4b85c08ecd16d2955"
          }
        },
        "940b1be26ef4405e9b57b2e649c98523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3200f1a0b0b4f049c66615a19bebb62",
            "placeholder": "​",
            "style": "IPY_MODEL_ce9570e751744b65bd637abebac6e1b9",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "5bddd78ab45f4376a20817b8364db2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43aecf30ee1479a869fa0528bcd3bab",
            "max": 480002027,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b156096ecef400d83837adacfb31c9d",
            "value": 480002027
          }
        },
        "b6a75a6865dc45f2b0bfdc6c767071ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f06ec5e4e07471b8a08ea0aab0ad54f",
            "placeholder": "​",
            "style": "IPY_MODEL_217c38140a7245aaa18a17c99e047f6f",
            "value": " 480M/480M [00:02&lt;00:00, 231MB/s]"
          }
        },
        "dc3b4cba81534eb4b85c08ecd16d2955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3200f1a0b0b4f049c66615a19bebb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9570e751744b65bd637abebac6e1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d43aecf30ee1479a869fa0528bcd3bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b156096ecef400d83837adacfb31c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f06ec5e4e07471b8a08ea0aab0ad54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217c38140a7245aaa18a17c99e047f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7215c77b685d4a2a8fc4aa8605688a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d49ad836d44f415d90e43329314ec792",
              "IPY_MODEL_c8bf5ba09eb747cd87450972fcd87c19",
              "IPY_MODEL_1b2d625b3b15446d91aa89e19fb152d4"
            ],
            "layout": "IPY_MODEL_275764a90b39455b86ea2c58be96e805"
          }
        },
        "d49ad836d44f415d90e43329314ec792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0b5d9edd5f4b29b049170c51c58b90",
            "placeholder": "​",
            "style": "IPY_MODEL_734a7d20f8ff4e50bcf37330f4dea562",
            "value": "(…)WordEmbeddings/wordembedding_config.json: 100%"
          }
        },
        "c8bf5ba09eb747cd87450972fcd87c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe58f3a3c3174775ad30710790c28254",
            "max": 164,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d5f40e3212045fd8409133499af9044",
            "value": 164
          }
        },
        "1b2d625b3b15446d91aa89e19fb152d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ae03480d87640b9b175b40ffbf6f6fc",
            "placeholder": "​",
            "style": "IPY_MODEL_8c614097e7554bfea2b9abcf1ee76879",
            "value": " 164/164 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "275764a90b39455b86ea2c58be96e805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0b5d9edd5f4b29b049170c51c58b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734a7d20f8ff4e50bcf37330f4dea562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe58f3a3c3174775ad30710790c28254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5f40e3212045fd8409133499af9044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ae03480d87640b9b175b40ffbf6f6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c614097e7554bfea2b9abcf1ee76879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df347e2e5168428e99072ac8b4d0d6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6105a251a0a3432f8e3add9212d357a6",
              "IPY_MODEL_511f350105f04e54af22166ca236a5e2",
              "IPY_MODEL_b40fd9d18cdd419ca07d04c1f2e4c880"
            ],
            "layout": "IPY_MODEL_c9ca7d20364c48819a75dcc29ad5e8a2"
          }
        },
        "6105a251a0a3432f8e3add9212d357a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90fbbf0cdb2949e08a961ad9e419e818",
            "placeholder": "​",
            "style": "IPY_MODEL_1057ac464c1d4ad381e7b2f62d5e2444",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "511f350105f04e54af22166ca236a5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9206ad39c67e46a7bcc061aa8083bc07",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d98c1fb998d648a5850e6bd757f23e1e",
            "value": 190
          }
        },
        "b40fd9d18cdd419ca07d04c1f2e4c880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c126bf7a09ce4ffeaee6c892b7ca373c",
            "placeholder": "​",
            "style": "IPY_MODEL_b5ed07bee73c445e8e018c7710cdeaf6",
            "value": " 190/190 [00:00&lt;00:00, 6.80kB/s]"
          }
        },
        "c9ca7d20364c48819a75dcc29ad5e8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90fbbf0cdb2949e08a961ad9e419e818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1057ac464c1d4ad381e7b2f62d5e2444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9206ad39c67e46a7bcc061aa8083bc07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98c1fb998d648a5850e6bd757f23e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c126bf7a09ce4ffeaee6c892b7ca373c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ed07bee73c445e8e018c7710cdeaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "321c9fbff141435eb87ccd3fb2305cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5579f7b11878432892c55df3437f76fa",
              "IPY_MODEL_610a34df00db44cab1dbbb5badb74b37",
              "IPY_MODEL_13c51325e89c4fe08e1d4b9771773c37",
              "IPY_MODEL_d14faaf4fe274d8fa6308f9c6424054f"
            ],
            "layout": "IPY_MODEL_f9002c7ac97549a59823a4f24786271b"
          }
        },
        "5579f7b11878432892c55df3437f76fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f831ebb8d76246c38728642797f2b41c",
              "IPY_MODEL_96322ead77754aa48f08bc0d88321850",
              "IPY_MODEL_b1ae35c3e8334e5c925c0a93aef1a7df",
              "IPY_MODEL_3240bd354a774ca49f2ccf7a258c6b19",
              "IPY_MODEL_899a49b56ec147b3b69fca2423cfe01a"
            ],
            "layout": "IPY_MODEL_db3fb23c3962479784f6409cfe79841d"
          }
        },
        "610a34df00db44cab1dbbb5badb74b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3d8fc3a805a4068a12eb3580b9871ba",
              "IPY_MODEL_beea61d5ed244b6da8caf42994fdb4d0",
              "IPY_MODEL_66ddefea6eda4f8e86152e167cf3ac5f",
              "IPY_MODEL_920d2e2edb9742b59d6b76957756a5b6",
              "IPY_MODEL_abae3e36d30f483eabdd8087856fb6f2",
              "IPY_MODEL_1bd700647b754898b52dcfe91374a5c2",
              "IPY_MODEL_ec160d5025e54496ad6a3c00bc16e32a"
            ],
            "layout": "IPY_MODEL_beca1ae0e2cb43ada7d060b259ab7168"
          }
        },
        "13c51325e89c4fe08e1d4b9771773c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aac2b35531104094b796aec055729f66",
              "IPY_MODEL_702494a910814963b4ad2b2f9bae4475",
              "IPY_MODEL_9f0e5614942f4703b2bcafcd228bc9de",
              "IPY_MODEL_9af7f8520ebf414db174eb9066a30f9d",
              "IPY_MODEL_2c67070ff4d546d48a1a76cf1c102248",
              "IPY_MODEL_2f13511fd85f4694b09cec67cadd0730",
              "IPY_MODEL_d40d11e88df94f13959885f69cc2f369"
            ],
            "layout": "IPY_MODEL_ffc1282930d642e5a3b40f4286a38faf"
          }
        },
        "d14faaf4fe274d8fa6308f9c6424054f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "reset-button"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Reset to Default",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a1f1b675ea4445cb8acd71f5b9e0578c",
            "style": "IPY_MODEL_fcdd8f612d104d74a51d38bed3589760",
            "tooltip": ""
          }
        },
        "f9002c7ac97549a59823a4f24786271b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f831ebb8d76246c38728642797f2b41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25d4d5f1ff924b2382f85f5e8da69d9c",
            "placeholder": "​",
            "style": "IPY_MODEL_643672af358747419810383eb2146e6a",
            "value": "<b style='font-size:16px;'>Architecture</b>"
          }
        },
        "96322ead77754aa48f08bc0d88321850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Number of Layers:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9ab257364afe49059f05e4edb8e40e58",
            "max": 5,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_cb2e7b6a4bae4ebfa699369f641c7895",
            "value": 2
          }
        },
        "b1ae35c3e8334e5c925c0a93aef1a7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Embedding Dimensions (Channels):",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_055c4c3015ee41caa1c728256ece4c73",
            "max": 512,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_644eb319d15b4b7e9668bb099fd0f43f",
            "value": 128
          }
        },
        "3240bd354a774ca49f2ccf7a258c6b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "sum",
              "mean",
              "max"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Aggregation Strategy for Neighbor Messages:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_5207a6c714fa4c8fb2c2366734cec1bf",
            "style": "IPY_MODEL_c7654909bcec4e37b35830428ecf80ac"
          }
        },
        "899a49b56ec147b3b69fca2423cfe01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "batch_norm",
              "layer_norm",
              "none"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Prediction Head Normalization:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_035985ad328d40b89aa846e1db35f280",
            "style": "IPY_MODEL_6fbd709d6dcc449385417f8dce72ef8a"
          }
        },
        "db3fb23c3962479784f6409cfe79841d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "solid 1px black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "10px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "10px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d8fc3a805a4068a12eb3580b9871ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92e3c0ba76047e4b08576a8d565f4b2",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b6a92dc7d94b3ea4f7c66b67d7d5d2",
            "value": "<b style='font-size:16px;'>Data Loading</b>"
          }
        },
        "beea61d5ed244b6da8caf42994fdb4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Time Attribute Name for Temporal Neighbor Sampling:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d1274fbe6492467db27a4e0d6b4340f7",
            "placeholder": "​",
            "style": "IPY_MODEL_54e50409cad14720b6caeb618cee133f",
            "value": "time"
          }
        },
        "66ddefea6eda4f8e86152e167cf3ac5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "uniform",
              "recent",
              "future"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Temporal Neighbor Sampling Strategy:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_e6ddd3b1ed084aaea32673bc9bfd3d5c",
            "style": "IPY_MODEL_a4f6a905919349e99ea85a79ae5040e1"
          }
        },
        "920d2e2edb9742b59d6b76957756a5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Batch Size:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c5d8cf0b09334bcc8213484dec052951",
            "max": 1024,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_57d122e3080a4e99ab5ded56f098be21",
            "value": 512
          }
        },
        "abae3e36d30f483eabdd8087856fb6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Only Batches where User Nodes have the Same Seed Time (No Shuffling)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2e79e0a45ebc4a15a62374f23a75a7be",
            "style": "IPY_MODEL_8580799778774c9bbe5d88d5b7e8986f",
            "value": true
          }
        },
        "1bd700647b754898b52dcfe91374a5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Max Number of Sampled Neighbors (100% Layer 1, Progressive 50% for Layers >1):",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7341eecd14c14dacb5b973925f508db4",
            "max": 256,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_c3471ea9178344e29a4bea7e204eb06b",
            "value": 128
          }
        },
        "ec160d5025e54496ad6a3c00bc16e32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Number of Workers for Parallel Data Loading:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e3f366772a0b4ff8912872be24bb0b5b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_61c498cbadae43da8e58807ceb8486a9",
            "value": 0
          }
        },
        "beca1ae0e2cb43ada7d060b259ab7168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "solid 1px black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "10px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "10px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac2b35531104094b796aec055729f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6736a1b988a40f2b35eff080a6a16e1",
            "placeholder": "​",
            "style": "IPY_MODEL_c026d194d7f649e4982885adc04a341f",
            "value": "<b style='font-size:16px;'>Training</b>"
          }
        },
        "702494a910814963b4ad2b2f9bae4475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Use Shallow Embeddings for Article Nodes",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2294cce4c046466a87dd38543c5ae340",
            "style": "IPY_MODEL_a1974e669c2c480f8222f74dddc1f3dd",
            "value": true
          }
        },
        "9f0e5614942f4703b2bcafcd228bc9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "Learning Rate:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_56d286fd51574b32972228f18c1ef49a",
            "max": 0.001,
            "min": 0.0001,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".4f",
            "step": 0.0001,
            "style": "IPY_MODEL_664c7b15b77b4bc7bcc62e4c330d8769",
            "value": 0.001
          }
        },
        "9af7f8520ebf414db174eb9066a30f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Number of Epochs:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c6ab6c777b7c4d12a73a2f227918c08b",
            "max": 20,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_9eb61d86d7df46678e9b1c091cde1911",
            "value": 20
          }
        },
        "2c67070ff4d546d48a1a76cf1c102248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Max Steps per Epoch:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_479255ddd65e4c74a98bb83c90e79ddc",
            "max": 5000,
            "min": 100,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 100,
            "style": "IPY_MODEL_cabafabec36a4bd0ae075b89dbb844c1",
            "value": 2000
          }
        },
        "2f13511fd85f4694b09cec67cadd0730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Evaluation Interval:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_828af1fe6518409eb8a06bfa44d8ac5d",
            "max": 10,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_d70646c548c842ca9f568b49e654abab",
            "value": 1
          }
        },
        "d40d11e88df94f13959885f69cc2f369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "link_prediction_map",
              "link_prediction_recall",
              "link_prediction_precision"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Tuning Metric for Best-Eval Checkpoint Saving:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_4b6b79bbcfbb4fdb934476f9b01522e6",
            "style": "IPY_MODEL_66c499e3dac843c49bd3599cda0975ba"
          }
        },
        "ffc1282930d642e5a3b40f4286a38faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "solid 1px black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "10px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "10px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f1b675ea4445cb8acd71f5b9e0578c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "40px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "200px"
          }
        },
        "fcdd8f612d104d74a51d38bed3589760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "25d4d5f1ff924b2382f85f5e8da69d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643672af358747419810383eb2146e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab257364afe49059f05e4edb8e40e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "cb2e7b6a4bae4ebfa699369f641c7895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "055c4c3015ee41caa1c728256ece4c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "644eb319d15b4b7e9668bb099fd0f43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "5207a6c714fa4c8fb2c2366734cec1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "c7654909bcec4e37b35830428ecf80ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px"
          }
        },
        "035985ad328d40b89aa846e1db35f280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "6fbd709d6dcc449385417f8dce72ef8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px"
          }
        },
        "b92e3c0ba76047e4b08576a8d565f4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b6a92dc7d94b3ea4f7c66b67d7d5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1274fbe6492467db27a4e0d6b4340f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "54e50409cad14720b6caeb618cee133f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px"
          }
        },
        "e6ddd3b1ed084aaea32673bc9bfd3d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "a4f6a905919349e99ea85a79ae5040e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px"
          }
        },
        "c5d8cf0b09334bcc8213484dec052951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "57d122e3080a4e99ab5ded56f098be21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "2e79e0a45ebc4a15a62374f23a75a7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "8580799778774c9bbe5d88d5b7e8986f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "300px"
          }
        },
        "7341eecd14c14dacb5b973925f508db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "c3471ea9178344e29a4bea7e204eb06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "e3f366772a0b4ff8912872be24bb0b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "61c498cbadae43da8e58807ceb8486a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "f6736a1b988a40f2b35eff080a6a16e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c026d194d7f649e4982885adc04a341f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2294cce4c046466a87dd38543c5ae340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "a1974e669c2c480f8222f74dddc1f3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px"
          }
        },
        "56d286fd51574b32972228f18c1ef49a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "664c7b15b77b4bc7bcc62e4c330d8769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "c6ab6c777b7c4d12a73a2f227918c08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "9eb61d86d7df46678e9b1c091cde1911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "479255ddd65e4c74a98bb83c90e79ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "cabafabec36a4bd0ae075b89dbb844c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "828af1fe6518409eb8a06bfa44d8ac5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "d70646c548c842ca9f568b49e654abab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px",
            "handle_color": null
          }
        },
        "4b6b79bbcfbb4fdb934476f9b01522e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "66c499e3dac843c49bd3599cda0975ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "500px"
          }
        },
        "3226d8f35bb945fb82e093914b381b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5e6559ec3014ccead080680bb220b73",
              "IPY_MODEL_2eb1c6c2fa6848838222a0cc0556d2a9",
              "IPY_MODEL_53496ed554e4430c8491761243d9d2cf",
              "IPY_MODEL_0e1853ba0228428aa81580e2a600f1c6",
              "IPY_MODEL_f975564e46b74e29a435ddf995582300"
            ],
            "layout": "IPY_MODEL_a99a459d782548f6a978660aeb12d1d0"
          }
        },
        "f5e6559ec3014ccead080680bb220b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "TRAIN_SIZE:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_301a881a1e58495abeb07d00fcd3c436",
            "placeholder": "(default 5000)",
            "style": "IPY_MODEL_2b3ac255da62473fb1d4aea5713182e3",
            "value": "1000"
          }
        },
        "2eb1c6c2fa6848838222a0cc0556d2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "VAL_SIZE:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_21328bee1f4a495dbf359ec338564656",
            "placeholder": "(default 1000)",
            "style": "IPY_MODEL_13de11a09403475c9f170169d756bfe3",
            "value": "1000"
          }
        },
        "53496ed554e4430c8491761243d9d2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "TEST_SIZE:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_22d7c941265c40449ba307de1ba2cb10",
            "placeholder": "(default 1000)",
            "style": "IPY_MODEL_76f97d217a8f4f438f4c3f50afd8878e",
            "value": "1000"
          }
        },
        "0e1853ba0228428aa81580e2a600f1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b484d21d427d4cf18face0eb4240ebd9",
            "style": "IPY_MODEL_82aab9b08e5846ec92afb2e2a850c4f5",
            "tooltip": ""
          }
        },
        "f975564e46b74e29a435ddf995582300": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9c37798c2a2c49319831f435bdbcde8b",
            "msg_id": "",
            "outputs": []
          }
        },
        "a99a459d782548f6a978660aeb12d1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301a881a1e58495abeb07d00fcd3c436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "400px"
          }
        },
        "2b3ac255da62473fb1d4aea5713182e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21328bee1f4a495dbf359ec338564656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "400px"
          }
        },
        "13de11a09403475c9f170169d756bfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d7c941265c40449ba307de1ba2cb10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "400px"
          }
        },
        "76f97d217a8f4f438f4c3f50afd8878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b484d21d427d4cf18face0eb4240ebd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "150px"
          }
        },
        "82aab9b08e5846ec92afb2e2a850c4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9c37798c2a2c49319831f435bdbcde8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24969bc48b85454a839d2adfda63d433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "contextgnn",
              "idgnn"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Select:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_a7d72d5963a642d588581328bad5b63b",
            "style": "IPY_MODEL_8c2fdbcfba5341e780e5ba96ce7ace7f"
          }
        },
        "a7d72d5963a642d588581328bad5b63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c2fdbcfba5341e780e5ba96ce7ace7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab on Graph Neural Networks\n",
        "\n",
        "Teacher: Prof. Gianluca Moro\n",
        "\n",
        "Teaching Assistant: Dr. Giacomo Frisoni\n",
        "\n",
        "Acknowledgments: Dr. Lorenzo Molfetta for baselines and resource-intensive server-side training.\n",
        "\n",
        "**Contact.** For any doubt, question, issue or help, you can always contact us at the following email addresses: {gianluca.moro, giacomo.frisoni}@unibo.it.\n",
        "\n",
        "**Keywords.** Graph Neural Networks, Graph Representation Learning, Relational Deep Learning."
      ],
      "metadata": {
        "id": "Dv5oxLrQ6Swp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📜 Outline\n",
        "\n",
        "Relational databases are the cornerstone of modern data management, forming the backbone of the digital economy. Their widespread adoption stems from their intuitive table-based structure, which simplifies data organization and maintenance, coupled with powerful query capabilities provided by languages like SQL. Given their ubiquity, relational databases serve as the foundation for AI systems across diverse domains such as e-commerce, social media, banking, healthcare, manufacturing, and open-source scientific research repositories. These databases naturally align with graph representations, where relationships between items in different tables are pivotal for advanced tasks like building recommender systems.\n",
        "\n",
        "We will delve into the cutting-edge field of **Relational Deep Learning**.\n",
        "Using a **real-world dataset from H&M**, a globally renowned fashion retailer, we will model their e-commerce relational database as a temporal heterogeneous graph. Leveraging this structured representation, we will train a state-of-the-art **Graph Neural Network to power product recommendations**.\n",
        "Through this hands-on exercise, we will witness how explicitly harnessing the relationships between customers, products, and transactions can achieve remarkable performance gains.\n",
        "Our approach will outperform even leading techniques such as **Large Language Models** and **Deep Tabular Models** like XGBoost and LightGBM."
      ],
      "metadata": {
        "id": "5LrZfxkN6kZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relational Deep Learning"
      ],
      "metadata": {
        "id": "Opw1kgZV64ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚙️ Install Dependencies ($<$ 1 min)"
      ],
      "metadata": {
        "id": "qhtqPRhM6yUz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv1QgHaB-hLW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install torch-geometric torch-sparse torch-scatter torch-cluster torch-spline-conv pyg-lib -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install relbench[full]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RELBENCH is a public benchmark for solving predictive tasks over relational databases with GNNs.\n",
        "\n",
        "First submitted on ArXiv on 29 July 2024 [[paper link](https://arxiv.org/abs/2407.20060)], it has been published by **Stanford University, Kumo.AI and the Max Planck Institute for Informatics** at **NeurIPS 2024**, Track on Datasets and Benchmarks.\n",
        "\n",
        "<img src=\"https://relbench.stanford.edu/img/logo.png\" alt=\"Stanford RelBench Logo\" width=\"400\">\n",
        "\n",
        "---\n",
        "\n",
        "RELBENCH enables training and evaluation of deep learning models on relational databases. RELBENCH supports framework agnostic data loading, task specification, standardized data splitting, standardized evaluation metrics, and a leaderboard for tracking progress.\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/a858a15c33d8aebde0cdae555260be83db968a4112816a1149a971fe367503f2/68747470733a2f2f72656c62656e63682e7374616e666f72642e6564752f696d672f72656c62656e63682d6669672e706e67\" alt=\"Stanford RelBench Pipeline\" width=\"750\">"
      ],
      "metadata": {
        "id": "_vOdMURe8CxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import relbench\n",
        "relbench.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dEotPIJ4_PQx",
        "outputId": "7c8529aa-d942-46f8-cf29-cd535d8609ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📂 Dataset"
      ],
      "metadata": {
        "id": "mZJU0LMr8ORV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RELBENCH contains **7 real-world datasets**, each with a *relational database* and a *set of realistic predictive tasks*.\n",
        "\n",
        "*   A **relational database** consists of a set of tables connected via primary-foreign key relationships. Each table has columns storing diverse information about each entity. Some tables also come with time columns, indicating the time at which the entity is created (e.g., transaction date).\n",
        "*   A **predictive task** is defined by a training table with columns for Entity ID, seed time, and target labels. The seed time indicates *at which time* the target is to be predicted, filtering out future data. Zooming out, tasks are grouped into **three task types**:\n",
        "  *   **Entity classification.** Predict binary labels of a given entity at a given seed time. Note that here only information from the single entity table is used.\n",
        "  *   **Entity regression.** Predict numerical labels of an entity at a given seed time.\n",
        "  *   **Link prediction.** Recommendation on pairs of entities. Predict a list of top-$K$ target entities given a source entity at a seed time. For this task, it is important to ensure a certain density of links in the training data in order for there to be sufficient predictive signal.\n",
        "\n"
      ],
      "metadata": {
        "id": "N3wxvtPw9slX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select a Dataset"
      ],
      "metadata": {
        "id": "KJusmJo3-MqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the databases currently available in RelBench:"
      ],
      "metadata": {
        "id": "-S3j7RX2_TBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.datasets import get_dataset_names\n",
        "\n",
        "get_dataset_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv2o-9ji_cpo",
        "outputId": "7868d8d2-0088-4845-8d6a-47da4496c6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rel-amazon',\n",
              " 'rel-avito',\n",
              " 'rel-event',\n",
              " 'rel-f1',\n",
              " 'rel-hm',\n",
              " 'rel-stack',\n",
              " 'rel-trial']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**rel-hm.** The H&M relational database hosts extensive customer and product data for online shopping experiences across its extensive network of brands and stores. This database includes detailed customer purchase histories and a rich set of metadata, encompassing everything from basic demographic information to extensive details about each product available.\n",
        "\n",
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1i9nxFYu7v26SeZPBlimX9ZVAgigXuZFC\" width=\"200\">"
      ],
      "metadata": {
        "id": "PdzGGYKH8_b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.datasets import get_dataset\n",
        "\n",
        "# Download the dataset from Stanford website and unzip it\n",
        "dataset = get_dataset(name=\"rel-hm\", download=True)"
      ],
      "metadata": {
        "id": "Ooi7KX-N_nFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e307278d-769d-4d8f-d350-da836361fe58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'rel-hm/db.zip' from 'https://relbench.stanford.edu/download/rel-hm/db.zip' to '/root/.cache/relbench'.\n",
            "100%|████████████████████████████████████████| 143M/143M [00:00<00:00, 124GB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-hm/db.zip' to '/root/.cache/relbench/rel-hm/.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JL3v24Zs_ONh",
        "outputId": "67c18abf-b78e-4dc8-8d20-300204b669c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have loaded the database, let's start poking around to see what's inside."
      ],
      "metadata": {
        "id": "N11dHVKjKxKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Temporal Splitting"
      ],
      "metadata": {
        "id": "mU3yyUCS-Z_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is split temporally, with models trained on rows up to `val_timestamp`, validated on the rows between `val_timestamp` and `test_timestamp`, and tested on the rows after `val_timestamp`.\n",
        "\n",
        "We must **avoid temporal leakage of information** during training and validation through temporal neighbor sampling."
      ],
      "metadata": {
        "id": "q1ScJHKZ-hEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.val_timestamp, dataset.test_timestamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8ircnWh-jUp",
        "outputId": "a812cee6-85d6-4280-87d5-4f8f8ef8b948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Timestamp('2020-09-07 00:00:00'), Timestamp('2020-09-14 00:00:00'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Information up to September 7, 2020 can be used for training.\n",
        "*   Information up to September 14, 2020 can be used for validation.\n",
        "*   Information after September 14, 2020 can be used for testing."
      ],
      "metadata": {
        "id": "ks5a6dgG-xhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relational Database"
      ],
      "metadata": {
        "id": "YcAKJghkL66r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load a Database"
      ],
      "metadata": {
        "id": "JsNxqG6PB7TX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check out the relational database itself..."
      ],
      "metadata": {
        "id": "kl-Ycf5oMC09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset object and cache it in memory\n",
        "db = dataset.get_db()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glea1y1NL9m1",
        "outputId": "2965dae9-1df1-4d6c-cc91-df9038db3b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Database object from /root/.cache/relbench/rel-hm/db...\n",
            "Done in 1.47 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This returns a RelBench `Database` object.\n",
        "\n",
        "By default, the rows with $\\text{timestamp} > \\text{test_timestamp}$ are excluded to prevent accidental test set leakage.\n",
        "\n",
        "The complete database can be loaded with `database.get_db(upto_test_timestamp=False)`."
      ],
      "metadata": {
        "id": "KWcVT3KrMLLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check Full Timespan"
      ],
      "metadata": {
        "id": "er881IliB9mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this we can double check the full timespan of the database:"
      ],
      "metadata": {
        "id": "CAeQ1TljCXRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db.min_timestamp, db.max_timestamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0wS-BkOCbt3",
        "outputId": "fb91e4ff-6923-4adf-bbaf-532727582ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Timestamp('2019-09-07 00:00:00'), Timestamp('2020-09-14 00:00:00'))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the `max_timestamp` is the same as `test_timestamp`."
      ],
      "metadata": {
        "id": "4qSeuttACsxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check Tables"
      ],
      "metadata": {
        "id": "VMgDH58uC1OH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the selected dataset, we have the following tables:"
      ],
      "metadata": {
        "id": "IDPBLSwcOfhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db.table_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoV-AL1WOwQy",
        "outputId": "8d2a446d-6293-459d-a5d9-e5cd6ee38e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['customer', 'transactions', 'article'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's 3 tables total! Let's look more closely at one of them."
      ],
      "metadata": {
        "id": "IE7dxKJMDWVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = db.table_dict[\"article\"]\n",
        "table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywkbxThdO8TM",
        "outputId": "c5464b18-c0ad-4ddc-9966-86c29f6c9fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Table(df=\n",
              "        article_id  product_code               prod_name  product_type_no  \\\n",
              "0                0        108775               Strap top              253   \n",
              "1                1        108775               Strap top              253   \n",
              "2                2        108775           Strap top (1)              253   \n",
              "3                3        110065       OP T-shirt (Idro)              306   \n",
              "4                4        110065       OP T-shirt (Idro)              306   \n",
              "...            ...           ...                     ...              ...   \n",
              "105537      105537        953450  5pk regular Placement1              302   \n",
              "105538      105538        953763       SPORT Malaga tank              253   \n",
              "105539      105539        956217         Cartwheel dress              265   \n",
              "105540      105540        957375        CLAIRE HAIR CLAW               72   \n",
              "105541      105541        959461            Lounge dress              265   \n",
              "\n",
              "       product_type_name  product_group_name  graphical_appearance_no  \\\n",
              "0               Vest top  Garment Upper body                  1010016   \n",
              "1               Vest top  Garment Upper body                  1010016   \n",
              "2               Vest top  Garment Upper body                  1010017   \n",
              "3                    Bra           Underwear                  1010016   \n",
              "4                    Bra           Underwear                  1010016   \n",
              "...                  ...                 ...                      ...   \n",
              "105537             Socks      Socks & Tights                  1010014   \n",
              "105538          Vest top  Garment Upper body                  1010016   \n",
              "105539             Dress   Garment Full body                  1010016   \n",
              "105540         Hair clip         Accessories                  1010016   \n",
              "105541             Dress   Garment Full body                  1010016   \n",
              "\n",
              "       graphical_appearance_name  colour_group_code colour_group_name  ...  \\\n",
              "0                          Solid                  9             Black  ...   \n",
              "1                          Solid                 10             White  ...   \n",
              "2                         Stripe                 11         Off White  ...   \n",
              "3                          Solid                  9             Black  ...   \n",
              "4                          Solid                 10             White  ...   \n",
              "...                          ...                ...               ...  ...   \n",
              "105537           Placement print                  9             Black  ...   \n",
              "105538                     Solid                  9             Black  ...   \n",
              "105539                     Solid                  9             Black  ...   \n",
              "105540                     Solid                  9             Black  ...   \n",
              "105541                     Solid                 11         Off White  ...   \n",
              "\n",
              "          department_name index_code        index_name index_group_no  \\\n",
              "0            Jersey Basic          A        Ladieswear              1   \n",
              "1            Jersey Basic          A        Ladieswear              1   \n",
              "2            Jersey Basic          A        Ladieswear              1   \n",
              "3          Clean Lingerie          B  Lingeries/Tights              1   \n",
              "4          Clean Lingerie          B  Lingeries/Tights              1   \n",
              "...                   ...        ...               ...            ...   \n",
              "105537          Socks Bin          F          Menswear              3   \n",
              "105538             Jersey          A        Ladieswear              1   \n",
              "105539             Jersey          A        Ladieswear              1   \n",
              "105540  Small Accessories          D           Divided              2   \n",
              "105541             Jersey          A        Ladieswear              1   \n",
              "\n",
              "        index_group_name section_no            section_name garment_group_no  \\\n",
              "0             Ladieswear         16  Womens Everyday Basics             1002   \n",
              "1             Ladieswear         16  Womens Everyday Basics             1002   \n",
              "2             Ladieswear         16  Womens Everyday Basics             1002   \n",
              "3             Ladieswear         61         Womens Lingerie             1017   \n",
              "4             Ladieswear         61         Womens Lingerie             1017   \n",
              "...                  ...        ...                     ...              ...   \n",
              "105537          Menswear         26           Men Underwear             1021   \n",
              "105538        Ladieswear          2                    H&M+             1005   \n",
              "105539        Ladieswear         18            Womens Trend             1005   \n",
              "105540           Divided         52     Divided Accessories             1019   \n",
              "105541        Ladieswear         18            Womens Trend             1005   \n",
              "\n",
              "        garment_group_name                                        detail_desc  \n",
              "0             Jersey Basic            Jersey top with narrow shoulder straps.  \n",
              "1             Jersey Basic            Jersey top with narrow shoulder straps.  \n",
              "2             Jersey Basic            Jersey top with narrow shoulder straps.  \n",
              "3        Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
              "4        Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
              "...                    ...                                                ...  \n",
              "105537    Socks and Tights  Socks in a fine-knit cotton blend with a small...  \n",
              "105538        Jersey Fancy  Loose-fitting sports vest top in ribbed fast-d...  \n",
              "105539        Jersey Fancy  Short, A-line dress in jersey with a round nec...  \n",
              "105540         Accessories                           Large plastic hair claw.  \n",
              "105541        Jersey Fancy  Calf-length dress in ribbed jersey made from a...  \n",
              "\n",
              "[105542 rows x 25 columns],\n",
              "  fkey_col_to_pkey_table={},\n",
              "  pkey_col=article_id,\n",
              "  time_col=None)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `article` table stores information on all products available in the H&M e-commerce. Note that the table comes with multiple bits of information:\n",
        "\n",
        "*   The table itself, `table.df` which is a Pandas DataFrame.\n",
        "*   The primary key column, `table.pkey_col`, which indicates that the `article_id` column holds the primary key for this particular table in the database.\n",
        "*   The primary time column, `table.time_col`, which, if the entity is an event, records the time an event happened. In the case of articles, they are non-temporal entities, so `table.time_col=None`.\n",
        "*   The other tables pointed by the foreign keys, if any, `table.fkey_col_to_pkey_table`. Again, in the case of articles, this is not applicable.\n",
        "\n"
      ],
      "metadata": {
        "id": "R9hbcTrXDdgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = db.table_dict[\"customer\"]\n",
        "table.df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "aNIEThXdPV67",
        "outputId": "272bc103-6b48-42af-a7f5-dd28fc39683b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         customer_id   FN  Active club_member_status fashion_news_frequency  \\\n",
              "0                  0  NaN     NaN             ACTIVE                   NONE   \n",
              "1                  1  NaN     NaN             ACTIVE                   NONE   \n",
              "2                  2  NaN     NaN             ACTIVE                   NONE   \n",
              "3                  3  NaN     NaN             ACTIVE                   NONE   \n",
              "4                  4  1.0     1.0             ACTIVE              Regularly   \n",
              "...              ...  ...     ...                ...                    ...   \n",
              "1371975      1371975  NaN     NaN             ACTIVE                   NONE   \n",
              "1371976      1371976  NaN     NaN             ACTIVE                   NONE   \n",
              "1371977      1371977  1.0     1.0             ACTIVE              Regularly   \n",
              "1371978      1371978  1.0     1.0             ACTIVE              Regularly   \n",
              "1371979      1371979  NaN     NaN         PRE-CREATE                   NONE   \n",
              "\n",
              "          age                                        postal_code  \n",
              "0        49.0  52043ee2162cf5aa7ee79974281641c6f11a68d276429a...  \n",
              "1        25.0  2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...  \n",
              "2        24.0  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...  \n",
              "3        54.0  5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...  \n",
              "4        52.0  25fa5ddee9aac01b35208d01736e57942317d756b32ddd...  \n",
              "...       ...                                                ...  \n",
              "1371975  24.0  7aa399f7e669990daba2d92c577b52237380662f36480b...  \n",
              "1371976  21.0  3f47f1279beb72215f4de557d950e0bfa73789d24acb5e...  \n",
              "1371977  21.0  4563fc79215672cd6a863f2b4bf56b8f898f2d96ed590e...  \n",
              "1371978  18.0  8892c18e9bc3dca6aa4000cb8094fc4b51ee8db2ed14d7...  \n",
              "1371979  65.0  0a1a03306fb2f62164c2a439b38c0caa64b40deaae8687...  \n",
              "\n",
              "[1371980 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78e5ce88-9275-4e42-bb60-a4e67f23eabd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>FN</th>\n",
              "      <th>Active</th>\n",
              "      <th>club_member_status</th>\n",
              "      <th>fashion_news_frequency</th>\n",
              "      <th>age</th>\n",
              "      <th>postal_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>49.0</td>\n",
              "      <td>52043ee2162cf5aa7ee79974281641c6f11a68d276429a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>64f17e6a330a85798e4998f62d0930d14db8db1c054af6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>54.0</td>\n",
              "      <td>5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>Regularly</td>\n",
              "      <td>52.0</td>\n",
              "      <td>25fa5ddee9aac01b35208d01736e57942317d756b32ddd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371975</th>\n",
              "      <td>1371975</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7aa399f7e669990daba2d92c577b52237380662f36480b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371976</th>\n",
              "      <td>1371976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3f47f1279beb72215f4de557d950e0bfa73789d24acb5e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371977</th>\n",
              "      <td>1371977</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>Regularly</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4563fc79215672cd6a863f2b4bf56b8f898f2d96ed590e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371978</th>\n",
              "      <td>1371978</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>Regularly</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8892c18e9bc3dca6aa4000cb8094fc4b51ee8db2ed14d7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371979</th>\n",
              "      <td>1371979</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PRE-CREATE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0a1a03306fb2f62164c2a439b38c0caa64b40deaae8687...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1371980 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78e5ce88-9275-4e42-bb60-a4e67f23eabd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78e5ce88-9275-4e42-bb60-a4e67f23eabd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78e5ce88-9275-4e42-bb60-a4e67f23eabd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-277d8fdd-d0c2-457f-95f6-ba403eafc443\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-277d8fdd-d0c2-457f-95f6-ba403eafc443')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-277d8fdd-d0c2-457f-95f6-ba403eafc443 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = db.table_dict[\"transactions\"]\n",
        "table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7SSSBL4h7rG",
        "outputId": "7e94695a-26ae-4659-8752-c49499cb1ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Table(df=\n",
              "              t_dat  customer_id  article_id     price  sales_channel_id\n",
              "0        2019-09-07          155       51985  0.010153                 1\n",
              "1        2019-09-07          155       51985  0.010153                 1\n",
              "2        2019-09-07          155       83127  0.042356                 1\n",
              "3        2019-09-07          155        6066  0.005068                 1\n",
              "4        2019-09-07          155       78525  0.033881                 1\n",
              "...             ...          ...         ...       ...               ...\n",
              "15187282 2020-09-14      1371926       93801  0.025407                 1\n",
              "15187283 2020-09-14      1371926       17155  0.033881                 1\n",
              "15187284 2020-09-14      1371926       65802  0.030492                 1\n",
              "15187285 2020-09-14      1371926       85883  0.016932                 1\n",
              "15187286 2020-09-14      1371926      104763  0.042356                 1\n",
              "\n",
              "[15187287 rows x 5 columns],\n",
              "  fkey_col_to_pkey_table={'customer_id': 'customer', 'article_id': 'article'},\n",
              "  pkey_col=None,\n",
              "  time_col=t_dat)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Database schema:**\n",
        "\n",
        "<img src=\"https://relbench.stanford.edu/img/rel-hm.png\" width=\"800px\">\n"
      ],
      "metadata": {
        "id": "FOSU0iliSej4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load a Task"
      ],
      "metadata": {
        "id": "9HMDdxiYRPLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each RELBENCH dataset comes with multiple pre-defined predictive tasks. For any given RELBENCH dataset, you can check all the associated tasks with:"
      ],
      "metadata": {
        "id": "9s8zMUyCRiZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.tasks import get_task_names, get_task\n",
        "\n",
        "get_task_names(\"rel-hm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V56ZIzsrQPNR",
        "outputId": "25c0f2e6-a117-481a-fbd4-d593cb868989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user-item-purchase', 'user-churn', 'item-sales']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will work with `user-item-purchase`, where the task is: **\"Predict the list of articles each customer will purchase in the next seven days\"** [[Source](https://relbench.stanford.edu/datasets/rel-hm/)]. The task itself is instantiated by calling:"
      ],
      "metadata": {
        "id": "aj8THBwaRqyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = get_task(\"rel-hm\", \"user-item-purchase\", download=True)\n",
        "task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvEHm2n0QZKN",
        "outputId": "e06989e2-984c-4fd5-89df-25c923481fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'rel-hm/tasks/user-item-purchase.zip' from 'https://relbench.stanford.edu/download/rel-hm/tasks/user-item-purchase.zip' to '/root/.cache/relbench'.\n",
            "100%|█████████████████████████████████████| 46.9M/46.9M [00:00<00:00, 44.9GB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-hm/tasks/user-item-purchase.zip' to '/root/.cache/relbench/rel-hm/tasks/.'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UserItemPurchaseTask(dataset=HMDataset())"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.base import TaskType\n",
        "assert task.task_type == TaskType.LINK_PREDICTION"
      ],
      "metadata": {
        "id": "KcykCrmMslPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we load the train / val / test labels."
      ],
      "metadata": {
        "id": "2Oj1vyCyTmoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")"
      ],
      "metadata": {
        "id": "_mrCe859QfK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each link prediction task table contains **triples** `(entity_1_id, entity_2_id, timestamp)` indicating:\n",
        "\n",
        "*   The target entity label (`entity_2_id`) associated to `entity_1_id`\n",
        "*   `timestamp`, the timepoint at which the prediction is made\n",
        "\n",
        "The task table also indicates which database table(s) it is \"attached\" to --- in this case the *customer* and *article* tables."
      ],
      "metadata": {
        "id": "TnWK7heWTxmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGAjVqyRQu1e",
        "outputId": "8d8adf68-a3c7-4206-e2de-b0003779d202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Table(df=\n",
              "         timestamp  customer_id  \\\n",
              "0       2019-12-09       149853   \n",
              "1       2019-12-09       435491   \n",
              "2       2019-12-09       600889   \n",
              "3       2019-12-09      1271535   \n",
              "4       2019-12-09       124560   \n",
              "...            ...          ...   \n",
              "3878446 2020-04-20       408061   \n",
              "3878447 2020-04-20      1138840   \n",
              "3878448 2020-03-30       140490   \n",
              "3878449 2020-03-30      1094930   \n",
              "3878450 2020-03-30      1217756   \n",
              "\n",
              "                                                article_id  \n",
              "0                                           [11667, 83069]  \n",
              "1        [8061, 56842, 70123, 83386, 14038, 70122, 3315...  \n",
              "2                                           [25756, 72271]  \n",
              "3         [78428, 38992, 91389, 86016, 2556, 72566, 10378]  \n",
              "4                                                  [80745]  \n",
              "...                                                    ...  \n",
              "3878446                                            [82437]  \n",
              "3878447                                           [101299]  \n",
              "3878448                                            [53385]  \n",
              "3878449                                            [53822]  \n",
              "3878450                                            [80651]  \n",
              "\n",
              "[3878451 rows x 3 columns],\n",
              "  fkey_col_to_pkey_table={'customer_id': 'customer', 'article_id': 'article'},\n",
              "  pkey_col=None,\n",
              "  time_col=timestamp)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Sampling"
      ],
      "metadata": {
        "id": "ZpGZnr4OabGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data sampling is not required for the original RELBENCH GNNs we will use in the first part. Everything can be runned on Google Colab.\n",
        "\n",
        "Anyway, it can be necessary with larger models or fewer hardware resources.\n",
        "\n",
        "Official sampling code from ContextGNN [[Source](https://github.com/snap-stanford/relbench/blob/6bcb12a94b163c52e01cc272dfd4817cd13eff69/examples/lightgbm_link.py#L113)]."
      ],
      "metadata": {
        "id": "5h9iobZA1_1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Subsample train data if SAMPLE_SIZE is less than the current size\n",
        "# TRAIN_SAMPLE_SIZE = 10000\n",
        "\n",
        "# if TRAIN_SAMPLE_SIZE > 0 and TRAIN_SAMPLE_SIZE < len(train_table):\n",
        "#     sampled_idx = np.random.permutation(len(train_table))[:TRAIN_SAMPLE_SIZE]\n",
        "#     train_table.df = train_table.df.iloc[sampled_idx].reset_index(drop=True)  # Reset indices\n",
        "\n",
        "# VAL_SAMPLE_SIZE = 1000\n",
        "# if VAL_SAMPLE_SIZE > 0 and VAL_SAMPLE_SIZE < len(val_table):\n",
        "#     sampled_idx = np.random.permutation(len(val_table))[:VAL_SAMPLE_SIZE]\n",
        "#     val_table.df = val_table.df.iloc[sampled_idx].reset_index(drop=True)  # Reset indices\n",
        "\n",
        "# TEST_SAMPLE_SIZE = 1000\n",
        "# if TEST_SAMPLE_SIZE > 0 and TEST_SAMPLE_SIZE < len(test_table):\n",
        "#     sampled_idx = np.random.permutation(len(test_table))[:TEST_SAMPLE_SIZE]\n",
        "#     test_table.df = test_table.df.iloc[sampled_idx].reset_index(drop=True)  # Reset indices"
      ],
      "metadata": {
        "id": "2Hnp9FBvagRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧑‍🏫 GNNs for Recommender Systems"
      ],
      "metadata": {
        "id": "3Blsk3SdPsVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preliminary of Recommendation"
      ],
      "metadata": {
        "id": "Iqj-tNoCP_EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Explosion in the era of Internet\n",
        "\n",
        "*   10K+ movies in Netflix\n",
        "*   12M products in Amazon\n",
        "*   70M+ music tracks in Spotify\n",
        "*   10B+ videos on YouTube\n",
        "*   200B+ pins (images) in Pinterest\n",
        "\n",
        "**Personalized recommendation (i.e., suggesting a small number of interesting items for each user)** is critical for users to effectively explore the content of their interest.\n",
        "\n"
      ],
      "metadata": {
        "id": "bCQmragwQGHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recommendation System as a Graph"
      ],
      "metadata": {
        "id": "4M_9MytoQsv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommender system can be naturally modeled as a **bipartite graph**.\n",
        "\n",
        "*   A graph with two node types: **users** and **items**\n",
        "*   Edges connect users and items\n",
        "    *    Indicates user-item interaction (e.g., click, purchase, review)\n",
        "    *    Often associated with timestamp (timing of the interaction)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QTprqNjLmxKU5xhjTVPVPRlUQmhiHKFS\" width=\"150\">\n",
        "\n",
        "> For the AI model to produce accurate recommendations it needs a detailed understanding of product properties as well as customer preferences. **Products as well as customers are often associated with unstructured textual information like product names, product descriptions, customer reviews, and more. It is critical for the recommender system to include text understanding capability because so much information is stored in unstructured text.**\n",
        "\n",
        "> At the same time, graph information is highly valuable in recommender systems because it captures **complex relationships between customers, products, and their interactions**. Graphs represent the relationships between customers and products as edges, allowing the system to consider not just **direct** interactions (like purchases or ratings) but also **indirect** connections (e.g., customers who like similar products or products that are liked by similar customers).\n",
        "\n",
        "> In graph-based systems, higher-order connections (i.e., multi-hop relationships) can be leveraged. **For instance, if Customer A likes a product that Customer B liked, and Customer C is similar to Customer B, the system might recommend that product to Customer C as well.** Overall, graph-based models provide a nuanced understanding of customers’ preferences by considering both direct and indirect interactions. This enables highly personalized recommendations, taking into account more contextual information about the customer and their network.\n",
        "\n",
        "⚠️ **We will not model our relational database as a bipartite graph, but this provides you with an idea about the popularity of graph representations within the RecSys field and the underlying motivations.**"
      ],
      "metadata": {
        "id": "G72S9hGRQvVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recommendation Task"
      ],
      "metadata": {
        "id": "C-y40xodRR1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given\n",
        "\n",
        "*   Past user-item interactions.\n",
        "\n",
        "Task\n",
        "\n",
        "*   Predict new items each user will interact in the future.\n",
        "*   Can be cast as **link prediction** problem.\n",
        "    *   Predict new user-item interaction edges given the past edges.\n",
        "\n",
        "For $u \\in U$, $v \\in V$, we need to get a real-valued score $f(u, v)$.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1S17_5hMnCEfYfgeUwYcv0EKqbF9I4zxd\" width=\"150\">\n",
        "\n"
      ],
      "metadata": {
        "id": "SVCwlPPeRT77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moder Recommender System"
      ],
      "metadata": {
        "id": "gpWepsNATmvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem:** Cannot evaluate $f(u,v)$ for every user $u$ $-$ item $v$ pair.\n",
        "**Solution:** 2-stage process.\n",
        "  *   Candidate generation (cheap, fast)\n",
        "  *   Ranking (slow, accurate)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1KuJBKw9BnsnC9HoBF20pg48nuXnrRgTm\" width=\"550\">"
      ],
      "metadata": {
        "id": "M-JNHZQ1TpHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top-K Recommendation"
      ],
      "metadata": {
        "id": "QyzUgHlRURT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each user, we recommend $K$ items (those from the user-item interaction pairs with the largest scores, excluding already-interacted items).\n",
        "\n",
        "  *   For recommendation to be effective, $K$ needs to be much smaller than the total number of items (up to billions).\n",
        "  *   $K$ is typically in the order of $10-100$.\n",
        "\n",
        "The goal is to include as many **positive items** as possible in the top-$K$ recommended items.\n",
        "\n",
        "  *   **Positive items = Items that the user will interact with in the future**.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mZPzFOQkgN0HOVkEZUW77DHLioi44PZj\" width=\"250\">"
      ],
      "metadata": {
        "id": "iFftoBILUUDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding-Based Models"
      ],
      "metadata": {
        "id": "jGk6X6VCX1UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider embedding-based models for scoring user$-$item interactions.\n",
        "\n",
        "*   For each user $u \\in U$, let $\\mathbf{u} \\in \\mathbb{R}^D$ be its $D$-dimensional embedding.\n",
        "*   For each item $v \\in V$, let $\\mathbf{v} \\in \\mathbb{R}^D$ be its $D$-dimensional embedding.\n",
        "*   $f_{\\theta}(\\cdot, \\cdot): \\mathbb{R}^D \\times \\mathbb{R}^D$ is a parametrized function.\n",
        "\n",
        "Thus, embedding-based models have **three kinds of parameters**:\n",
        "*   An encoder to generate user embeddings $\\{\\mathbf{u}\\}_{u \\in U}$.\n",
        "*   An encoder to generate item embeddings $\\{\\mathbf{v}\\}_{v \\in V}$.\n",
        "*   Score function $f_{\\theta}(\\cdot, \\cdot)$.\n",
        "\n",
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1aht8ewGJ7Hv7KhG2cA8yw1Lbtep3rBgV\" width=\"210\">"
      ],
      "metadata": {
        "id": "Z1DMpbvpX3nN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Objective"
      ],
      "metadata": {
        "id": "Y8PiBJPFapWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimize the model parameters to **achieve high recall@$K$ on seen (i.e., training) user$-$item interactions**.\n",
        "*   We hope this objective would lead to high recall@$K$ on unseen (i.e., test) interactions.\n",
        "\n",
        "Recall@$K$ for user $u$ is $\\frac{|P_u ∩ R_u|}{|P_u|}$: percentage of recommended positive items. The final Recall@$K$ is computed by averaging the recall values across all users.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FDWeao5uWsL1KY6KCOV6gK4xQ3MpRW4j\" width=\"400\">\n",
        "\n",
        "The original training objective (recall@$K$) is **not differentiable**.\n",
        "*   The community employs **surrogate (differentiable) losses** that align well with the original training objective.\n",
        "*   Widely-used surrogate loss: **Bayesian Personalized Ranking (BPR)**.\n",
        "\n",
        "Considering this illustration...\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1o4wz7GNpZ4uBAurKj22uV9On0G__oIIt\" width=\"200\">\n",
        "\n",
        "BPR [[Rendle et al., 2012](https://arxiv.org/pdf/1205.2618)]\n",
        "*   **For each user $u^*$, we want the scores of rooted positive edges $E(u^*)$ to be higher than those of rooted negative edges $E_{neg}(u^*)$**.\n",
        "*    It supports **mini-batches**.\n",
        "    *    In each mini-batch, we sample a subset of users $U_{mini} ⊂ U$.\n",
        "    *    For each user $u^* \\in U_{mini}$, we sample one positive item $v_{pos}$ and a set of sampled negative items $V_{neg}$.\n",
        "\n",
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1fgZu6WsPznqWotFRl_jCjXcoOLsiTjey\" width=\"600\">\n",
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1RwS73U0kYAY4zv4zp43tFZeZJRhMB6vM\" width=\"600\">\n",
        "\n",
        "<br>\n",
        "More information: https://web.stanford.edu/class/cs224w/slides/12-recsys.pdf"
      ],
      "metadata": {
        "id": "PdUVw3YmatDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Embedding Models Work?"
      ],
      "metadata": {
        "id": "UlR_21AKf6Vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Underlying idea: **Collaborative filtering**\n",
        "\n",
        "*   Recommend items for a user by **collecting preferences of many other similar users**.\n",
        "*   **Similar users tend to prefer similar items**\n",
        "\n",
        "Embedding-based models can capture similarity of users/items!\n",
        "\n",
        "*   Low-dimensional embeddings cannot memorize all user$-$item interaction data.\n",
        "*   Embeddings are forced to capture similarity between users/items to fit the data.\n",
        "*   This allows the models to make effective prediction on *unseen* user$-$item interactions.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1VH59zqdaONHC45UkrQU2TQtpcNX6MxbP\" width=\"300\">\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Gf-5xx1f9E_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🤖 Train a GNN"
      ],
      "metadata": {
        "id": "ff7m2hBNWGiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the data we did not require any deep learning libraries. In this part of the notebook, we will work with PyTorch."
      ],
      "metadata": {
        "id": "t0MyQb6FXIPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup"
      ],
      "metadata": {
        "id": "pBu1zjvDZ15C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch_geometric.seed import seed_everything\n",
        "\n",
        "# Check that it's cuda if you want it to run in reasonable time!\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_num_threads(1)\n",
        "print(device)\n",
        "\n",
        "# Set the seed for generating random numbers to ensure reproducibility\n",
        "seed_everything(42)\n",
        "\n",
        "# Path to the directory for caching graph data\n",
        "root_dir = \"./data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjW5ZjHeSZhC",
        "outputId": "f772d189-0dc7-4a0e-cf93-97b8d6a8ce9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the Graph and Initialize Features"
      ],
      "metadata": {
        "id": "oEVlg1wMaMvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heterogeneous Temporal Graph**\n",
        "\n",
        "The first big move is to build a graph out of the database.\n",
        "We will use a pre-prepared conversion function, `make_pkey_fkey_graph`, from Stanford [[Source Code](https://github.com/snap-stanford/relbench/blob/main/relbench/modeling/graph.py)].\n",
        "Given a set of tables with primary-foreigh key relations between them, we automatically construct a heterogeneous temporal graph, where:\n",
        "\n",
        "*   Each **table** represents a **node type** (HETEROGENEOUS).\n",
        "*   Each **row in a table** represents a **node**.\n",
        "*   A **primary-foreign-key relation** between two table rows (nodes) represent an **edge** between the respective nodes. Even edges have multiple types (HETEROGENEOUS), depending on the attribute that connects two tables.\n",
        "\n",
        "Some node types are associated with time attributes, representing the timestamp at which a node appears (TEMPORAL).\n",
        "\n",
        "The heterogeneous temporal graph is represented as a **PyTorch Geometric** graph object.\n",
        "\n",
        "💡 The graph representation allows GNNs to be used as predictive models."
      ],
      "metadata": {
        "id": "bRoQIVV8jlJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Initialization**\n",
        "\n",
        "Each node in the graph comes with a rich feature derived from diverse columns of the corresponding table.\n",
        "\n",
        "We use **Tensor Frame provided by PyTorch Frame** to represent rich node features with diverse column types, e.g., numerical, categorical, timestamp, and text.\n",
        "\n",
        "**PyTorch Frame also stores the `stype` (i.e., modality) of each column** and **allows to set the feature encoders (e.g., text encoders) to be used later**.\n",
        "\n",
        "So, we need to configure the `stype` for each column, for which we use a function that tries to automatically detect the `stype`."
      ],
      "metadata": {
        "id": "LPrbuRa6pa5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.modeling.utils import get_stype_proposal\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "col_to_stype_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBulIHV5Sxmq",
        "outputId": "8bc24686-701b-45f7-bd18-0e6a31f31cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'customer': {'customer_id': <stype.numerical: 'numerical'>,\n",
              "  'FN': <stype.categorical: 'categorical'>,\n",
              "  'Active': <stype.categorical: 'categorical'>,\n",
              "  'club_member_status': <stype.categorical: 'categorical'>,\n",
              "  'fashion_news_frequency': <stype.text_embedded: 'text_embedded'>,\n",
              "  'age': <stype.numerical: 'numerical'>,\n",
              "  'postal_code': <stype.text_embedded: 'text_embedded'>},\n",
              " 'transactions': {'t_dat': <stype.timestamp: 'timestamp'>,\n",
              "  'customer_id': <stype.numerical: 'numerical'>,\n",
              "  'article_id': <stype.numerical: 'numerical'>,\n",
              "  'price': <stype.numerical: 'numerical'>,\n",
              "  'sales_channel_id': <stype.categorical: 'categorical'>},\n",
              " 'article': {'article_id': <stype.numerical: 'numerical'>,\n",
              "  'product_code': <stype.numerical: 'numerical'>,\n",
              "  'prod_name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'product_type_no': <stype.numerical: 'numerical'>,\n",
              "  'product_type_name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'product_group_name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'graphical_appearance_no': <stype.numerical: 'numerical'>,\n",
              "  'graphical_appearance_name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'colour_group_code': <stype.numerical: 'numerical'>,\n",
              "  'colour_group_name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'perceived_colour_value_id': <stype.categorical: 'categorical'>,\n",
              "  'perceived_colour_value_name': <stype.categorical: 'categorical'>,\n",
              "  'perceived_colour_master_id': <stype.categorical: 'categorical'>,\n",
              "  'perceived_colour_master_name': <stype.categorical: 'categorical'>,\n",
              "  'department_no': <stype.numerical: 'numerical'>,\n",
              "  'department_name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'index_code': <stype.categorical: 'categorical'>,\n",
              "  'index_name': <stype.categorical: 'categorical'>,\n",
              "  'index_group_no': <stype.categorical: 'categorical'>,\n",
              "  'index_group_name': <stype.categorical: 'categorical'>,\n",
              "  'section_no': <stype.numerical: 'numerical'>,\n",
              "  'section_name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'garment_group_no': <stype.categorical: 'categorical'>,\n",
              "  'garment_group_name': <stype.categorical: 'categorical'>,\n",
              "  'detail_desc': <stype.text_embedded: 'text_embedded'>}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we also define our text encoding model. We will use **GloVe** embeddings for speed and convenience. Feel free to try alternatives here."
      ],
      "metadata": {
        "id": "6371BuLgdPAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch import Tensor\n",
        "\n",
        "class GloveTextEmbedding:\n",
        "    def __init__(self, device: Optional[torch.device] = None):\n",
        "        self.model = SentenceTransformer(\n",
        "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    def __call__(self, sentences: List[str]) -> Tensor:\n",
        "        return self.model.encode(sentences, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "7tM6vwe0UbPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🕒 *Please note that graph construction can take up to 10 minutes.*"
      ],
      "metadata": {
        "id": "jHeXLwDAeAbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Root directory where files will be stored\n",
        "root_dir = \"./data\"\n",
        "\n",
        "# Run the from-scratch graph computation\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "\n",
        "# Configure the text encoder\n",
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=GloveTextEmbedding(device=device),\n",
        "    batch_size=256\n",
        ")\n",
        "\n",
        "# Generate graph data\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # Column types\n",
        "    text_embedder_cfg=text_embedder_cfg,  # Our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-hm_materialized_cache\"\n",
        "    ),  # Store materialized graph for convenience\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519,
          "referenced_widgets": [
            "b15f412bb5a74a779ed1d21930ad2c49",
            "090831c5bc3344f0828132081b49f372",
            "54a1852ba4ce4fcbb49911bcd67c1dbf",
            "92e89c3693f743d48f0705b6a67d1342",
            "dbb63c456f45406d90349400e3571a98",
            "02b2508703f643fb9ec8a761f47c3f60",
            "a4cd0459d09c4c1a9a875340121201b2",
            "1851aca5a20c4d7aba247b386ebdec12",
            "24f2dbba21854f41919028f54058c48f",
            "45695d68fa174e34b1cea00e5e1b97ab",
            "6e104f04732d41478ea88c75bec251b8",
            "b8ff57c6b89a4104b058ebb5114fb9b0",
            "87a0db2bc05d4c178316a8adfb3f86ba",
            "2aeeb1cd222c4f758fc2183f933490ac",
            "29715dce7eaf4afdb1dc948e5bad1569",
            "10fb5a19c80d4b09ad7b8b0d26ca3b41",
            "83611b8f08ac4e0e8d39c4935969a223",
            "b07f465a649b44f4978105fdc33f609d",
            "c06b8e63fe2940a194ad66780146c628",
            "cf303a9f621146fea2f03a00ffd73c16",
            "e0c80acfe195499ea7854111b055a866",
            "4eccce726e764fa9b463ad823a3ccf78",
            "ddf3e229eca04eadaef0c58ae5f10a04",
            "497a567aecf54da8b3825b16844f63e8",
            "82f950cb3a424247883ec236648bd9d8",
            "7228ef0a9ab2472bb7dc3b6da9ac4bee",
            "1550a1610f014a258f42890a2aa51dd4",
            "e801470eb3a045a28db99022910c7924",
            "7f811c9a576d4c81939cd422667dde6f",
            "450085b901754622ac06bb024cd00292",
            "a7c7a577ba3144d8a01d610ee4dffbf0",
            "de9bc6f6168847f783b5cd51d8103f3a",
            "65cc639053f1426284de90d385c16799",
            "296631feff564837ba8e518cb107020e",
            "9a7a584c39f84accaf0c6946877225a6",
            "594f714eb4c947098205b08b4221c1bb",
            "9380f6f5cb8a43e4838fb2cf9b0cbeae",
            "7c9849c28cf541cfaf75366ef7914724",
            "ddefca047c9446db9a73797c6ad6552e",
            "b22684e0102e4ec080b8b1ace7e3857b",
            "512f37cd6dc84966bc43a32fa761a5db",
            "b08389d240074913ac3019d2cf0a8fe9",
            "6e07c0a39745401daed7d175c775403a",
            "aea54148ce694d5b9464fc17ab7c40ae",
            "24957b437c514f9fb21b1327b4e682c3",
            "940b1be26ef4405e9b57b2e649c98523",
            "5bddd78ab45f4376a20817b8364db2d1",
            "b6a75a6865dc45f2b0bfdc6c767071ae",
            "dc3b4cba81534eb4b85c08ecd16d2955",
            "e3200f1a0b0b4f049c66615a19bebb62",
            "ce9570e751744b65bd637abebac6e1b9",
            "d43aecf30ee1479a869fa0528bcd3bab",
            "5b156096ecef400d83837adacfb31c9d",
            "6f06ec5e4e07471b8a08ea0aab0ad54f",
            "217c38140a7245aaa18a17c99e047f6f",
            "7215c77b685d4a2a8fc4aa8605688a45",
            "d49ad836d44f415d90e43329314ec792",
            "c8bf5ba09eb747cd87450972fcd87c19",
            "1b2d625b3b15446d91aa89e19fb152d4",
            "275764a90b39455b86ea2c58be96e805",
            "0d0b5d9edd5f4b29b049170c51c58b90",
            "734a7d20f8ff4e50bcf37330f4dea562",
            "fe58f3a3c3174775ad30710790c28254",
            "7d5f40e3212045fd8409133499af9044",
            "1ae03480d87640b9b175b40ffbf6f6fc",
            "8c614097e7554bfea2b9abcf1ee76879",
            "df347e2e5168428e99072ac8b4d0d6f4",
            "6105a251a0a3432f8e3add9212d357a6",
            "511f350105f04e54af22166ca236a5e2",
            "b40fd9d18cdd419ca07d04c1f2e4c880",
            "c9ca7d20364c48819a75dcc29ad5e8a2",
            "90fbbf0cdb2949e08a961ad9e419e818",
            "1057ac464c1d4ad381e7b2f62d5e2444",
            "9206ad39c67e46a7bcc061aa8083bc07",
            "d98c1fb998d648a5850e6bd757f23e1e",
            "c126bf7a09ce4ffeaee6c892b7ca373c",
            "b5ed07bee73c445e8e018c7710cdeaf6"
          ]
        },
        "id": "IAx9NlWcWcSK",
        "outputId": "dc107125-2dff-429d-fc9f-353cb4e5e832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/248 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b15f412bb5a74a779ed1d21930ad2c49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8ff57c6b89a4104b058ebb5114fb9b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddf3e229eca04eadaef0c58ae5f10a04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)beddings/whitespacetokenizer_config.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "296631feff564837ba8e518cb107020e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/480M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24957b437c514f9fb21b1327b4e682c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)WordEmbeddings/wordembedding_config.json:   0%|          | 0.00/164 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7215c77b685d4a2a8fc4aa8605688a45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df347e2e5168428e99072ac8b4d0d6f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding raw data in mini-batch: 100%|██████████| 5360/5360 [00:28<00:00, 189.91it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 5360/5360 [00:32<00:00, 166.32it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:02<00:00, 172.27it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:02<00:00, 164.90it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:04<00:00, 93.08it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:02<00:00, 171.70it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:02<00:00, 155.60it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:02<00:00, 167.76it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:02<00:00, 178.34it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 413/413 [00:02<00:00, 161.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check out `data`, our main graph object, with node types given by the table it originates from."
      ],
      "metadata": {
        "id": "8xRB8wDceTxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKdvcQtRWrC6",
        "outputId": "f0583c51-ef1e-458f-c07d-907c4ddfb589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  customer={ tf=TensorFrame([1371980, 6]) },\n",
              "  transactions={\n",
              "    tf=TensorFrame([15187287, 3]),\n",
              "    time=[15187287],\n",
              "  },\n",
              "  article={ tf=TensorFrame([105542, 24]) },\n",
              "  (transactions, f2p_customer_id, customer)={ edge_index=[2, 15187287] },\n",
              "  (customer, rev_f2p_customer_id, transactions)={ edge_index=[2, 15187287] },\n",
              "  (transactions, f2p_article_id, article)={ edge_index=[2, 15187287] },\n",
              "  (article, rev_f2p_article_id, transactions)={ edge_index=[2, 15187287] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is `HeteroData`?**\n",
        "\n",
        "`HeteroData` is a specialized container in PyTorch Geometric that extends the `Data` class to support heterogeneous graphs. It enables:\n",
        "- Representation of **different node types** with distinct feature sets.\n",
        "- Representation of **different edge types** capturing various relationships between nodes.\n",
        "- Efficient storage of graph data for use in graph neural networks (GNNs).\n",
        "\n",
        "---\n",
        "\n",
        "**Node types**\n",
        "\n",
        "We see 3 node types (`customer`, `transactions`, `article`). Each node type has its own `TensorFrame` (or tensor) to store features. Example: `customer={ tf=TensorFrame([1371980, 6]) }` means that there are 1,371,980 customer nodes, each with 6 features.\n",
        "\n",
        "The `transactions` node type, `data['transactions']`, stores two feature types:\n",
        "\n",
        "*   A `TensorFrame` object.\n",
        "*   A timestamp for each node.\n",
        "\n",
        "---\n",
        "\n",
        "**Edge types**\n",
        "\n",
        "An edge type defines the relationship between two node types in the graph. Each edge type consists of: `(source_node_type, relation_type, target_node_type)`.\n",
        "We see 4 edge types. Example: `(transactions, f2p_customer_id, customer)={ edge_index=[2, 15187287] }` indicates 15,187,287 directed edges connecting `transactions` nodes to `customer` nodes via the relationship `f2p_customer_id`."
      ],
      "metadata": {
        "id": "-WWlMEMsRRkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check out the `TensorFrame` for one table like this:"
      ],
      "metadata": {
        "id": "Gomu2Qise42j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"customer\"].tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULQ1lgcv_gz3",
        "outputId": "b42a6ffa-8980-4caa-e5de-bd2fcfec9078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=6,\n",
              "  num_rows=1371980,\n",
              "  categorical (3): ['Active', 'FN', 'club_member_status'],\n",
              "  numerical (1): ['age'],\n",
              "  embedding (2): ['fashion_news_frequency', 'postal_code'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"article\"].tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lHoQs0Y_osm",
        "outputId": "185e2ff0-5bbd-4773-9884-3913951f0de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=24,\n",
              "  num_rows=105542,\n",
              "  numerical (6): ['colour_group_code', 'department_no', 'graphical_appearance_no', 'product_code', 'product_type_no', 'section_no'],\n",
              "  categorical (10): ['garment_group_name', 'garment_group_no', 'index_code', 'index_group_name', 'index_group_no', 'index_name', 'perceived_colour_master_id', 'perceived_colour_master_name', 'perceived_colour_value_id', 'perceived_colour_value_name'],\n",
              "  embedding (8): ['colour_group_name', 'department_name', 'detail_desc', 'graphical_appearance_name', 'prod_name', 'product_group_name', 'product_type_name', 'section_name'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"transactions\"].tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0udnCscXPV0",
        "outputId": "e05163ed-0aa5-40c5-e460-9a5893511bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=3,\n",
              "  num_rows=15187287,\n",
              "  timestamp (1): ['t_dat'],\n",
              "  numerical (1): ['price'],\n",
              "  categorical (1): ['sales_channel_id'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ℹ️ *Features marked as embedding in the TensorFrame (e.g., colour_group_name, department_name, etc.) represent pre-existing embeddings or dense representations, such as word embeddings for textual data. In our case, they are the GloVe embeddings previously computed at graph construction time.*"
      ],
      "metadata": {
        "id": "CRUO8-J_APIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(data[\"transactions\"].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ibmru6P1zy8",
        "outputId": "86bc5cd8-6233-4b0f-f573-e6fe1df3a711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tf', 'time']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `TensorFrame` object acts analogously to the usual tensor of node features, and you can simply use indexing to retrieve the features of a single row (node), or group of nodes.\n",
        "\n"
      ],
      "metadata": {
        "id": "xiO4JTXPkXOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features of node 10\n",
        "data[\"transactions\"].tf[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywYlLnJc14gQ",
        "outputId": "9fca4f0a-e116-4520-da47-4a5f61b5d161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=3,\n",
              "  num_rows=1,\n",
              "  timestamp (1): ['t_dat'],\n",
              "  numerical (1): ['price'],\n",
              "  categorical (1): ['sales_channel_id'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features of nodes 10, 11, ..., 19\n",
        "data[\"transactions\"].tf[10:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUhpTrrW1_I1",
        "outputId": "da3e12ec-878d-4031-833c-86ab7cfbd63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=3,\n",
              "  num_rows=10,\n",
              "  timestamp (1): ['t_dat'],\n",
              "  numerical (1): ['price'],\n",
              "  categorical (1): ['sales_channel_id'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the edge indices between two different node types, such as `transactions` and `customers`. Since the edges are also heterogenous, we need to specify which edge type we want to look at. Here we look at `f2p_customer_id`, which are the directed edges pointing from a transaction (the *f* stands for *foreign key*), to the customer that completed that transaction (the *p* stands for *primary key*)."
      ],
      "metadata": {
        "id": "whYqz2EvbEya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[(\"transactions\", \"f2p_customer_id\", \"customer\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeOwm4MJ2P4s",
        "outputId": "9840c0da-aaf4-4812-ed32-b286c684d1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[       0,        1,        2,  ..., 15187284, 15187285, 15187286],\n",
              "        [     155,      155,      155,  ...,  1371926,  1371926,  1371926]])}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `edge_index` tensor has the following structure:\n",
        "\n",
        "*   It is a 2D tensor with shape `[2, num_edges]`.\n",
        "*   The first row (`edge_index[0]`) contains the indices of the source nodes (in this case, transactions).\n",
        "*   The second row (`edge_index[1]`) contains the indices of the target nodes (in this case, customer).\n",
        "*   Each column in `edge_index` defines a directed edge between two nodes, connecting a source node to a target node."
      ],
      "metadata": {
        "id": "8Iz7aGyCdayd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two-Tower GNN Architecture"
      ],
      "metadata": {
        "id": "r0wCFxiheIf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that recommendation requires computing scores between pairs of source nodes and target nodes.\n",
        "\n",
        "For this task type, our architecture is a **two-tower GNN** [[Wang et al., 2019](https://dl.acm.org/doi/abs/10.1145/3331184.3331267?casa_token=NWPeKZ6jwg4AAAAA:H8GuVLZSfjA_KaABlf-UUHUjGKatRbwP4UyTkZpPJJRcsrhnfuRBa2dBFolHE4S6l1ggI8j-thqdig)] that computes the pairwise score via inner product between source and target node embeddings.\n",
        "\n",
        "Illustration of a two-tower GNN from the reference paper:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1TspJlRuCw33VBB3CD1ZJeLDDiZrIDEZ7\" width=\"600\">\n",
        "\n",
        "Initial embeddings of the customer (left) and article (right) nodes under comparison are separately refined through a GNN with multiple layers (shared weights). The outputs are pooled to make the final binary prediction (0 = no link, 1 = link) via inner product."
      ],
      "metadata": {
        "id": "HMpjHi4Z569W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Architecture for Temporal-Aware Heterogeneous Graph Neural Networks**\n",
        "\n",
        "The following model implements a heterogeneous graph neural network with temporal awareness using PyTorch Geometric and PyTorch Frame.\n",
        "\n",
        "It processes raw tabular data into node embeddings, incorporates temporal information, and performs neighbor aggregation through a GraphSAGE-inspired GNN architecture.\n",
        "\n",
        "As in the RELBENCH paper, our modeling supports two representative predictive architectures.\n",
        "1. **GraphSAGE [[Hamilton et al., 2017](https://proceedings.neurips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html)]**.\n",
        "   * Each layer:\n",
        "      * Concatenates self and neighborhood states, and apply on it a single trainable weight matrix as the update function.\n",
        "      * Samples a fixed number of neighbors at multiple distances and treat them as direct neighbors of node $v$.\n",
        "   * It considers the *Bayesian Personalized Ranking (BPR) loss*.\n",
        "2. **ID-GNN [[You et al., 2021](https://ojs.aaai.org/index.php/AAAI/article/view/17283)]**.\n",
        "   * ID-GNN extends existing GNN architectures (GraphSAGE in our case) by inductively considering nodes' identities during message passing.\n",
        "   * It adds an identity coloring technique to distinguish a node itself (the root node in the computational graph) from other nodes in its local neighborhood, within its respective computational graph. The center node and the rest of the nodes are computed using different sets of parameters. In summary, it adds expressive power.\n",
        "   * It considers a standard *Binary Cross-Entropy loss*.\n"
      ],
      "metadata": {
        "id": "bcx-_iLq8r-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, List\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Heterogeneous Graph Neural Network Model with Temporal Encoding.\n",
        "\n",
        "    This model is designed for tasks on heterogeneous graphs with temporal information. It processes\n",
        "    raw tabular data into embeddings, encodes temporal information, aggregates node features\n",
        "    with a GNN, and produces task-specific predictions.\n",
        "\n",
        "    Args:\n",
        "        data (HeteroData): A heterogeneous graph object containing nodes, edges, and features.\n",
        "        col_stats_dict (Dict[str, Dict[str, Dict[StatType, Any]]]): Column statistics for raw tabular features.\n",
        "            - This is a dictionary where:\n",
        "                - `node_type` -> Feature name -> Statistic (e.g., mean, std).\n",
        "                - Used by the HeteroEncoder for normalizing input features.\n",
        "        num_layers (int): Number of layers in the GNN (depth of feature propagation).\n",
        "        channels (int): Dimensionality of intermediate node embeddings (hidden layer size).\n",
        "        out_channels (int): Dimensionality of output embeddings (final layer size).\n",
        "        aggr (str): Aggregation function for GraphSAGE (e.g., \"sum\", \"mean\").\n",
        "        norm (str): Normalization method applied in the MLP head (e.g., \"batchnorm\").\n",
        "        shallow_list (List[NodeType], optional): List of node types to assign shallow embeddings to. Defaults to [].\n",
        "        id_awareness (bool, optional): If True, adds a unique embedding for ID-awareness. Defaults to False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData,\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        1. HeteroEncoder: Encoding Raw Tabular Features\n",
        "        ---\n",
        "        HeteroEncoder is responsible for converting raw tabular data from different node types into dense embeddings.\n",
        "\n",
        "        - TYPE-AWARE FEATURE EMBEDDING\n",
        "          - NUMERICAL FEATURES: These are passed through a linear layer (e.g., LinearEncoder), which maps them into a dense vector space.\n",
        "          - CATEGORICAL FEATURES: These are embedded using an embedding layer (e.g., EmbeddingEncoder). For example,\n",
        "            if 'sales_channel_id' has 5 categories, each category is mapped to a learned vector of size `channels`.\n",
        "          - TIMESTAMP FEATURES: These are encoded with a timestamp encoder (e.g., TimestampEncoder) to add time sensitivity.\n",
        "          - EMBEDDING FEATURES: These are already dense vectors, unlike raw categorical or numerical features. The HeteroEncoder processes\n",
        "            them using a linear transformation layer (LinearEmbeddingEncoder), which adjusts their dimensionality.\n",
        "\n",
        "        - AGGREGATION: The encoded features for each node type are aggregated by a ResNet tabular model. The ResNet combines raw feature\n",
        "          embeddings and their interactions, producing a final dense embedding of size `channels` for the node type. This aggregated\n",
        "          embedding is passed downstream to the GNN.\n",
        "\n",
        "        - END-TO-END TRAINING: All these transformations are trainable and learned alongside the GNN, similar to an embedding layer\n",
        "          in transformer models. The model optimizes the parameters of these encoders during backpropagation.\n",
        "\n",
        "        - ROLE OF COLUMN STATISTICS (`col_stats_dict`): These are used to normalize the numerical features (e.g., subtract mean, divide by std).\n",
        "          For example, 'price' may be normalized using its mean and std before being passed through LinearEncoder.\n",
        "        \"\"\"\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,  # target embedding dim\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },  # dictionary mapping from node type to column names\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        2. HeteroTemporalEncoder: Incorporating Time Sensitivity\n",
        "        ---\n",
        "        The HeteroTemporalEncoder is designed to encode time-related information for nodes that have temporal features.\n",
        "        It ensures that the model respects the temporal ordering of events and can include relative time-based signals\n",
        "        in the embeddings, which is critical for temporal tasks (e.g., predicting future behavior).\n",
        "\n",
        "        - NODE TYPES WITH TIME FEATURES\n",
        "          - The encoder processes only those node types where a \"time\" key is present in the `HeteroData` object.\n",
        "          - For example, since the `transactions` node type has a time feature (see `list(data[\"transactions\"].keys())`),\n",
        "            it will be included in this temporal processing.\n",
        "\n",
        "        - TEMPORAL ENCODING PROCESS:\n",
        "          1. Compute **relative time differences**:\n",
        "            - For each node, compute the difference between the `seed_time` (reference time for the batch) and the node's\n",
        "              timestamp (`time_dict[node_type]`).\n",
        "            - Convert the difference from seconds to days (scaling for interpretability and numerical stability).\n",
        "          2. Apply **positional encoding**:\n",
        "            - The relative time differences are passed through the `PositionalEncoding` module, producing dense embeddings.\n",
        "          3. Apply **linear transformation**:\n",
        "            - The embeddings from positional encoding are passed through a node-type-specific linear layer for further processing.\n",
        "            - This ensures the temporal embeddings are adapted to the specific node type and task.\n",
        "          4. Store the output:\n",
        "            - The resulting temporal embeddings are stored in a dictionary (`out_dict`), keyed by node type.\n",
        "\n",
        "        - OUTPUT:\n",
        "          - A dictionary of temporal embeddings for each node type, with embeddings of size `channels`.\n",
        "\n",
        "        - TRAINING:\n",
        "          - The positional encoding and linear transformations are fully trainable. Gradients flow through the entire\n",
        "            temporal encoding process during backpropagation.\n",
        "\n",
        "        - WHY IT MATTERS:\n",
        "          - Temporal embeddings enable the model to capture time-sensitive patterns, such as sequential events or evolving\n",
        "            relationships. By adding these embeddings to the base node embeddings, the model can better understand temporal\n",
        "            dynamics within the graph.\n",
        "        \"\"\"\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        3. HeteroGraphSAGE: Node Feature Aggregation in Heterogeneous Graphs\n",
        "        ---\n",
        "        The `HeteroGraphSAGE` module implements a heterogeneous version of the GraphSAGE model. It aggregates features from neighboring nodes\n",
        "        using a series of message-passing layers (`HeteroConv`), followed by normalization (`LayerNorm`) and activation.\n",
        "\n",
        "        - MAIN INPUTS:\n",
        "          - **Node Features (`x_dict`)**:\n",
        "            - A dictionary mapping each node type to its corresponding features.\n",
        "            - Features are initially generated by the `HeteroEncoder` and optionally augmented with temporal embeddings.\n",
        "          - **Edge Index (`edge_index_dict`)**:\n",
        "            - A dictionary mapping each edge type to its corresponding sparse edge index tensor (i.e., graph connectivity).\n",
        "            - Specifies how nodes of different types are connected in the graph.\n",
        "\n",
        "        - ARCHITECTURE:\n",
        "          1. **HeteroConv Layers (`self.convs`)**:\n",
        "            - A stack of `HeteroConv` layers, each aggregating features from neighboring nodes across all edge types.\n",
        "            - Each `HeteroConv` layer consists of:\n",
        "              - Multiple `SAGEConv` layers (one per edge type), which perform the GraphSAGE aggregation for specific node pairs.\n",
        "              - An aggregation function (`sum`) that combines the outputs of these `SAGEConv` layers into a unified embedding\n",
        "                for each node type.\n",
        "            - The number of layers is specified by `num_layers`, allowing multi-hop message passing.\n",
        "          2. **Layer Normalization (`self.norms`)**:\n",
        "            - A `LayerNorm` is applied to the aggregated features of each node type to stabilize training and improve convergence.\n",
        "            - Each node type has its own normalization layer.\n",
        "          3. **Non-Linearity (ReLU)**:\n",
        "            - A ReLU activation is applied after normalization to introduce non-linearity into the learned embeddings.\n",
        "\n",
        "        - MESSAGE-PASSING PROCESS:\n",
        "          1. For each layer:\n",
        "            - **Aggregation**:\n",
        "              - Node embeddings are updated by aggregating features from neighboring nodes based on the graph structure.\n",
        "              - This includes type-specific transformations via `SAGEConv` and cross-type aggregation via `HeteroConv`.\n",
        "            - **Normalization**:\n",
        "              - LayerNorm ensures that the embeddings for each node type are normalized.\n",
        "            - **Non-Linearity**:\n",
        "              - A ReLU activation is applied to add non-linear expressiveness.\n",
        "          2. This process is repeated for `num_layers` steps, enabling multi-hop feature propagation across the graph.\n",
        "\n",
        "        - TYPICAL GRAPHSAGE NEIGHBOR SAMPLING:\n",
        "          - There is no optional sampling metadata at architecture definition. However, at forward (call) time, we can\n",
        "            pass already-sampled nodes. In other terms, neighbor sampling, if performed, happens outside this module,\n",
        "            as part of the data preprocessing.\n",
        "          - Optionally, `num_sampled_nodes_dict` and `num_sampled_edges_dict` provide information on sampled nodes and edges\n",
        "            for each layer during mini-batch training, enabling efficient scaling to large graphs.\n",
        "\n",
        "        - TRAINING:\n",
        "          - All parameters in the `SAGEConv` layers and `LayerNorm` modules are trainable. Gradients flow back through the entire\n",
        "            message-passing process during backpropagation.\n",
        "\n",
        "        - OUTPUT:\n",
        "          - A dictionary mapping each node type to its updated embeddings after `num_layers` of message-passing.\n",
        "\n",
        "        - WHY IT MATTERS:\n",
        "          - The `HeteroGraphSAGE` module enables the model to capture relationships and dependencies between nodes of different types\n",
        "            (heterogeneous graph learning). By aggregating features from neighbors, the model can learn richer representations that\n",
        "            incorporate both node attributes and graph structure.\n",
        "        \"\"\"\n",
        "        self.gnn = HeteroGraphSAGE(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            aggr=aggr,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        4. MLP: Task-Specific Prediction Head\n",
        "        ---\n",
        "        The `MLP` (Multi-Layer Perceptron) from PyTorch Geometric is used as the final prediction head of the model.\n",
        "        It transforms the node embeddings output by the `HeteroGraphSAGE` module into task-specific outputs.\n",
        "\n",
        "        - INPUTS:\n",
        "          - **Input Dimensionality (`channels`)**:\n",
        "            - The dimensionality of the node embeddings output by the `HeteroGraphSAGE` module.\n",
        "            - This represents the size of the features that the MLP processes.\n",
        "\n",
        "          - **Output Dimensionality (`out_channels`)**:\n",
        "            - The size of the final output. For example:\n",
        "              - For node classification, this corresponds to the number of classes (e.g., `out_channels=4` for 4-way classification).\n",
        "              - For regression tasks, this might correspond to the size of the predicted vector (e.g., `out_channels=1` for a single regression score).\n",
        "\n",
        "          - **Normalization (`norm`)**:\n",
        "            - Specifies the normalization method applied to the intermediate layers of the MLP.\n",
        "            - Common options include `\"batchnorm\"` or `\"layernorm\"`. Normalization stabilizes training and accelerates convergence.\n",
        "\n",
        "          - **Number of Layers (`num_layers`)**:\n",
        "            - Controls the depth of the MLP. In this case, `num_layers=1`, meaning the MLP has a single linear transformation\n",
        "              followed by optional normalization and activation.\n",
        "              - For `num_layers=1`, the MLP effectively acts as a linear transformation.\n",
        "\n",
        "        - TRAINABLE PARAMETERS:\n",
        "          - All weights and biases of the MLP are trainable and are updated during backpropagation.\n",
        "\n",
        "        - OUTPUT:\n",
        "          - A tensor of size `[num_nodes, out_channels]`, where `num_nodes` corresponds to the number of nodes being predicted.\n",
        "\n",
        "        - WHY IT MATTERS:\n",
        "          - The `MLP` serves as the final layer that adapts the model's learned embeddings to the specific task at hand.\n",
        "            It provides flexibility to handle a variety of prediction tasks with different output requirements.\n",
        "        \"\"\"\n",
        "        self.head = MLP(\n",
        "            channels,\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        5. Optional Shallow Embeddings for Selected Node Types\n",
        "        ---\n",
        "        These embeddings provide additional trainable representations for selected node types.\n",
        "        Shallow embeddings are often used when certain node types require extra learnable parameters independent of their raw\n",
        "        features or encoded embeddings.\n",
        "        These embeddings are specific to each node type and are added to the node features before message passing.\n",
        "\n",
        "        - INPUT:\n",
        "          - `shallow_list`: A list of node types for which shallow embeddings are required.\n",
        "          - `data.num_nodes_dict`: A dictionary mapping each node type to the number of nodes of that type.\n",
        "\n",
        "        - IMPLEMENTATION:\n",
        "          - For each node type in `shallow_list`, a separate embedding table is created using `torch.nn.Embedding`.\n",
        "          - The size of the embedding for each node is `channels`, matching the size of other embeddings in the model.\n",
        "          - These embeddings are trainable and initialized with random values.\n",
        "\n",
        "        - USAGE:\n",
        "          - During the forward pass, shallow embeddings are added directly to the node features for their corresponding node types.\n",
        "          - This provides an additional trainable signal that can improve model performance in certain cases.\n",
        "        \"\"\"\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        6. Optional ID-awareness Embedding\n",
        "        ---\n",
        "        ID-awareness in this model is not about assigning a unique embedding to each node.\n",
        "        It serves as an additional, shared global feature vector added only to the embeddings of the \"seed nodes\" (the nodes for\n",
        "        which predictions are being made).\n",
        "        Thus, every seed node gets the same ID-awareness signal, which helps the model learn relationships better during training.\n",
        "        \"\"\"\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Resets parameters for all model components.\"\"\"\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass for node-level prediction tasks.\n",
        "\n",
        "        Args:\n",
        "            batch (HeteroData): Batch of sampled subgraphs.\n",
        "            entity_table (NodeType): The node type for which predictions are made.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predictions for the specified node type.\n",
        "        \"\"\"\n",
        "        # Extract the seed time for temporal encoding\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "\n",
        "        # Encode raw node features\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        # Add temporal information to embeddings\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        # Add shallow embeddings for specified node types\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        # Apply the GNN to aggregate features\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        # Return the final predictions for the specified node type\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass with destination table readout for prediction tasks.\n",
        "\n",
        "        Args:\n",
        "            batch (HeteroData): Batch of sampled subgraphs.\n",
        "            entity_table (NodeType): The node type for seed entities.\n",
        "            dst_table (NodeType): The destination node type for predictions.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Predictions for the destination node type.\n",
        "\n",
        "        Raises:\n",
        "            RuntimeError: If `id_awareness` is not enabled.\n",
        "        \"\"\"\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "\n",
        "        # Extract seed time for temporal encoding\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "\n",
        "        # Encode raw node features\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        # Add ID-awareness to the seed node embeddings\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        # Add temporal information to embeddings\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        # Add shallow embeddings for specified node types\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        # Apply the GNN to aggregate features\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        # Return predictions for the destination node type\n",
        "        return self.head(x_dict[dst_table])"
      ],
      "metadata": {
        "id": "4zUkGML_eLJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1r9Xt3Zfi8Y-z8ECeRMgyIa_Y9awN3B-k\" width=\"400\">\n",
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1lLaGuXUjzoT1DPBbF04FTQ1uv2ALxhJ2\" width=\"500\">"
      ],
      "metadata": {
        "id": "9B2XYF3acE05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "OAfNK7TId5pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Default values matches those reported by the RELBENCH paper [[Source, Table 9](https://arxiv.org/pdf/2407.20060)]."
      ],
      "metadata": {
        "id": "Ohe6I34yaH2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import VBox, HBox, Button, IntSlider, FloatSlider, Checkbox, Dropdown, Text, Label, Layout, HTML\n",
        "\n",
        "# Default values (reorganized based on the appearance order in boxes)\n",
        "default_params = {\n",
        "    # Architecture\n",
        "    \"num_layers\": 2,\n",
        "    \"channels\": 128,\n",
        "    \"aggr\": \"sum\",\n",
        "    \"norm\": \"layer_norm\",\n",
        "\n",
        "    # Data Loading\n",
        "    \"time_attr\": \"time\",\n",
        "    \"temporal_strategy\": \"uniform\",\n",
        "    \"batch_size\": 512,\n",
        "    \"share_same_time\": True,\n",
        "    \"num_neighbors\": 128,\n",
        "    \"num_workers\": 0,\n",
        "\n",
        "    # Training\n",
        "    \"use_shallow\": True,\n",
        "    \"lr\": 0.001,\n",
        "    \"epochs\": 20,\n",
        "    \"max_steps_per_epoch\": 2000,\n",
        "    \"eval_epochs_interval\": 1,\n",
        "    \"tune_metric\": \"link_prediction_map\",\n",
        "}\n",
        "\n",
        "# Widget definitions (reorganized to match default_params and box order)\n",
        "widgets = {\n",
        "    # Architecture\n",
        "    \"num_layers\": IntSlider(value=default_params[\"num_layers\"], min=1, max=5, step=1,\n",
        "                            description=\"Number of Layers:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"channels\": IntSlider(value=default_params[\"channels\"], min=1, max=512, step=1,\n",
        "                          description=\"Embedding Dimensions (Channels):\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"aggr\": Dropdown(options=[\"sum\", \"mean\", \"max\"], value=default_params[\"aggr\"],\n",
        "                     description=\"Aggregation Strategy for Neighbor Messages:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"norm\": Dropdown(options=[\"batch_norm\", \"layer_norm\", \"none\"], value=default_params[\"norm\"],\n",
        "                     description=\"Prediction Head Normalization:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "\n",
        "    # Data Loading\n",
        "    \"time_attr\": Text(value=default_params[\"time_attr\"], description=\"Time Attribute Name for Temporal Neighbor Sampling:\",\n",
        "                      style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"temporal_strategy\": Dropdown(options=[\"uniform\", \"recent\", \"future\"], value=default_params[\"temporal_strategy\"],\n",
        "                                  description=\"Temporal Neighbor Sampling Strategy:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"batch_size\": IntSlider(value=default_params[\"batch_size\"], min=1, max=1024, step=1,\n",
        "                            description=\"Batch Size:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"share_same_time\": Checkbox(value=default_params[\"share_same_time\"],\n",
        "                                description=\"Only Batches where User Nodes have the Same Seed Time (No Shuffling)\", style={\"description_width\": \"300px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"num_neighbors\": IntSlider(value=default_params[\"num_neighbors\"], min=1, max=256, step=1,\n",
        "                               description=\"Max Number of Sampled Neighbors (100% Layer 1, Progressive 50% for Layers >1):\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"num_workers\": IntSlider(value=default_params[\"num_workers\"], min=0, max=4, step=1,\n",
        "                             description=\"Number of Workers for Parallel Data Loading:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "\n",
        "    # Training\n",
        "    \"use_shallow\": Checkbox(value=default_params[\"use_shallow\"],\n",
        "                            description=\"Use Shallow Embeddings for Article Nodes\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"lr\": FloatSlider(value=default_params[\"lr\"], min=0.0001, max=0.001, step=0.0001,\n",
        "                      description=\"Learning Rate:\", readout_format=\".4f\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"epochs\": IntSlider(value=default_params[\"epochs\"], min=1, max=20, step=1,\n",
        "                        description=\"Number of Epochs:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"max_steps_per_epoch\": IntSlider(value=default_params[\"max_steps_per_epoch\"], min=100, max=5000, step=100,\n",
        "                                     description=\"Max Steps per Epoch:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"eval_epochs_interval\": IntSlider(value=default_params[\"eval_epochs_interval\"], min=1, max=10, step=1,\n",
        "                                      description=\"Evaluation Interval:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "    \"tune_metric\": Dropdown(options=[\"link_prediction_map\", \"link_prediction_recall\", \"link_prediction_precision\"], value=default_params[\"tune_metric\"],\n",
        "                             description=\"Tuning Metric for Best-Eval Checkpoint Saving:\", style={\"description_width\": \"500px\"}, layout=Layout(width=\"800px\")),\n",
        "}\n",
        "\n",
        "# Grouping architecture-related widgets\n",
        "architecture_label = HTML(value=\"<b style='font-size:16px;'>Architecture</b>\")\n",
        "architecture_box = VBox([\n",
        "    architecture_label,\n",
        "    widgets[\"num_layers\"],\n",
        "    widgets[\"channels\"],\n",
        "    widgets[\"aggr\"],\n",
        "    widgets[\"norm\"],\n",
        "], layout=Layout(border=\"solid 1px black\", padding=\"10px\", margin=\"10px\"))\n",
        "\n",
        "# Grouping data-related widgets\n",
        "data_label = HTML(value=\"<b style='font-size:16px;'>Data Loading</b>\")\n",
        "data_box = VBox([\n",
        "    data_label,\n",
        "    widgets[\"time_attr\"],\n",
        "    widgets[\"temporal_strategy\"],\n",
        "    widgets[\"batch_size\"],\n",
        "    widgets[\"share_same_time\"],\n",
        "    widgets[\"num_neighbors\"],\n",
        "    widgets[\"num_workers\"],\n",
        "], layout=Layout(border=\"solid 1px black\", padding=\"10px\", margin=\"10px\"))\n",
        "\n",
        "# Grouping training-related widgets\n",
        "training_label = HTML(value=\"<b style='font-size:16px;'>Training</b>\")\n",
        "training_box = VBox([\n",
        "    training_label,\n",
        "    widgets[\"use_shallow\"],\n",
        "    widgets[\"lr\"],\n",
        "    widgets[\"epochs\"],\n",
        "    widgets[\"max_steps_per_epoch\"],\n",
        "    widgets[\"eval_epochs_interval\"],\n",
        "    widgets[\"tune_metric\"],\n",
        "], layout=Layout(border=\"solid 1px black\", padding=\"10px\", margin=\"10px\"))\n",
        "\n",
        "# Reset function\n",
        "def reset_to_defaults(button):\n",
        "    for key, widget in widgets.items():\n",
        "        widget.value = default_params[key]\n",
        "\n",
        "# Button for resetting to defaults\n",
        "reset_button = Button(\n",
        "    description=\"Reset to Default\",\n",
        "    layout=Layout(width=\"200px\", height=\"40px\")\n",
        ")\n",
        "reset_button.add_class(\"reset-button\")\n",
        "reset_button.on_click(reset_to_defaults)\n",
        "\n",
        "# Main layout\n",
        "form = VBox([architecture_box, data_box, training_box, reset_button])\n",
        "\n",
        "# Display\n",
        "form"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796,
          "referenced_widgets": [
            "321c9fbff141435eb87ccd3fb2305cb9",
            "5579f7b11878432892c55df3437f76fa",
            "610a34df00db44cab1dbbb5badb74b37",
            "13c51325e89c4fe08e1d4b9771773c37",
            "d14faaf4fe274d8fa6308f9c6424054f",
            "f9002c7ac97549a59823a4f24786271b",
            "f831ebb8d76246c38728642797f2b41c",
            "96322ead77754aa48f08bc0d88321850",
            "b1ae35c3e8334e5c925c0a93aef1a7df",
            "3240bd354a774ca49f2ccf7a258c6b19",
            "899a49b56ec147b3b69fca2423cfe01a",
            "db3fb23c3962479784f6409cfe79841d",
            "f3d8fc3a805a4068a12eb3580b9871ba",
            "beea61d5ed244b6da8caf42994fdb4d0",
            "66ddefea6eda4f8e86152e167cf3ac5f",
            "920d2e2edb9742b59d6b76957756a5b6",
            "abae3e36d30f483eabdd8087856fb6f2",
            "1bd700647b754898b52dcfe91374a5c2",
            "ec160d5025e54496ad6a3c00bc16e32a",
            "beca1ae0e2cb43ada7d060b259ab7168",
            "aac2b35531104094b796aec055729f66",
            "702494a910814963b4ad2b2f9bae4475",
            "9f0e5614942f4703b2bcafcd228bc9de",
            "9af7f8520ebf414db174eb9066a30f9d",
            "2c67070ff4d546d48a1a76cf1c102248",
            "2f13511fd85f4694b09cec67cadd0730",
            "d40d11e88df94f13959885f69cc2f369",
            "ffc1282930d642e5a3b40f4286a38faf",
            "a1f1b675ea4445cb8acd71f5b9e0578c",
            "fcdd8f612d104d74a51d38bed3589760",
            "25d4d5f1ff924b2382f85f5e8da69d9c",
            "643672af358747419810383eb2146e6a",
            "9ab257364afe49059f05e4edb8e40e58",
            "cb2e7b6a4bae4ebfa699369f641c7895",
            "055c4c3015ee41caa1c728256ece4c73",
            "644eb319d15b4b7e9668bb099fd0f43f",
            "5207a6c714fa4c8fb2c2366734cec1bf",
            "c7654909bcec4e37b35830428ecf80ac",
            "035985ad328d40b89aa846e1db35f280",
            "6fbd709d6dcc449385417f8dce72ef8a",
            "b92e3c0ba76047e4b08576a8d565f4b2",
            "a8b6a92dc7d94b3ea4f7c66b67d7d5d2",
            "d1274fbe6492467db27a4e0d6b4340f7",
            "54e50409cad14720b6caeb618cee133f",
            "e6ddd3b1ed084aaea32673bc9bfd3d5c",
            "a4f6a905919349e99ea85a79ae5040e1",
            "c5d8cf0b09334bcc8213484dec052951",
            "57d122e3080a4e99ab5ded56f098be21",
            "2e79e0a45ebc4a15a62374f23a75a7be",
            "8580799778774c9bbe5d88d5b7e8986f",
            "7341eecd14c14dacb5b973925f508db4",
            "c3471ea9178344e29a4bea7e204eb06b",
            "e3f366772a0b4ff8912872be24bb0b5b",
            "61c498cbadae43da8e58807ceb8486a9",
            "f6736a1b988a40f2b35eff080a6a16e1",
            "c026d194d7f649e4982885adc04a341f",
            "2294cce4c046466a87dd38543c5ae340",
            "a1974e669c2c480f8222f74dddc1f3dd",
            "56d286fd51574b32972228f18c1ef49a",
            "664c7b15b77b4bc7bcc62e4c330d8769",
            "c6ab6c777b7c4d12a73a2f227918c08b",
            "9eb61d86d7df46678e9b1c091cde1911",
            "479255ddd65e4c74a98bb83c90e79ddc",
            "cabafabec36a4bd0ae075b89dbb844c1",
            "828af1fe6518409eb8a06bfa44d8ac5d",
            "d70646c548c842ca9f568b49e654abab",
            "4b6b79bbcfbb4fdb934476f9b01522e6",
            "66c499e3dac843c49bd3599cda0975ba"
          ]
        },
        "id": "oWwNgGKaooap",
        "outputId": "edc63c16-9bfc-4b28-e831-d194fc97926b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(VBox(children=(HTML(value=\"<b style='font-size:16px;'>Architecture</b>\"), IntSlider(value=2, de…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "321c9fbff141435eb87ccd3fb2305cb9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = {key: widget.value for key, widget in widgets.items()}\n",
        "args[\"num_neighbors\"] = [int(args[\"num_neighbors\"] // 2**i) for i in range(args[\"num_layers\"])]\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TUlVrGizpk3",
        "outputId": "8ba39737-a953-464c-b626-937c8a5f43ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_layers': 2,\n",
              " 'channels': 128,\n",
              " 'aggr': 'sum',\n",
              " 'norm': 'layer_norm',\n",
              " 'time_attr': 'time',\n",
              " 'temporal_strategy': 'uniform',\n",
              " 'batch_size': 512,\n",
              " 'share_same_time': True,\n",
              " 'num_neighbors': [128, 64],\n",
              " 'num_workers': 0,\n",
              " 'use_shallow': True,\n",
              " 'lr': 0.001,\n",
              " 'epochs': 20,\n",
              " 'max_steps_per_epoch': 2000,\n",
              " 'eval_epochs_interval': 1,\n",
              " 'tune_metric': 'link_prediction_map'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loaders"
      ],
      "metadata": {
        "id": "ZE8oGGpl0P8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.modeling.graph import get_link_train_table_input, make_pkey_fkey_graph\n",
        "from relbench.modeling.loader import LinkNeighborLoader\n",
        "\n",
        "\"\"\"\n",
        "Prepare the training table for the link prediction task.\n",
        "\n",
        "This function processes the input table (`train_table`) and task metadata (`task`) to structure the data required for\n",
        "link prediction into a `LinkTrainTableInput` object. It creates a well-defined structure for the source and destination\n",
        "nodes, their relationships, and timestamps if available.\n",
        "\n",
        "Specifically, the function computes the following:\n",
        "\n",
        "1. **Source Nodes (`src_nodes`)**:\n",
        "   - A tuple consisting of:\n",
        "     - The source node type (`task.src_entity_table`), indicating the type of entity for the source nodes.\n",
        "     - A tensor (`src_node_idx`) containing the indices of the source nodes. This tensor is derived from the column\n",
        "       in `table.df` specified by `task.src_entity_col`.\n",
        "\n",
        "   **Example:**\n",
        "   - Suppose `task.src_entity_col = \"customer_id\"` and the table contains:\n",
        "     ```\n",
        "     customer_id  article_id          timestamp\n",
        "     0            [1, 2]   2024-01-01 12:00:00\n",
        "     1            [2, 3]   2024-01-02 12:00:00\n",
        "     2            [1, 3]   2024-01-03 12:00:00\n",
        "     ```\n",
        "   - Then, `src_node_idx` is:\n",
        "     ```\n",
        "     src_node_idx = tensor([0, 1, 2])  # Indices for customers\n",
        "     ```\n",
        "\n",
        "2. **Destination Nodes (`dst_nodes`)**:\n",
        "   - A tuple consisting of:\n",
        "     - The destination node type (`task.dst_entity_table`), indicating the type of entity for the destination nodes.\n",
        "     - A sparse CSR (Compressed Sparse Row) matrix (`dst_node_indices`) representing the links between source nodes\n",
        "       and destination nodes. Each row corresponds to a source node, and non-zero entries in a row indicate linked\n",
        "       destination nodes.\n",
        "\n",
        "   **Example:**\n",
        "   - Suppose `task.dst_entity_col = \"article_id\"` and the table contains the same data as above:\n",
        "     ```\n",
        "     customer_id  article_id          timestamp\n",
        "     0            [1, 2]   2024-01-01 12:00:00\n",
        "     1            [2, 3]   2024-01-02 12:00:00\n",
        "     2            [1, 3]   2024-01-03 12:00:00\n",
        "     ```\n",
        "   - After flattening and converting to COO and then CSR:\n",
        "     ```\n",
        "     COO Representation:\n",
        "     Row (source): [0, 0, 1, 1, 2, 2]\n",
        "     Col (dest):   [1, 2, 2, 3, 1, 3]\n",
        "\n",
        "     CSR Representation:\n",
        "     dst_node_indices =\n",
        "       (row pointers) [0, 2, 4, 6]  # Indices where rows start and end\n",
        "       (column indices) [1, 2, 2, 3, 1, 3]  # Linked destination nodes\n",
        "     ```\n",
        "\n",
        "3. **Number of Destination Nodes (`num_dst_nodes`)**:\n",
        "   - The total number of unique destination nodes (e.g., all articles in a recommendation system).\n",
        "   - In the above example, `num_dst_nodes = 4` (article IDs: 1, 2, 3).\n",
        "\n",
        "4. **Source Timestamps (`src_time`)**:\n",
        "   - Temporal information associated with the source nodes.\n",
        "   - Converted to Unix time:\n",
        "     ```\n",
        "     src_time = tensor([1704110400, 1704196800, 1704283200])  # Unix timestamps\n",
        "     ```\n",
        "\n",
        "This structured input enables efficient neighbor sampling and subgraph preparation for training link prediction models.\n",
        "\"\"\"\n",
        "table_input = get_link_train_table_input(\n",
        "    table=train_table,\n",
        "    task=task,\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Create a data loader for training the link prediction model using neighbor sampling.\n",
        "\n",
        "The `LinkNeighborLoader` is a custom data loader designed for temporal heterogeneous graphs, specifically for link prediction tasks.\n",
        "It samples subgraphs containing the neighbors of source and destination nodes while adhering to temporal and structural constraints.\n",
        "The key arguments are:\n",
        "\n",
        "1. **Graph Data (`data`)**:\n",
        "   - The input graph, a `HeteroData` object, containing node types, edge types, features, and timestamps.\n",
        "\n",
        "2. **Number of Neighbors (`num_neighbors`)**:\n",
        "   - Defines the maximum number of neighbors to sample at each GNN layer.\n",
        "   - Can be specified globally as a list (e.g., `[10, 5]` for two layers) or per edge type as a dictionary.\n",
        "\n",
        "3. **Temporal Attribute (`time_attr`)**:\n",
        "   - Specifies the column in `data` that contains timestamp information.\n",
        "   - Used for temporal neighbor sampling to ensure only past or relevant neighbors are included, avoiding time leakage.\n",
        "\n",
        "4. **Source Nodes (`src_nodes`)**:\n",
        "5. **Destination Nodes (`dst_nodes`)**:\n",
        "6. **Number of Destination Nodes (`num_dst_nodes`)**:\n",
        "7. **Source Timestamps (`src_time`)**:\n",
        "   - From the previous function.\n",
        "\n",
        "8. **Shared Time Context (`share_same_time`)**:\n",
        "   - If `True`, ensures all nodes in a mini-batch share the same seed time, enabling uniform temporal context for predictions.\n",
        "   - If enabled, `shuffle` is automatically set to `False` since shuffling disrupts the timestamp alignment.\n",
        "\n",
        "9. **Batch Size (`batch_size`)**:\n",
        "   - The number of source-destination node pairs to process per mini-batch.\n",
        "\n",
        "10. **Temporal Strategy (`temporal_strategy`)**:\n",
        "    - Specifies the method for temporal neighbor sampling:\n",
        "      - `\"uniform\"`: Uniform sampling of neighbors constrained by temporal validity.\n",
        "      - Other strategies may emphasize different temporal patterns.\n",
        "\n",
        "11. **Shuffle (`shuffle`)**:\n",
        "    - Controls whether the input node pairs are shuffled. If `share_same_time=True`, shuffling must be disabled to\n",
        "      maintain temporal alignment.\n",
        "\n",
        "12. **Number of Workers (`num_workers`)**:\n",
        "    - Specifies the number of workers for parallel data loading. Increasing this value can improve performance\n",
        "      for large graphs, but requires careful resource management.\n",
        "\n",
        "**Purpose**:\n",
        "This loader dynamically samples the subgraphs needed for each training batch, incorporating structural and temporal\n",
        "constraints. It ensures scalability for large graphs by limiting the neighborhood size and focusing on the nodes\n",
        "relevant for each source-destination pair.\n",
        "\n",
        "**Output**:\n",
        "Each batch from the loader includes:\n",
        "- Source subgraph (pre-computed sampled neighborhood of source nodes in the batch, to use during message-passing).\n",
        "- Positive destination subgraph (sampled neighborhoods for positively linked destination nodes).\n",
        "- Negative destination subgraph (sampled neighborhoods for unlinked destination nodes).\n",
        "\"\"\"\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data,  # Input graph data\n",
        "    num_neighbors=args[\"num_neighbors\"],  # Number of neighbors to sample per layer\n",
        "    time_attr=args[\"time_attr\"],  # Timestamp column for temporal sampling\n",
        "    src_nodes=table_input.src_nodes,  # Source nodes (type and indices)\n",
        "    dst_nodes=table_input.dst_nodes,  # Destination nodes (type and sparse CSR matrix)\n",
        "    num_dst_nodes=table_input.num_dst_nodes,  # Total number of destination nodes\n",
        "    src_time=table_input.src_time,  # Source node timestamps\n",
        "    share_same_time=args[\"share_same_time\"],  # Shared temporal context within a batch\n",
        "    batch_size=args[\"batch_size\"],  # Number of source-destination pairs per batch\n",
        "    temporal_strategy=args[\"temporal_strategy\"],  # Temporal sampling strategy\n",
        "    shuffle=not args[\"share_same_time\"],  # Shuffle only if shared time is disabled\n",
        "    num_workers=args[\"num_workers\"],  # Number of parallel workers for data loading\n",
        ")"
      ],
      "metadata": {
        "id": "_MUsPB1l5yMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d9487a-72fb-479d-82dd-aff289d322b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Database object from /root/.cache/relbench/rel-hm/db...\n",
            "Done in 1.39 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/relbench/modeling/graph.py:217: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  dst_node_indices = sparse_coo.to_sparse_csr()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🧸 TOY EXAMPLE FOR BETTER UNDERSTANDING**\n",
        "\n",
        "\n",
        "```\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "\n",
        "# Create a sample heterogeneous graph:\n",
        "data = HeteroData()\n",
        "data['customer'].x = torch.randn(5, 16)  # 5 customers, 16 features\n",
        "data['article'].x = torch.randn(6, 16)  # 6 articles, 16 features\n",
        "data['customer', 'buys', 'article'].edge_index = torch.tensor(\n",
        "    [[0, 1, 2, 3],  # Source nodes\n",
        "     [1, 2, 0, 4]]  # Destination nodes\n",
        ")\n",
        "\n",
        "# Add temporal attributes:\n",
        "data['customer', 'buys', 'article'].time = torch.tensor([100, 200, 300, 400])\n",
        "\n",
        "# Initialize the loader:\n",
        "loader = LinkNeighborLoader(\n",
        "    data=data,\n",
        "    num_neighbors=[2, 1],  # Sample 2 neighbors at layer 1, 1 neighbor at layer 2\n",
        "    src_nodes=(\"customer\", torch.tensor([0, 1, 2])),\n",
        "    dst_nodes=(\"article\", torch.tensor([0, 1, 2, 3])),\n",
        "    num_dst_nodes=6,  # Total number of articles\n",
        "    src_time=torch.tensor([100, 200, 300]),\n",
        "    batch_size=2,\n",
        "    time_attr=\"time\",\n",
        "    temporal_strategy=\"uniform\",\n",
        "    share_same_time=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "```\n",
        "\n",
        "$↓$\n",
        "\n",
        "```\n",
        "Source Subgraph:\n",
        "HeteroData(\n",
        "  customer={\n",
        "    x=[2, 16], edge_index=[2, 4], time=[4]\n",
        "  }\n",
        ")\n",
        "\n",
        "Positive Destination Subgraph:\n",
        "HeteroData(\n",
        "  article={\n",
        "    x=[2, 16], edge_index=[2, 2], time=[2]\n",
        "  }\n",
        ")\n",
        "\n",
        "Negative Destination Subgraph:\n",
        "HeteroData(\n",
        "  article={\n",
        "    x=[2, 16], edge_index=[2, 2], time=[2]\n",
        "  }\n",
        ")\n",
        "```\n",
        "\n",
        "Source Subgraph: Contains 2 sampled source nodes (customer) with their features, neighbors, and timestamps.\n",
        "- **For each source node in a batch, we have ONE positive node and ONE negative node.**"
      ],
      "metadata": {
        "id": "ao0Z6QlmYiT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Tuple\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "\"\"\"\n",
        "Prepare evaluation data loaders for validation and testing using `NeighborLoader`.\n",
        "\n",
        "Key Details:\n",
        "- Temporal Consistency:\n",
        "  - Both loaders are initialized with `seed_time` to ensure all sampled neighbors respect the evaluation timestamp,\n",
        "    avoiding future data leakage during validation and testing.\n",
        "- Source vs. Destination Loaders:\n",
        "  - The source loader processes the nodes for which predictions are made.\n",
        "  - The destination loader processes the target (gold) nodes in the link prediction task.\n",
        "- Output:\n",
        "  - For each split (`val`, `test`), two loaders (`src_loader` and `dst_loader`) are available for evaluation tasks.\n",
        "\"\"\"\n",
        "eval_loaders_dict: Dict[str, Tuple[NeighborLoader, NeighborLoader]] = {}\n",
        "for split in [\"val\", \"test\"]:\n",
        "\n",
        "    # 1. Get the timestamp for the evaluation split\n",
        "    timestamp = dataset.val_timestamp if split == \"val\" else dataset.test_timestamp\n",
        "    seed_time = int(timestamp.timestamp())  # Convert to Unix time\n",
        "\n",
        "    # 2. Retrieve the target table and source node indices\n",
        "    target_table = task.get_table(split)\n",
        "    src_node_indices = torch.from_numpy(target_table.df[task.src_entity_col].values)\n",
        "\n",
        "    # 3. Create the source node loader\n",
        "    src_loader = NeighborLoader(\n",
        "        data,  # Graph data\n",
        "        num_neighbors=args[\"num_neighbors\"],  # Number of neighbors to sample per layer\n",
        "        time_attr=args[\"time_attr\"],  # Temporal attribute for neighbor sampling\n",
        "        input_nodes=(task.src_entity_table, src_node_indices),  # Source node type and indices\n",
        "        input_time=torch.full(  # Seed time tensor for all source nodes\n",
        "            size=(len(src_node_indices),), fill_value=seed_time, dtype=torch.long\n",
        "        ),\n",
        "        batch_size=args[\"batch_size\"],  # Batch size for source nodes\n",
        "        shuffle=not args[\"share_same_time\"],  # Disable shuffle if shared time is enforced\n",
        "        num_workers=args[\"num_workers\"],  # Parallel workers for loading\n",
        "    )\n",
        "\n",
        "    # 4. Create the destination node loader\n",
        "    dst_loader = NeighborLoader(\n",
        "        data,  # Graph data\n",
        "        num_neighbors=args[\"num_neighbors\"],  # Number of neighbors to sample per layer\n",
        "        time_attr=args[\"time_attr\"],  # Temporal attribute for neighbor sampling\n",
        "        input_nodes=task.dst_entity_table,  # Destination node type\n",
        "        input_time=torch.full(  # Seed time tensor for all destination nodes\n",
        "            size=(task.num_dst_nodes,), fill_value=seed_time, dtype=torch.long\n",
        "        ),\n",
        "        batch_size=args[\"batch_size\"],  # Batch size for destination nodes\n",
        "        shuffle=not args[\"share_same_time\"],  # Disable shuffle if shared time is enforced\n",
        "        num_workers=args[\"num_workers\"],  # Parallel workers for loading\n",
        "    )\n",
        "\n",
        "    # 5. Store loaders in the dictionary for the current split\n",
        "    eval_loaders_dict[split] = (src_loader, dst_loader)"
      ],
      "metadata": {
        "id": "J25i5Hp4bSmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the Model, Train and Evaluate"
      ],
      "metadata": {
        "id": "PkYo7BNW1Q5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model for link prediction\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=args[\"num_layers\"],\n",
        "    channels=args[\"channels\"],\n",
        "    out_channels=1,  # A single scalar indicating the likelihood of the customer interacting with the article\n",
        "    aggr=args[\"aggr\"],\n",
        "    norm=args[\"norm\"],\n",
        "    shallow_list=[task.dst_entity_table] if args[\"use_shallow\"] else [],\n",
        ").to(device)\n",
        "\n",
        "# Initialize the optimizer for training\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args[\"lr\"])"
      ],
      "metadata": {
        "id": "4T9VGqlkcIi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We utilize the standard **Bayesian Personalized Ranking loss (w/ mini-batches, one negative only)** for training."
      ],
      "metadata": {
        "id": "18YUl-Zu5rjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train() -> float:\n",
        "    \"\"\"\n",
        "    Train the model for one epoch using Bayesian Personalized Ranking (BPR) loss.\n",
        "\n",
        "    The function iterates over the training data, computes positive and negative scores for link prediction,\n",
        "    and updates the model parameters using gradient descent. The BPR loss encourages the model to assign\n",
        "    higher scores to positive links than to negative links.\n",
        "\n",
        "    Returns:\n",
        "        float: The average training loss for the epoch.\n",
        "    \"\"\"\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    # Initialize accumulators for loss and count\n",
        "    loss_accum = count_accum = 0\n",
        "    steps = 0\n",
        "\n",
        "    # Determine the maximum number of training steps\n",
        "    total_steps = min(len(train_loader), args[\"max_steps_per_epoch\"])\n",
        "\n",
        "    for batch in tqdm(train_loader, total=total_steps):  # Iterate through batches with progress bar\n",
        "\n",
        "        # Unpack the batch into source, positive destination, and negative destination\n",
        "        src_batch, batch_pos_dst, batch_neg_dst = batch\n",
        "        src_batch, batch_pos_dst, batch_neg_dst = (\n",
        "            src_batch.to(device),\n",
        "            batch_pos_dst.to(device),\n",
        "            batch_neg_dst.to(device),\n",
        "        )\n",
        "\n",
        "        # Compute embeddings for source, positive, and negative destination nodes\n",
        "        x_src = model(src_batch, task.src_entity_table)  # Source embeddings\n",
        "        x_pos_dst = model(batch_pos_dst, task.dst_entity_table)  # Positive destination embeddings\n",
        "        x_neg_dst = model(batch_neg_dst, task.dst_entity_table)  # Negative destination embeddings\n",
        "\n",
        "        # Compute positive scores (dot product between source and positive destination embeddings)\n",
        "        pos_score = torch.sum(x_src * x_pos_dst, dim=1)  # [batch_size]\n",
        "\n",
        "        if args[\"share_same_time\"]:\n",
        "            # Compute negative scores as a matrix product for the shared time context\n",
        "            neg_score = x_src @ x_neg_dst.t()  # [batch_size, batch_size]\n",
        "            pos_score = pos_score.view(-1, 1)  # Reshape positive scores to [batch_size, 1]\n",
        "        else:\n",
        "            # Compute negative scores as a dot product for individual pairs\n",
        "            neg_score = torch.sum(x_src * x_neg_dst, dim=1)  # [batch_size]\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "\n",
        "        # Compute the Bayesian Personalized Ranking (BPR) loss\n",
        "        diff_score = pos_score - neg_score  # Difference between positive and negative scores\n",
        "        loss = F.softplus(-diff_score).mean()  # BPR loss with softplus activation\n",
        "        loss.backward()  # Backpropagate gradients\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        # Accumulate the loss and count\n",
        "        loss_accum += float(loss) * x_src.size(0)  # Weighted by batch size\n",
        "        count_accum += x_src.size(0)  # Count the number of samples\n",
        "\n",
        "        steps += 1\n",
        "        if steps > args[\"max_steps_per_epoch\"]:  # Stop if max steps reached\n",
        "            break\n",
        "\n",
        "    # Warn if no valid destination nodes were sampled\n",
        "    if count_accum == 0:\n",
        "        warnings.warn(\n",
        "            f\"Did not sample a single '{task.dst_entity_table}' \"\n",
        "            f\"node in any mini-batch. Try to increase the number \"\n",
        "            f\"of layers/hops and re-try. If you run into memory \"\n",
        "            f\"issues with deeper nets, decrease the batch size.\"\n",
        "        )\n",
        "\n",
        "    # Return the average loss for the epoch\n",
        "    return loss_accum / count_accum if count_accum > 0 else float(\"nan\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(src_loader: NeighborLoader, dst_loader: NeighborLoader) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Evaluate the model on a validation or test set using top-k predictions.\n",
        "\n",
        "    The function computes embeddings for all destination nodes, then evaluates the top-k predicted links\n",
        "    for each source node based on dot-product similarity between embeddings.\n",
        "\n",
        "    Args:\n",
        "        src_loader (NeighborLoader): Data loader for source nodes.\n",
        "        dst_loader (NeighborLoader): Data loader for destination nodes.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: An array of indices corresponding to the top-k predicted destination nodes\n",
        "                    for each source node.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    dst_embs: list[Tensor] = []  # List to accumulate destination node embeddings\n",
        "\n",
        "    # Compute embeddings for all destination nodes\n",
        "    for batch in tqdm(dst_loader):  # Iterate through the destination loader with a progress bar\n",
        "        batch = batch.to(device)\n",
        "        emb = model(batch, task.dst_entity_table).detach()  # Compute and detach embeddings\n",
        "        dst_embs.append(emb)\n",
        "    dst_emb = torch.cat(dst_embs, dim=0)  # Concatenate all destination embeddings\n",
        "    del dst_embs  # Free memory\n",
        "\n",
        "    pred_index_mat_list: list[Tensor] = []  # List to accumulate top-k indices\n",
        "\n",
        "    # Compute top-k predictions for source nodes\n",
        "    for batch in tqdm(src_loader):  # Iterate through the source loader\n",
        "        batch = batch.to(device)\n",
        "        emb = model(batch, task.src_entity_table)  # Compute source node embeddings\n",
        "        # Compute dot-product similarity and retrieve top-k predictions\n",
        "        _, pred_index_mat = torch.topk(emb @ dst_emb.t(), k=task.eval_k, dim=1)\n",
        "        pred_index_mat_list.append(pred_index_mat.cpu())  # Move indices to CPU and store them\n",
        "\n",
        "    # Concatenate all top-k predictions and convert to NumPy\n",
        "    pred = torch.cat(pred_index_mat_list, dim=0).numpy()\n",
        "    return pred  # Return the array of top-k predictions"
      ],
      "metadata": {
        "id": "LESG81Voc97K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To recap, our task is to predict a list of top $K$ target entities given a source entity at a given seed time. The metric we use is **Mean Average Precision (MAP) @ $K$**.\n",
        "\n",
        "MAP is a commonly used evaluation metric in recommender systems, particularly for ranking-based tasks like item recommendations or link prediction. It measures the quality of the ordered list of recommended items by **considering both relevance and the ranking position of relevant items**.\n",
        "\n",
        "Key concepts:\n",
        "\n",
        "* **Precision:** Precision at a given position $i$ in the ranked list is the proportion of relevant items in the top-$i$ recommendations:\n",
        "$\\text{Precision}@k=\\frac{\\text{Number of relevant items in top-k}}{k}$\n",
        "* **Average Precision (AP):** For a single user, AP computes the average of precision values at all positions where a relevant item is found:\n",
        "$\\text{AP}@k=\\frac{\\sum_{i=1}^n\\text{Precision}@i \\cdot \\text{relevance}(i)}{\\text{Total number of relevant items in the top-}k}$. Here, $\\text{relevance}(i)=1$ if the item at position $i$ is relevant, 0 otherwise.\n",
        "* **Mean Average Precision (MAP):** MAP aggregates the AP values over all users and computes the mean: $\\text{MAP}=\\frac{1}{|U|}\\sum_{u \\in U}\\text{AP}_u$. Here, $U$ is the set of all users, and $\\text{AP}_u$ is the Average Precision for user $u$.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1KZtjMvjcBugLB-CijLR59ynqClXYBAOx\" width=\"550\">\n",
        "\n",
        "The boundary of the MAP output is **between 0 and 1, inclusive (the higher the better)**.\n",
        "* $\\text{MAP}=1$. Every relevant item for each user is included in the recommendation list, and all relevant items are ranked at the top.\n",
        "* $\\text{MAP}=0$. No relevant items are present in the recommendation lists for any user.\n",
        "* A low MAP value (e.g., 0.2) means the system struggles to rank relevant items effectively, often placing them lower in the recommendation list or not recommending them at all.\n",
        "\n",
        "In RELBENCH, the value of $K$ is set per task.\n",
        "Ours, `UserItemPurchaseTask` has **$K=12$** [[Source](https://github.com/snap-stanford/relbench/blob/6bcb12a94b163c52e01cc272dfd4817cd13eff69/relbench/tasks/hm.py#L19)]."
      ],
      "metadata": {
        "id": "1AC5UTgSbFe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK THE VALUE OF K THAT WILL BE USED FOR MAP EVALUATION\n",
        "task.eval_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu1ZLyBBcFVC",
        "outputId": "3bb9229f-e50c-463c-c580-062dfdddf1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEFORE TRAINING\n",
        "import json\n",
        "test_pred = test(*eval_loaders_dict[\"test\"])\n",
        "test_metrics = task.evaluate(test_pred, target_table=test_table)\n",
        "print(f\"Best test metrics: \\n{json.dumps(test_metrics, indent=2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSfEUmt0TbpM",
        "outputId": "92bedbf8-e9e4-4847-d326-f6b235b12b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 207/207 [00:09<00:00, 22.24it/s]\n",
            "100%|██████████| 132/132 [00:06<00:00, 19.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best test metrics: \n",
            "{\n",
            "  \"link_prediction_precision\": 1.2411136264347273e-06,\n",
            "  \"link_prediction_recall\": 4.964454505738909e-06,\n",
            "  \"link_prediction_map\": 6.205568132173637e-07\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🕒 *Training requires $\\approx$13 minutes per epoch.*"
      ],
      "metadata": {
        "id": "g6cLVjLCdzJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import gdown\n",
        "\n",
        "load_pretrained = False\n",
        "\n",
        "if load_pretrained:\n",
        "\n",
        "    # The model has been pretrained with default hyperparameters\n",
        "    # Ensure the model is compatible before loading the checkpoint\n",
        "    checkpoint_url = \"https://drive.google.com/uc?id=16b6z77S-p9LNAOV9PL-19ICfK-VaosJn\"\n",
        "    gdown.download(checkpoint_url, \"./relbench_hm_graphsage_checkpoint.pt\", quiet=False)\n",
        "    state_dict = torch.load(\"./relbench_hm_graphsage_checkpoint.pt\")\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "else:\n",
        "\n",
        "    state_dict = None\n",
        "    best_val_metric = 0\n",
        "    for epoch in range(1, args[\"epochs\"] + 1):\n",
        "        train_loss = train()\n",
        "        if epoch % args[\"eval_epochs_interval\"] == 0:\n",
        "            val_pred = test(*eval_loaders_dict[\"val\"])\n",
        "            val_metrics = task.evaluate(val_pred, target_table=val_table)\n",
        "            print(\n",
        "                f\"Epoch: {epoch:02d}, Train loss: {train_loss}, \"\n",
        "                f\"Val metrics: \\n{json.dumps(val_metrics, indent=2)}\"\n",
        "            )\n",
        "            if val_metrics[args[\"tune_metric\"]] >= best_val_metric:\n",
        "                best_val_metric = val_metrics[args[\"tune_metric\"]]\n",
        "                state_dict = copy.deepcopy(model.state_dict())\n",
        "    model.load_state_dict(state_dict)\n",
        "    # Save the checkpoint\n",
        "    torch.save(state_dict, \"/content/relbench_hm_gnn.pt\")\n",
        "\n",
        "val_pred = test(*eval_loaders_dict[\"val\"])\n",
        "val_metrics = task.evaluate(val_pred, target_table=val_table)\n",
        "print(f\"Best Val metrics: {val_metrics}\")"
      ],
      "metadata": {
        "id": "JuJMKhXz1peb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch: 01, Train loss: 0.1087472868700703, Val metrics:\n",
        "{'link_prediction_precision': 0.005003911051514135, 'link_prediction_recall': 0.01959143846237254, 'link_prediction_map': 0.005726242268206763}\n",
        "\n",
        "Epoch: 02, Train loss: 0.08682966694935806, Val metrics:\n",
        "{'link_prediction_precision': 0.0056833165716839865, 'link_prediction_recall': 0.023962679731169785, 'link_prediction_map': 0.007834079957611971}\n",
        "\n",
        "Epoch: 03, Train loss: 0.08096918152242169, Val metrics:\n",
        "{'link_prediction_precision': 0.005184936864454128, 'link_prediction_recall': 0.021360978176741836, 'link_prediction_map': 0.007129379139913946}\n",
        "\n",
        "Epoch: 04, Train loss: 0.0776181455900793, Val metrics:\n",
        "{'link_prediction_precision': 0.0059079226729243485, 'link_prediction_recall': 0.02450972418118223, 'link_prediction_map': 0.00784053437725389}\n",
        "\n",
        "Epoch: 05, Train loss: 0.07522295702663974, Val metrics:\n",
        "{'link_prediction_precision': 0.005837523745669906, 'link_prediction_recall': 0.025018195532812256, 'link_prediction_map': 0.0077185426961791734}\n",
        "\n",
        "Epoch: 06, Train loss: 0.07302185772978205, Val metrics:\n",
        "{'link_prediction_precision': 0.006036428651245948, 'link_prediction_recall': 0.025450903598061386, 'link_prediction_map': 0.007799122365245512}\n",
        "\n",
        "Epoch: 07, Train loss: 0.07127932919704098, Val metrics:\n",
        "{'link_prediction_precision': 0.00608112638283607, 'link_prediction_recall': 0.025176688056008544, 'link_prediction_map': 0.0077879343088768285}\n",
        "\n",
        "Epoch: 08, Train loss: 0.06931001383779586, Val metrics:\n",
        "{'link_prediction_precision': 0.006159347413118783, 'link_prediction_recall': 0.025842584524293773, 'link_prediction_map': 0.00799117079994164}\n",
        "\n",
        "Epoch: 09, Train loss: 0.0682670115169765, Val metrics:\n",
        "{'link_prediction_precision': 0.006333668566320258, 'link_prediction_recall': 0.02689625655466527, 'link_prediction_map': 0.008352073392629328}\n",
        "\n",
        "Epoch: 10, Train loss: 0.06654648913227874, Val metrics:\n",
        "{'link_prediction_precision': 0.006262152195776064, 'link_prediction_recall': 0.026929272878504707, 'link_prediction_map': 0.00853130592736636}\n",
        "\n",
        "Epoch: 11, Train loss: 0.06582279922603548, Val metrics:\n",
        "{'link_prediction_precision': 0.006080008939546317, 'link_prediction_recall': 0.02601899683266872, 'link_prediction_map': 0.00820869170336041}\n",
        "\n",
        "Epoch: 12, Train loss: 0.06526682509490099, Val metrics:\n",
        "{'link_prediction_precision': 0.006180578835624091, 'link_prediction_recall': 0.02633966436163992, 'link_prediction_map': 0.008524656209741353}\n",
        "\n",
        "Epoch: 13, Train loss: 0.06395177540836157, Val metrics:\n",
        "{'link_prediction_precision': 0.006586210749804446, 'link_prediction_recall': 0.027832192113045016, 'link_prediction_map': 0.009010682303600543}\n",
        "\n",
        "Epoch: 14, Train loss: 0.06328508630022593, Val metrics:\n",
        "{'link_prediction_precision': 0.006080008939546318, 'link_prediction_recall': 0.026080306645656606, 'link_prediction_map': 0.008498832402539992}\n",
        "\n",
        "Epoch: 15, Train loss: 0.06332891656440505, Val metrics:\n",
        "{'link_prediction_precision': 0.006514694379260252, 'link_prediction_recall': 0.028010604181663984, 'link_prediction_map': 0.008871537800073928}\n",
        "\n",
        "Epoch: 16, Train loss: 0.06318439393751565, Val metrics:\n",
        "{'link_prediction_precision': 0.0065649793272991395, 'link_prediction_recall': 0.02800220728207887, 'link_prediction_map': 0.009205209084666452}\n",
        "\n",
        "Epoch: 17, Train loss: 0.06196682529895381, Val metrics:\n",
        "{'link_prediction_precision': 0.006614146832048273, 'link_prediction_recall': 0.02863960764112953, 'link_prediction_map': 0.008910399061920309}\n",
        "\n",
        "Epoch: 18, Train loss: 0.06157738820224747, Val metrics:\n",
        "{'link_prediction_precision': 0.0063873058442284044, 'link_prediction_recall': 0.027685218907965155, 'link_prediction_map': 0.008744753840983485}\n",
        "\n",
        "Epoch: 19, Train loss: 0.061020472694350326, Val metrics:\n",
        "{'link_prediction_precision': 0.006463291987931612, 'link_prediction_recall': 0.027365864870720256, 'link_prediction_map': 0.008493917513842326}\n",
        "\n",
        "Epoch: 20, Train loss: 0.06088389920769841, Val metrics:\n",
        "{'link_prediction_precision': 0.006218571907475695, 'link_prediction_recall': 0.02645116573418713, 'link_prediction_map': 0.00831022733622273}\n",
        "\n",
        "**Best Val metrics: {'link_prediction_precision': 0.006602972399150742, 'link_prediction_recall': 0.028296511136977648, 'link_prediction_map': 0.009285367460726964}**\n",
        "\n",
        "**Best test metrics: {'link_prediction_precision': 0.005721533817864092, 'link_prediction_recall': 0.025377126447581024, 'link_prediction_map': 0.008338150296773754}**"
      ],
      "metadata": {
        "id": "RkT4mug0qoGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AFTER TRAINING\n",
        "import json\n",
        "test_pred = test(*eval_loaders_dict[\"test\"])\n",
        "test_metrics = task.evaluate(test_pred, target_table=test_table)\n",
        "print(f\"Best test metrics: \\n{json.dumps(test_metrics, indent=2)}\")"
      ],
      "metadata": {
        "id": "i4HeL1HnTp0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚔️ Baselines"
      ],
      "metadata": {
        "id": "SfJ9lYTIUNfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RELBENCH baseline description:\n",
        "\n",
        "> Despite the importance of relational databases, the rich relational information is typically foregone, as no model architecture is capable of handling varied database structures. Instead, **data is \"flattened\" into a simpler format such as a single table**, often by manual feature engineering, **on which standard tabular models can be used**.\n",
        "\n"
      ],
      "metadata": {
        "id": "clJ9o5zlHCne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient-Boosted Trees Recap"
      ],
      "metadata": {
        "id": "zIIu2A_wI-s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient boosting is one of the most popular machine learning algorithms for tabular datasets. It is powerful enough to find any non-linear relationship between your model target and features.\n",
        "\n",
        "Gradient boosting is one of the variants of ensemble methods where **you create multiple weak models and combine them to get better performance as a whole**.\n",
        "\n",
        "Let's suppose to have a non-linear relationship between a feature $x$ and a target $y$.\n",
        "\n",
        "* *Iteration 0*. A first, very naive predictor ($F_0$) could be the overall average of $y$.\n",
        "* *Iteration 1*.\n",
        "  * To improve our prediction, we could focus on the **residuals** (i.e., prediction errors shown as vertical blue lines in the figure below) from the first step because this is what we want **to minimize** to get a better prediction.\n",
        "  * To minimize these residuals, we can build a **regression tree model** with $x$ as its feature and the residuals $r_1 = y - mean(y)$ as its target. For example:\n",
        "\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1DP0RY32Kk7ezc7s5-o9AKmnvpxXrFsJA\" width=\"550\">\n",
        "\n",
        "  * The outputs of the first predictor are thereby corrected in sum with those from the second predictor to reduce the residuals, i.e., $F_1 = F_0 + \\gamma_1$.\n",
        "* ...\n",
        "\n",
        "By repeating this process, the combined prediction $F_m$ is getting more closer to the target $y$.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1avR1wH3W7l7qA5HnMux0VY522WcFVrX9\" width=\"650\">\n",
        "\n",
        "In summary, in the gradient-boosted trees algorithm, we iterate the following:\n",
        "* We train a tree on the errors made at the previous iteration.\n",
        "* We add the tree to the ensemble, and we predict with the new model.\n",
        "* We compute the errors made for this iteration.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1PzE_lgfwm3xQ6R8reSdAgoT0Qwla8_8j\" width=\"650\">\n",
        "\n",
        "Typically, to prevent overfitting, we use the method of shrinkage. We multiply the contribution of the new tree by a small factor such that the new tree does not bring too much impact on the overall prediction.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Pc-xGUsD3u6bDC8WFwnVK43GJXTTwvwq\" width=\"650\">\n",
        "\n",
        "[[Source 1](https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502), [Source 2](https://newsletter.theaiedge.io/p/gbm-vs-xgboost-vs-lightgbm-vs-catboost)]"
      ],
      "metadata": {
        "id": "cLw0O_pfJPc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both **XGBoost** (Extreme Gradient Boosting) and **LightGBM** (Light Gradient Boosting Machine) are advanced implementations of the gradient boosting framework and are particularly well-suited for modeling on structured tabular data. These algorithms build upon the foundation of gradient boosting, aiming to address its limitations while improving efficiency, scalability, and accuracy. Here's a detailed look at how they work and differ, especially in the context of making recommendations on single-table datasets."
      ],
      "metadata": {
        "id": "B4eHqxeihYvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Single-Table Data Formalism"
      ],
      "metadata": {
        "id": "y3q9UhaTBlR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tabular machine learning models, particularly those using methods like tree-based learning or feature aggregation, require data to be represented in a **flat**, single-table format. Relational databases, however, store data in normalized tables to reduce redundancy and optimize storage. Transforming relational data into a single table for machine learning requires **careful preprocessing** to preserve as much of the relational structure and information as possible.\n",
        "\n",
        "The standard method of flattening relational data involves joining tables and engineering features to combine relevant information into a unified table. However, this process is often **computationally expensive** and risks **losing valuable predictive signals**. Flattening discards latent correlations and complex relationships between entities, which are essential for accurately capturing interactions in many predictive tasks."
      ],
      "metadata": {
        "id": "z0oty-pTBv13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Core Preprocessing Operations**\n",
        "\n",
        "The preprocessing phase of the `rel-hm` dataset for the link prediction task `user-item-purchase` involves a series of structured operations that transform relational data into a feature-rich table suitable for training and evaluating machine learning models. The key steps include:\n",
        "\n",
        "1. **Entity Table Link**:\n",
        "   - Data from related entity tables is merged with the interaction table. Specifically, entries with users' information and the characteristics of the purchased items connected.\n",
        "\n",
        "2. **Feature Engineering**:\n",
        "   - **Historical Context**: Features that capture past interaction patterns, such as the frequency of interactions between specific entities, are computed. These features provide insights into recurring behaviors and relationships.\n",
        "   - **Global Popularity**: Metrics that quantify the overall popularity or importance of selling articles across the dataset are calculated. These metrics reflect trends and preferences within the data.\n",
        "\n",
        "3. **Negative Sampling**:\n",
        "   - Negative examples are generated by randomly pairing users with articles they never bought. These synthetic samples are essential for training the model to differentiate between meaningful and random associations.\n",
        "\n",
        "\n",
        "> ‼️ **NOTE**: In addition to modifying the data handling paradigm, the following models and experiments utilize tables that have been enhanced with two additional features:\n",
        "- `global_popularity_fraction` ( $\\forall \\; \\text{item}$ ): The ratio of the number of items sold to the total number of sales.\n",
        "- `num_past_visits` ( $\\forall \\; \\langle \\text{user}, \\text{item}\\rangle$ ): The total number of times each user has visited a specific item."
      ],
      "metadata": {
        "id": "qgbjHPxECAKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Libraries\n",
        "\n",
        "%%capture\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install torch-geometric torch-sparse torch-scatter torch-cluster torch-spline-conv pyg-lib -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install relbench[full]\n",
        "\n",
        "\n",
        "!pip install lightgbm\\\n",
        "             xgboost \\\n",
        "             optuna_integration \\\n",
        "             dask[dataframe]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3Qm9U4F0s2Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download data\n",
        "\n",
        "print(\"Importing libraries...\")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import json\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, NamedTuple, Optional, Tuple, Union\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer # Assuming this was previously imported\n",
        "from torch import Tensor\n",
        "\n",
        "import torch_frame\n",
        "from torch_frame import stype\n",
        "from torch_frame.config import TextEmbedderConfig\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig as TextEmbedderConfig2 # Renamed to avoid conflict\n",
        "from torch_frame.data import Dataset as TorchFrameDataset\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.seed import seed_everything\n",
        "from torch_geometric.typing import NodeType\n",
        "from torch_geometric.utils import sort_edge_index\n",
        "from torch_geometric.utils.cross_entropy import sparse_cross_entropy\n",
        "from tqdm import tqdm\n",
        "\n",
        "from relbench.base import Database, EntityTask, RecommendationTask, Table, TaskType, Dataset\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.modeling.graph import get_link_train_table_input\n",
        "from relbench.modeling.loader import SparseTensor\n",
        "from relbench.modeling.utils import get_stype_proposal, remove_pkey_fkey, to_unix_time\n",
        "from relbench.tasks import get_task\n",
        "\n",
        "\n",
        "from typing import List, Optional\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "LINK_PRED_BASELINE_TARGET_COL_NAME = \"link_pred_baseline_target_column_name\"\n",
        "PRED_SCORE_COL_NAME = \"pred_score_col_name\"\n",
        "dataset_name = \"rel-hm\"\n",
        "task_name = \"user-item-purchase\"\n",
        "\n",
        "\n",
        "class GloveTextEmbedding:\n",
        "    def __init__(self, device: Optional[torch.device\n",
        "                                       ] = None):\n",
        "        self.model = SentenceTransformer(\n",
        "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    def __call__(self, sentences: List[str]) -> Tensor:\n",
        "        return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n",
        "def make_pkey_fkey_graph(\n",
        "    db: Database,\n",
        "    col_to_stype_dict: Dict[str, Dict[str, stype]],\n",
        "    text_embedder_cfg: Optional[TextEmbedderConfig] = None,\n",
        "    cache_dir: Optional[str] = None,\n",
        ") -> Tuple[HeteroData, Dict[str, Dict[str, Dict[StatType, Any]]]]:\n",
        "    r\"\"\"Given a :class:`Database` object, construct a heterogeneous graph with primary-\n",
        "    foreign key relationships, together with the column stats of each table.\n",
        "\n",
        "    Args:\n",
        "        db: A database object containing a set of tables.\n",
        "        col_to_stype_dict: Column to stype for\n",
        "            each table.\n",
        "        text_embedder_cfg: Text embedder config.\n",
        "        cache_dir: A directory for storing materialized tensor\n",
        "            frames. If specified, we will either cache the file or use the\n",
        "            cached file. If not specified, we will not use cached file and\n",
        "            re-process everything from scratch without saving the cache.\n",
        "\n",
        "    Returns:\n",
        "        HeteroData: The heterogeneous :class:`PyG` object with\n",
        "            :class:`TensorFrame` feature.\n",
        "    \"\"\"\n",
        "    data = HeteroData()\n",
        "    col_stats_dict = dict()\n",
        "    if cache_dir is not None:\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "    for table_name, table in db.table_dict.items():\n",
        "        # Materialize the tables into tensor frames:\n",
        "        df = table.df\n",
        "        # Ensure that pkey is consecutive.\n",
        "        if table.pkey_col is not None:\n",
        "            assert (df[table.pkey_col].values == np.arange(len(df))).all()\n",
        "\n",
        "        col_to_stype = col_to_stype_dict[table_name]\n",
        "\n",
        "        # Remove pkey, fkey columns since they will not be used as input\n",
        "        # feature.\n",
        "        remove_pkey_fkey(col_to_stype, table)\n",
        "\n",
        "        if len(col_to_stype) == 0:  # Add constant feature in case df is empty:\n",
        "            col_to_stype = {\"__const__\": stype.numerical}\n",
        "            # We need to add edges later, so we need to also keep the fkeys\n",
        "            fkey_dict = {key: df[key] for key in table.fkey_col_to_pkey_table}\n",
        "            df = pd.DataFrame({\"__const__\": np.ones(len(table.df)), **fkey_dict})\n",
        "\n",
        "        path = (\n",
        "            None if cache_dir is None else os.path.join(cache_dir, f\"{table_name}.pt\")\n",
        "        )\n",
        "\n",
        "        dataset_list = []\n",
        "\n",
        "        dataset = TorchFrameDataset(\n",
        "            df=df,\n",
        "            col_to_stype=col_to_stype,\n",
        "            col_to_text_embedder_cfg=text_embedder_cfg,\n",
        "        ).materialize(path=path, device=\"cuda\")\n",
        "\n",
        "        data[table_name].tf = dataset.tensor_frame\n",
        "        col_stats_dict[table_name] = dataset.col_stats\n",
        "\n",
        "        # Add time attribute:\n",
        "        if table.time_col is not None:\n",
        "            data[table_name].time = torch.from_numpy(\n",
        "                to_unix_time(table.df[table.time_col])\n",
        "            )\n",
        "\n",
        "        # Add edges:\n",
        "        for fkey_name, pkey_table_name in table.fkey_col_to_pkey_table.items():\n",
        "            pkey_index = df[fkey_name]\n",
        "            # Filter out dangling foreign keys\n",
        "            mask = ~pkey_index.isna()\n",
        "            fkey_index = torch.arange(len(pkey_index))\n",
        "            # Filter dangling foreign keys:\n",
        "            pkey_index = torch.from_numpy(pkey_index[mask].astype(int).values)\n",
        "            fkey_index = fkey_index[torch.from_numpy(mask.values)]\n",
        "            # Ensure no dangling fkeys\n",
        "            assert (pkey_index < len(db.table_dict[pkey_table_name])).all()\n",
        "\n",
        "            # fkey -> pkey edges\n",
        "            edge_index = torch.stack([fkey_index, pkey_index], dim=0)\n",
        "            edge_type = (table_name, f\"f2p_{fkey_name}\", pkey_table_name)\n",
        "            data[edge_type].edge_index = sort_edge_index(edge_index)\n",
        "\n",
        "            # pkey -> fkey edges.\n",
        "            # \"rev_\" is added so that PyG loader recognizes the reverse edges\n",
        "            edge_index = torch.stack([pkey_index, fkey_index], dim=0)\n",
        "            edge_type = (pkey_table_name, f\"rev_f2p_{fkey_name}\", table_name)\n",
        "            data[edge_type].edge_index = sort_edge_index(edge_index)\n",
        "\n",
        "    data.validate()\n",
        "\n",
        "    return data, col_stats_dict\n",
        "\n",
        "\n",
        "print(\"Downloading data ...\")\n",
        "dataset: Dataset = get_dataset(dataset_name, download=True)\n",
        "task: RecommendationTask = get_task(dataset_name, task_name, download=True)\n",
        "target_col_name: str = LINK_PRED_BASELINE_TARGET_COL_NAME\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "print(\"Getting data from tables ...\")\n",
        "db = dataset.get_db()\n",
        "src_entity_table = db.table_dict[task.src_entity_table]\n",
        "dst_entity_table = db.table_dict[task.dst_entity_table]\n",
        "\n",
        "src_entity_df = src_entity_table.df\n",
        "dst_entity_df = dst_entity_table.df\n",
        "print(\"Data loaded successfully\")\n",
        "\n",
        "\n",
        "cache_dir = os.path.expanduser(\"~/.cache/relbench_examples\")\n",
        "stypes_cache_path = Path(f\"{cache_dir}/{dataset_name}/stypes.json\")\n",
        "try:\n",
        "    with open(stypes_cache_path, \"r\") as f:\n",
        "        col_to_stype_dict = json.load(f)\n",
        "    for table, c_to_s in col_to_stype_dict.items():\n",
        "        for col, stype_str in c_to_s.items():\n",
        "            c_to_s[col] = stype(stype_str)\n",
        "except FileNotFoundError:\n",
        "    col_to_stype_dict = get_stype_proposal(dataset.get_db())\n",
        "    Path(stypes_cache_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(stypes_cache_path, \"w\") as f:\n",
        "        json.dump(col_to_stype_dict, f, indent=2, default=str)\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# Prepare col_to_stype dictionary\n",
        "print(\"Preparing tables ...\")\n",
        "col_to_stype = {}\n",
        "src_entity_table_col_to_stype = copy.deepcopy(col_to_stype_dict[task.src_entity_table])\n",
        "dst_entity_table_col_to_stype = copy.deepcopy(col_to_stype_dict[task.dst_entity_table])\n",
        "\n",
        "remove_pkey_fkey(src_entity_table_col_to_stype, src_entity_table)\n",
        "remove_pkey_fkey(dst_entity_table_col_to_stype, dst_entity_table)\n",
        "\n",
        "# Resolve naming conflicts by adding _x and _y suffixes\n",
        "src_dst_intersection_column_names = set(src_entity_table_col_to_stype.keys()) & set(\n",
        "    dst_entity_table_col_to_stype.keys()\n",
        ")\n",
        "for column_name in src_dst_intersection_column_names:\n",
        "    src_entity_table_col_to_stype[f\"{column_name}_x\"] = src_entity_table_col_to_stype[column_name]\n",
        "    del src_entity_table_col_to_stype[column_name]\n",
        "    dst_entity_table_col_to_stype[f\"{column_name}_y\"] = dst_entity_table_col_to_stype[column_name]\n",
        "    del dst_entity_table_col_to_stype[column_name]\n",
        "\n",
        "col_to_stype.update(src_entity_table_col_to_stype)\n",
        "col_to_stype.update(dst_entity_table_col_to_stype)\n",
        "col_to_stype[target_col_name] = torch_frame.categorical\n",
        "print(\"Download finished with success!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WZAKtvkLyOZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ba3779-7ae1-414f-85c6-f15862c543bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing libraries...\n",
            "Downloading data ...\n",
            "Getting data from tables ...\n",
            "Loading Database object from /root/.cache/relbench/rel-hm/db...\n",
            "Done in 3.41 seconds.\n",
            "Data loaded successfully\n",
            "Preparing tables ...\n",
            "Download finished with success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Preprocessing\n",
        "\n",
        "Let's define the preprocessing functions described above to obtain a single-table version of data."
      ],
      "metadata": {
        "id": "r40fXAifUSgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_past_label_feature(\n",
        "    train_table_df: pd.DataFrame,\n",
        "    past_table_df: pd.DataFrame,\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"Add past visit count and percentage of global popularity to train table df used\n",
        "    for training, evaluation of testing.\n",
        "\n",
        "    Args:\n",
        "        evaluate_table_df (pd.DataFrame): The dataframe used for evaluation.\n",
        "        past_table_df (pd.DataFrame): The dataframe containing labels in the\n",
        "            past.\n",
        "    \"\"\"\n",
        "    # Add number of past visit for each src_entity and dst_entity pair\n",
        "    # Explode the dst_entity list to get one row per (src_entity, dst_entity) pair\n",
        "    exploded_past_table = past_table_df.explode(dst_entity)\n",
        "\n",
        "    # Count occurrences of each (src_entity, dst_entity) pair\n",
        "    dst_entity_count = (\n",
        "        exploded_past_table.groupby([src_entity, dst_entity])\n",
        "        .size()\n",
        "        .reset_index(name=\"num_past_visit\")\n",
        "    )\n",
        "\n",
        "    # Merge the count information with train_table_df\n",
        "    train_table_df = train_table_df.merge(\n",
        "        dst_entity_count, how=\"left\", on=[src_entity, dst_entity]\n",
        "    )\n",
        "\n",
        "    # Fill NaN values with 0 (if there are any dst_entity in train_table_df not present in past_table_df)\n",
        "    train_table_df[\"num_past_visit\"] = (\n",
        "        train_table_df[\"num_past_visit\"].fillna(0).astype(int)\n",
        "    )\n",
        "\n",
        "    # Add percentage of global popularity for each dst_entity\n",
        "    # Count occurrences of each dst_entity\n",
        "    dst_entity_count = exploded_past_table[dst_entity].value_counts().reset_index()\n",
        "\n",
        "    # Calculate the fraction\n",
        "    # total_right_entities = len(exploded_past_table)\n",
        "    dst_entity_count[\"global_popularity_fraction\"] = (\n",
        "        dst_entity_count[\"count\"] / dst_entity_count[\"count\"].max()\n",
        "    )\n",
        "\n",
        "    # Merge the fraction information with train_table_df\n",
        "    train_table_df = train_table_df.merge(\n",
        "        dst_entity_count[[dst_entity, \"global_popularity_fraction\"]],\n",
        "        how=\"left\",\n",
        "        on=dst_entity,\n",
        "    )\n",
        "\n",
        "    # Fill NaN values with 0 (if there are any dst_entity in train_table_df not present in past_table_df)\n",
        "    train_table_df[\"global_popularity_fraction\"] = train_table_df[\n",
        "        \"global_popularity_fraction\"\n",
        "    ].fillna(0)\n",
        "\n",
        "    return train_table_df"
      ],
      "metadata": {
        "id": "Yk4a8A8sUeO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def dst_entities_aggr(dst_entities):\n",
        "    r\"concatenate and rank dst entities\"\n",
        "    dst_entities_concat = []\n",
        "    for dst_entity_list in list(dst_entities):\n",
        "        dst_entities_concat.extend(dst_entity_list)\n",
        "    counter = Counter(dst_entities_concat)\n",
        "    topk = [elem for elem, _ in counter.most_common(task.eval_k)]\n",
        "    return topk\n",
        "\n",
        "\n",
        "def prepare_for_link_pred_eval(\n",
        "    evaluate_table_df: pd.DataFrame,\n",
        "    past_table_df: pd.DataFrame\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Transform evaluation dataframe into the correct format for link prediction metric\n",
        "    calculation.\n",
        "\n",
        "    Args:\n",
        "        pred_table_df (pd.DataFrame): The prediction dataframe.\n",
        "        past_table_df (pd.DataFrame): The dataframe containing labels in the\n",
        "            past.\n",
        "    Returns:\n",
        "        (pd.DataFrame): The evaluation dataframe containing past visit and\n",
        "            global popularity dst entities as candidate set.\n",
        "    \"\"\"\n",
        "\n",
        "    def interleave_lists(list1, list2):\n",
        "        interleaved = [item for pair in zip(list1, list2) for item in pair]\n",
        "        longer_list = list1 if len(list1) > len(list2) else list2\n",
        "        interleaved.extend(longer_list[len(interleaved) // 2 :])\n",
        "        return interleaved\n",
        "\n",
        "    grouped_ranked_past_table_df = (\n",
        "        past_table_df.groupby(src_entity)[dst_entity]\n",
        "        .apply(dst_entities_aggr)\n",
        "        .reset_index()\n",
        "    )\n",
        "    evaluate_table_df = pd.merge(\n",
        "        evaluate_table_df, grouped_ranked_past_table_df, how=\"left\", on=src_entity\n",
        "    )\n",
        "\n",
        "    # collect the most popular dst entities\n",
        "    all_dst_entities = [\n",
        "        entity for sublist in past_table_df[dst_entity] for entity in sublist\n",
        "    ]\n",
        "    dst_entity_counter = Counter(all_dst_entities)\n",
        "    top_dst_entities = [\n",
        "        entity for entity, _ in dst_entity_counter.most_common(task.eval_k * 2)\n",
        "    ]\n",
        "\n",
        "    evaluate_table_df[dst_entity] = evaluate_table_df[dst_entity].apply(\n",
        "        lambda x: (\n",
        "            interleave_lists(x, top_dst_entities)\n",
        "            if isinstance(x, list)\n",
        "            else top_dst_entities\n",
        "        )\n",
        "    )\n",
        "    # For each src entity, keep at most `task.eval_k * 2` dst entity candidates\n",
        "    evaluate_table_df[dst_entity] = evaluate_table_df[dst_entity].apply(\n",
        "        lambda x: (\n",
        "            x[: task.eval_k * 2]\n",
        "            if isinstance(x, list) and len(x) > task.eval_k * 2\n",
        "            else x\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Include src and dst entity table features for `evaluate_table_df`\n",
        "    evaluate_table_df = pd.merge(\n",
        "        evaluate_table_df,\n",
        "        src_entity_df,\n",
        "        how=\"left\",\n",
        "        left_on=src_entity,\n",
        "        right_on=src_entity_table.pkey_col,\n",
        "    )\n",
        "\n",
        "    evaluate_table_df = evaluate_table_df.explode(dst_entity)\n",
        "    evaluate_table_df = pd.merge(\n",
        "        evaluate_table_df,\n",
        "        dst_entity_df,\n",
        "        how=\"left\",\n",
        "        left_on=dst_entity,\n",
        "        right_on=dst_entity_table.pkey_col,\n",
        "    )\n",
        "\n",
        "    evaluate_table_df = add_past_label_feature(evaluate_table_df, past_table_df)\n",
        "    return evaluate_table_df"
      ],
      "metadata": {
        "id": "0bP9biJpT9YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data sampling scheme\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Default values for the variables\n",
        "DEFAULT_TRAIN_SAMPLE_SIZE = 5000\n",
        "DEFAULT_VAL_SAMPLE_SIZE = 1000\n",
        "DEFAULT_TEST_SAMPLE_SIZE = 1000\n",
        "\n",
        "# Define the text fields with placeholders for default values\n",
        "var1_field = widgets.Text(\n",
        "    value='',\n",
        "    placeholder=f'(default {DEFAULT_TRAIN_SAMPLE_SIZE})',\n",
        "    description='TRAIN_SIZE:',\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "var2_field = widgets.Text(\n",
        "    value='',\n",
        "    placeholder=f'(default {DEFAULT_VAL_SAMPLE_SIZE})',\n",
        "    description='VAL_SIZE:',\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "var3_field = widgets.Text(\n",
        "    value='',\n",
        "    placeholder=f'(default {DEFAULT_TEST_SAMPLE_SIZE})',\n",
        "    description='TEST_SIZE:',\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "# Define a button to confirm inputs\n",
        "submit_button = widgets.Button(\n",
        "    description=\"Submit\",\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "# Output area\n",
        "output = widgets.Output()\n",
        "\n",
        "# Initialize variables with default values\n",
        "TRAIN_SIZE = DEFAULT_TRAIN_SAMPLE_SIZE\n",
        "VAL_SIZE = DEFAULT_VAL_SAMPLE_SIZE\n",
        "TEST_SIZE = DEFAULT_TEST_SAMPLE_SIZE\n",
        "\n",
        "# Function to handle the button click\n",
        "def on_submit_button_clicked(b):\n",
        "    global TRAIN_SIZE, VAL_SIZE, TEST_SIZE\n",
        "    with output:\n",
        "        try:\n",
        "            # Use defaults if input is empty, otherwise parse the input\n",
        "            TRAIN_SIZE = int(var1_field.value) if var1_field.value.strip() else DEFAULT_TRAIN_SAMPLE_SIZE\n",
        "            VAL_SIZE = int(var2_field.value) if var2_field.value.strip() else DEFAULT_VAL_SAMPLE_SIZE\n",
        "            TEST_SIZE = int(var3_field.value) if var3_field.value.strip() else DEFAULT_TEST_SAMPLE_SIZE\n",
        "        except ValueError:\n",
        "            print(\"Error: Please enter valid integer values or leave fields blank for default values.\")\n",
        "        output.clear_output()\n",
        "\n",
        "# Attach the button click event\n",
        "submit_button.on_click(on_submit_button_clicked)\n",
        "\n",
        "# Arrange widgets vertically\n",
        "form = widgets.VBox([var1_field, var2_field, var3_field, submit_button, output])\n",
        "\n",
        "# Display the form\n",
        "display(form)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gKh8Wyj0W0n6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "3226d8f35bb945fb82e093914b381b19",
            "f5e6559ec3014ccead080680bb220b73",
            "2eb1c6c2fa6848838222a0cc0556d2a9",
            "53496ed554e4430c8491761243d9d2cf",
            "0e1853ba0228428aa81580e2a600f1c6",
            "f975564e46b74e29a435ddf995582300",
            "a99a459d782548f6a978660aeb12d1d0",
            "301a881a1e58495abeb07d00fcd3c436",
            "2b3ac255da62473fb1d4aea5713182e3",
            "21328bee1f4a495dbf359ec338564656",
            "13de11a09403475c9f170169d756bfe3",
            "22d7c941265c40449ba307de1ba2cb10",
            "76f97d217a8f4f438f4c3f50afd8878e",
            "b484d21d427d4cf18face0eb4240ebd9",
            "82aab9b08e5846ec92afb2e2a850c4f5",
            "9c37798c2a2c49319831f435bdbcde8b"
          ]
        },
        "outputId": "fad5509b-56a5-4fb5-b3d1-8e78bcf64292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='TRAIN_SIZE:', layout=Layout(width='400px'), placeholder='(default 5…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3226d8f35bb945fb82e093914b381b19"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As mentioned before, one of the major drawbacks of the one-table formalism is the **high computational requirements**. The"
      ],
      "metadata": {
        "id": "DB8xci9PvzoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample train set\n",
        "sampled_train_table = copy.deepcopy(train_table)\n",
        "sampled_idx = np.random.permutation(len(sampled_train_table))[:TRAIN_SIZE]\n",
        "sampled_train_table.df = sampled_train_table.df.iloc[sampled_idx]\n",
        "\n",
        "# Sample validation set\n",
        "sampled_val_table = copy.deepcopy(val_table)\n",
        "sampled_idx = np.random.permutation(len(sampled_val_table))[:VAL_SIZE]\n",
        "sampled_val_table.df = sampled_val_table.df.iloc[sampled_idx]\n",
        "\n",
        "# Sample test set\n",
        "sampled_test_table = copy.deepcopy(test_table)\n",
        "sampled_idx = np.random.permutation(len(sampled_test_table))[:TEST_SIZE]\n",
        "sampled_test_table.df = sampled_test_table.df.iloc[sampled_idx]"
      ],
      "metadata": {
        "id": "g3XhTLjRVQgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now prepare the dataset for training our baseline algorithms. Specifically, for each src entity (user), its corresponding dst entities (items) are used as **positive** label. The same number of random dst entities are sampled as **negative** label. Models will be trained and evaluated on this **binary classification task**."
      ],
      "metadata": {
        "id": "ipcluFGz3N41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_entity = list(sampled_train_table.fkey_col_to_pkey_table.keys())[0]\n",
        "dst_entity = list(sampled_train_table.fkey_col_to_pkey_table.keys())[1]\n",
        "\n",
        "\n",
        "def timed_execution(description, func, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Measures the execution time of a task, prints a descriptive message, and returns the result.\n",
        "\n",
        "    Args:\n",
        "        description (str): A brief description of the task being executed.\n",
        "        func (callable): The function to be executed.\n",
        "        *args: Positional arguments for the function.\n",
        "        **kwargs: Keyword arguments for the function.\n",
        "\n",
        "    Returns:\n",
        "        The result of the function execution.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    print(f\"{description}...\")\n",
        "    result = func(*args, **kwargs)\n",
        "    print(f\"Completed {description} in {time.time() - start_time:.2f} seconds\\n\")\n",
        "    return result\n",
        "\n",
        "\n",
        "def process_split(\n",
        "    split_name,\n",
        "    table,\n",
        "    src_entity_df,\n",
        "    dst_entity_df,\n",
        "    target_col_name,\n",
        "    train_table_df,\n",
        "    src_entity_col,\n",
        "    dst_entity_col,\n",
        "    additional_data=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Unified function to process splits for training, validation, validation prediction, and testing.\n",
        "\n",
        "    Args:\n",
        "        split_name (str): Name of the split being processed (e.g., \"train\", \"val\", \"val_pred\", \"test\").\n",
        "        table: The data table for the split.\n",
        "        src_entity_df (pd.DataFrame): Dataframe for the source entity with additional features.\n",
        "        dst_entity_df (pd.DataFrame): Dataframe for the destination entity with additional features.\n",
        "        target_col_name (str): Name of the column for target labels.\n",
        "        train_table_df (pd.DataFrame): Training table dataframe used for past label feature computation.\n",
        "        src_entity_col (str): Column name for the source entity primary key.\n",
        "        dst_entity_col (str): Column name for the destination entity primary key.\n",
        "        additional_data (Dict[str, pd.DataFrame], optional): Additional data required for specific splits.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The processed dataframe for the split.\n",
        "    \"\"\"\n",
        "    print(f\"{'=' * 30}\\nProcessing {split_name} split\\n{'=' * 30}\")\n",
        "\n",
        "    # Train and validation splits\n",
        "    if split_name in [\"train\", \"val\"]:\n",
        "        def process_train_val():\n",
        "            # Step 1: Ensure dtype consistency\n",
        "            src_entity_df_typed = src_entity_df.astype(\n",
        "                {src_entity_col: table.df[src_entity_col].dtype}\n",
        "            )\n",
        "            dst_entity_df_typed = dst_entity_df.astype(\n",
        "                {dst_entity_col: table.df[dst_entity_col].dtype}\n",
        "            )\n",
        "\n",
        "            # Step 2: Merge source entity\n",
        "            df = table.df.merge(\n",
        "                src_entity_df_typed,\n",
        "                how=\"left\",\n",
        "                left_on=src_entity_col,\n",
        "                right_on=src_entity_col,\n",
        "            )\n",
        "\n",
        "            # Step 3: Explode destination entity\n",
        "            df = df.explode(dst_entity_col)\n",
        "\n",
        "            # Step 4: Add a target column indicating positive links\n",
        "            df[target_col_name] = 1\n",
        "\n",
        "            # Step 5: Create negative samples\n",
        "            negative_sample_df_columns = list(df.columns)\n",
        "            negative_sample_df_columns.remove(dst_entity_col)\n",
        "            negative_samples_df = df[negative_sample_df_columns]\n",
        "            negative_samples_df[dst_entity_col] = np.random.choice(\n",
        "                dst_entity_df_typed[dst_entity_col], size=len(negative_samples_df)\n",
        "            )\n",
        "            negative_samples_df[target_col_name] = 0\n",
        "\n",
        "            # Step 6: Combine positive and negative samples\n",
        "            df = pd.concat([df, negative_samples_df], ignore_index=True)\n",
        "\n",
        "            # Step 7: Merge destination entity features\n",
        "            df = pd.merge(\n",
        "                df,\n",
        "                dst_entity_df_typed,\n",
        "                how=\"left\",\n",
        "                left_on=dst_entity_col,\n",
        "                right_on=dst_entity_col,\n",
        "            )\n",
        "\n",
        "            # Step 8: Add past label feature\n",
        "            df = add_past_label_feature(df, train_table_df)\n",
        "\n",
        "            return df\n",
        "\n",
        "        return timed_execution(f\"Parsing and creating positive-negatives for {split_name} split\", process_train_val)\n",
        "\n",
        "    # Validation prediction split\n",
        "    elif split_name == \"val_pred\":\n",
        "        def prepare_val_pred():\n",
        "            \"\"\"\n",
        "            Prepares the validation prediction split for evaluation by merging historical training data\n",
        "            with validation data, and removing irrelevant columns.\n",
        "            \"\"\"\n",
        "            val_df_pred_columns = list(table.df.columns)\n",
        "            val_df_pred_columns.remove(dst_entity_col)\n",
        "            val_df_pred = table.df[val_df_pred_columns]\n",
        "\n",
        "            val_past_table_df = train_table_df.copy()\n",
        "            val_past_table_df.drop(columns=[table.time_col], inplace=True)\n",
        "\n",
        "            return prepare_for_link_pred_eval(val_df_pred, val_past_table_df)\n",
        "\n",
        "        return timed_execution(\"Preparing val_pred\", prepare_val_pred)\n",
        "\n",
        "    # Test split\n",
        "    elif split_name == \"test\":\n",
        "        def prepare_test():\n",
        "            \"\"\"\n",
        "            Prepares the test split for evaluation by merging historical train and validation data\n",
        "            with the test data, and removing irrelevant columns.\n",
        "            \"\"\"\n",
        "            test_df_columns = list(table.df.columns)\n",
        "            test_df_columns.remove(dst_entity_col)\n",
        "            test_df = table.df[test_df_columns]\n",
        "\n",
        "            test_past_table_df = pd.concat(additional_data.values(), axis=0)\n",
        "            test_past_table_df.drop(columns=[table.time_col], inplace=True)\n",
        "\n",
        "            return prepare_for_link_pred_eval(test_df, test_past_table_df)\n",
        "\n",
        "        return timed_execution(\"Preparing test\", prepare_test)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown split name: {split_name}\")\n",
        "\n",
        "\n",
        "# Extract source and destination entity columns\n",
        "src_entity_col = list(sampled_train_table.fkey_col_to_pkey_table.keys())[0]\n",
        "dst_entity_col = list(sampled_train_table.fkey_col_to_pkey_table.keys())[1]\n",
        "\n",
        "# Prepare all splits\n",
        "dfs = {\n",
        "    \"train\": process_split(\n",
        "        \"train\",\n",
        "        sampled_train_table,\n",
        "        src_entity_df,\n",
        "        dst_entity_df,\n",
        "        target_col_name,\n",
        "        sampled_train_table.df,\n",
        "        src_entity_col,\n",
        "        dst_entity_col,\n",
        "    ),\n",
        "    \"val\": process_split(\n",
        "        \"val\",\n",
        "        sampled_val_table,\n",
        "        src_entity_df,\n",
        "        dst_entity_df,\n",
        "        target_col_name,\n",
        "        sampled_train_table.df,\n",
        "        src_entity_col,\n",
        "        dst_entity_col,\n",
        "    ),\n",
        "    \"val_pred\": process_split(\n",
        "        \"val_pred\",\n",
        "        sampled_val_table,\n",
        "        src_entity_df,\n",
        "        dst_entity_df,\n",
        "        target_col_name,\n",
        "        sampled_train_table.df,\n",
        "        src_entity_col,\n",
        "        dst_entity_col,\n",
        "    ),\n",
        "    \"test\": process_split(\n",
        "        \"test\",\n",
        "        sampled_test_table,\n",
        "        src_entity_df,\n",
        "        dst_entity_df,\n",
        "        target_col_name,\n",
        "        sampled_train_table.df,\n",
        "        src_entity_col,\n",
        "        dst_entity_col,\n",
        "        additional_data={\"train\": sampled_train_table.df, \"val\": sampled_val_table.df},\n",
        "    ),\n",
        "}\n",
        "\n",
        "print(\"Processing complete for all splits!\")"
      ],
      "metadata": {
        "id": "sAYV0LXXfAxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127a0b92-454d-4d49-a146-c340da1d25a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Processing train split\n",
            "==============================\n",
            "Parsing and creating positive-negatives for train split...\n",
            "Completed Parsing and creating positive-negatives for train split in 1.11 seconds\n",
            "\n",
            "==============================\n",
            "Processing val split\n",
            "==============================\n",
            "Parsing and creating positive-negatives for val split...\n",
            "Completed Parsing and creating positive-negatives for val split in 1.00 seconds\n",
            "\n",
            "==============================\n",
            "Processing val_pred split\n",
            "==============================\n",
            "Preparing val_pred...\n",
            "Completed Preparing val_pred in 0.71 seconds\n",
            "\n",
            "==============================\n",
            "Processing test split\n",
            "==============================\n",
            "Preparing test...\n",
            "Completed Preparing test in 0.48 seconds\n",
            "\n",
            "Processing complete for all splits!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost"
      ],
      "metadata": {
        "id": "jHvar6n8U463"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Developed by [Tianqi Chen (2014)](https://arxiv.org/pdf/1603.02754.pdf).\n",
        "\n",
        "* *Tree Growth Strategy:* **Level-wise**, meaning all nodes at a given depth are split before increasing the depth of the tree. It can lead to unnecessary splits in regions where further partitioning isn’t helpful, which slows down training and increases computational cost.\n",
        "* *Split Finding:* **Exact**, evaluating all possible split points for numeric features. While accurate, this is computationally expensive and can be slow for datasets with high cardinality features.\n",
        "* *Categorical Feature Handling:* **Requires to be encoded manually** (e.g., one-hot encoding). This can inflate dimensionality, especially for high-cardinality features, increasing computational overhead.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16MhV7Dw69T8vDwlLKHW4eMzL1SzEqeQN\" width=\"650\">"
      ],
      "metadata": {
        "id": "qpB-AieCfC_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **XGBoost** class definition\n",
        "\n",
        "import copy\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "from torch_frame import Metric, TaskType, TensorFrame, stype\n",
        "from torch_frame.gbdt import GBDT\n",
        "import xgboost as xgb\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def neg_to_nan(x: Tensor) -> Tensor:\n",
        "    r\"\"\"Convert -1 category back to NaN that can be handled by GBDT.\n",
        "\n",
        "    Args:\n",
        "        x (Tensor): Input categ. feature, where `-1` represents `NaN`.\n",
        "\n",
        "    Returns:\n",
        "        x (Tensor): Output categ. feature, where `-1` is replaced with `NaN`\n",
        "    \"\"\"\n",
        "    is_neg = x == -1\n",
        "    if is_neg.any():\n",
        "        x = copy.copy(x).to(torch.float32)\n",
        "        x[is_neg] = torch.nan\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class XGBoost(GBDT):\n",
        "    \"\"\"\n",
        "    Optimized XGBoost implementation extending GBDT.\n",
        "    Supports hyperparameter tuning and uses GPU acceleration for training.\n",
        "    \"\"\"\n",
        "    def _to_xgboost_input(\n",
        "        self, tf: TensorFrame\n",
        "    ) -> tuple[xgb.DMatrix, torch.Tensor, list[str]]:\n",
        "        \"\"\"\n",
        "        Convert TensorFrame to XGBoost-compatible input.\n",
        "        Args:\n",
        "            tf (TensorFrame): Input TensorFrame.\n",
        "        Returns:\n",
        "            xgb.DMatrix: Input data in DMatrix format for XGBoost.\n",
        "        \"\"\"\n",
        "        tf = tf.cpu()  # Ensure data is on CPU for conversion to DMatrix\n",
        "        y = tf.y.numpy() if tf.y is not None else None\n",
        "\n",
        "        feats = []\n",
        "        types = []\n",
        "\n",
        "        # Process categorical features\n",
        "        if stype.categorical in tf.feat_dict:\n",
        "            feats.append(neg_to_nan(tf.feat_dict[stype.categorical]).numpy())\n",
        "            types.extend([\"c\"] * len(tf.col_names_dict[stype.categorical]))\n",
        "\n",
        "        # Process numerical features\n",
        "        if stype.numerical in tf.feat_dict:\n",
        "            feats.append(tf.feat_dict[stype.numerical].numpy())\n",
        "            types.extend([\"q\"] * len(tf.col_names_dict[stype.numerical]))\n",
        "\n",
        "        # Process embedding features\n",
        "        if stype.embedding in tf.feat_dict:\n",
        "            feat = tf.feat_dict[stype.embedding]\n",
        "            feat = feat.values.view(feat.size(0), -1).numpy()\n",
        "            feats.append(feat)\n",
        "            types.extend([\"q\"] * feat.shape[1])\n",
        "\n",
        "        if not feats:\n",
        "            raise ValueError(\"TensorFrame contains no features.\")\n",
        "\n",
        "        # Concatenate all features into a single matrix\n",
        "        X = np.hstack(feats)\n",
        "        dmatrix = xgb.DMatrix(X, label=y, enable_categorical=True)\n",
        "\n",
        "        return dmatrix\n",
        "\n",
        "    def objective(\n",
        "        self, trial: Any, dtrain: xgb.DMatrix, dvalid: xgb.DMatrix, num_boost_round: int\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Objective function for hyperparameter tuning.\n",
        "        Args:\n",
        "            trial (optuna.Trial): Trial object for hyperparameter optimization.\n",
        "            dtrain (xgb.DMatrix): Training data.\n",
        "            dvalid (xgb.DMatrix): Validation data.\n",
        "            num_boost_round (int): Number of boosting rounds.\n",
        "        Returns:\n",
        "            float: Validation score.\n",
        "        \"\"\"\n",
        "        import optuna\n",
        "\n",
        "        self.params = {\n",
        "            \"tree_method\": \"gpu_hist\",  # Use GPU for faster training\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
        "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "            \"lambda\": trial.suggest_float(\"lambda\", 1e-9, 10.0, log=True),\n",
        "            \"alpha\": trial.suggest_float(\"alpha\", 1e-9, 10.0, log=True),\n",
        "        }\n",
        "\n",
        "        if self.task_type == TaskType.BINARY_CLASSIFICATION:\n",
        "            self.params.update({\"objective\": \"binary:logistic\", \"eval_metric\": \"auc\"})\n",
        "        elif self.task_type == TaskType.REGRESSION:\n",
        "            self.params.update({\"objective\": \"reg:squarederror\", \"eval_metric\": \"rmse\"})\n",
        "        elif self.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
        "            self.params.update(\n",
        "                {\n",
        "                    \"objective\": \"multi:softmax\",\n",
        "                    \"num_class\": self._num_classes,\n",
        "                    \"eval_metric\": \"mlogloss\",\n",
        "                }\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported task type: {self.task_type}\")\n",
        "\n",
        "        pruning_callback = optuna.integration.XGBoostPruningCallback(\n",
        "            trial, f\"validation-{self.params['eval_metric']}\"\n",
        "        )\n",
        "\n",
        "        booster = xgb.train(\n",
        "            self.params,\n",
        "            dtrain,\n",
        "            num_boost_round=num_boost_round,\n",
        "            early_stopping_rounds=50,\n",
        "            evals=[(dvalid, \"validation\")],\n",
        "            callbacks=[pruning_callback],\n",
        "        )\n",
        "\n",
        "        pred = booster.predict(dvalid)\n",
        "        score = self.compute_metric(\n",
        "            torch.tensor(dvalid.get_label()), torch.tensor(pred)\n",
        "        )\n",
        "        return score\n",
        "\n",
        "    def _tune(\n",
        "        self, tf_train: TensorFrame, tf_val: TensorFrame, num_trials: int, num_boost_round: int = 2000\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Perform hyperparameter tuning using Optuna.\n",
        "        Args:\n",
        "            tf_train (TensorFrame): Training data.\n",
        "            tf_val (TensorFrame): Validation data.\n",
        "            num_trials (int): Number of tuning trials.\n",
        "            num_boost_round (int): Number of boosting rounds.\n",
        "        \"\"\"\n",
        "        import optuna\n",
        "\n",
        "        dtrain = self._to_xgboost_input(tf_train)\n",
        "        dvalid = self._to_xgboost_input(tf_val)\n",
        "\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(\n",
        "            lambda trial: self.objective(trial, dtrain, dvalid, num_boost_round),\n",
        "            n_trials=num_trials,\n",
        "        )\n",
        "        self.params.update(study.best_params)\n",
        "\n",
        "        # Train final model with best parameters\n",
        "        self.model = xgb.train(\n",
        "            self.params,\n",
        "            dtrain,\n",
        "            num_boost_round=num_boost_round,\n",
        "            evals=[(dvalid, \"validation\")],\n",
        "            early_stopping_rounds=50,\n",
        "        )\n",
        "\n",
        "    def _predict(self, tf_test: TensorFrame) -> Tensor:\n",
        "        \"\"\"\n",
        "        Predict using the trained model.\n",
        "        Args:\n",
        "            tf_test (TensorFrame): Test data.\n",
        "        Returns:\n",
        "            Tensor: Predictions.\n",
        "        \"\"\"\n",
        "        dtest = self._to_xgboost_input(tf_test)\n",
        "        pred = self.model.predict(dtest)\n",
        "        return torch.tensor(pred, device=tf_test.device)\n",
        "\n",
        "    def _load(self, path: str):\n",
        "        \"\"\"\n",
        "        Load a pre-trained model from file.\n",
        "        Args:\n",
        "            path (str): Path to the saved model.\n",
        "        \"\"\"\n",
        "        self.model = xgb.Booster(model_file=path)\n",
        "\n",
        "    def _save(self, path: str):\n",
        "        \"\"\"\n",
        "        Save the trained model to file.\n",
        "        Args:\n",
        "            path (str): Path to save the model.\n",
        "        \"\"\"\n",
        "        if self.model:\n",
        "            self.model.save_model(path)\n",
        "        else:\n",
        "            raise ValueError(\"No model has been trained.\")"
      ],
      "metadata": {
        "id": "qtqHYSjx8hUP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LightGBM"
      ],
      "metadata": {
        "id": "I7hT5AFtU3ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Developed by Microsoft, [Ke et al. (2017)](https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf).\n",
        "\n",
        "* *Tree Growth Strategy:* **Life-wise**, selecting the leaf with the largest loss reduction to split. This produces trees that are deeper in parts of the feature space with high variance while remaining shallow in simpler regions. It captures complex, localized interactions better but risks overfitting, especially if the dataset is small or lacks regularization.\n",
        "* *Split Finding:* **Histogram-based**, grouping feature values into discrete bins and finding splits based on these bins. This approach is much faster, particularly for high-dimensional or sparse data.\n",
        "* *Categorical Feature Handling:* **Natively handles categorical features** by directly learning optimal splits for them, avoiding the need for preprocessing. This greatly reduces preprocessing effort, memory usage, and runtime for datasets with categorical features.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uA4EdbDYvfYegsq1t85vnmtSFe1HpkHH\" width=\"650\">"
      ],
      "metadata": {
        "id": "xavwiBBNoln4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### **LightGBM** class definition\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "from torch_frame import Metric, TaskType, TensorFrame, stype\n",
        "from torch_frame.gbdt import GBDT\n",
        "import optuna\n",
        "import lightgbm\n",
        "\n",
        "class LightGBM(GBDT):\n",
        "    r\"\"\"LightGBM implementation with hyper-parameter tuning using Optuna.\n",
        "\n",
        "    This implementation extends GBDT and aims to find optimal hyperparameters\n",
        "    by optimizing the given objective function.\n",
        "    \"\"\"\n",
        "    def _to_lightgbm_input(\n",
        "        self,\n",
        "        tf: TensorFrame,\n",
        "        ) -> tuple[pd.DataFrame, np.ndarray, list[str]]:\n",
        "        r\"\"\"Convert :class:`TensorFrame` into LightGBM-compatible input format:\n",
        "        :obj:`(feat, y, cat_features)`.\n",
        "\n",
        "        Args:\n",
        "            tf (Tensor Frame): Input :obj:TensorFrame object.\n",
        "\n",
        "        Returns:\n",
        "            df (DataFrame): :obj:`DataFrame` that concatenates tensors of\n",
        "                numerical and categorical features of the input\n",
        "                :class:`TensorFrame`.\n",
        "            y (numpy.ndarray, optional): Prediction label.\n",
        "            cat_features (list[int]): Array containing indexes of\n",
        "                categorical features.\n",
        "        \"\"\"\n",
        "        tf = tf.cpu()\n",
        "        y = tf.y\n",
        "        if y is not None:\n",
        "            y: np.ndarray = y.numpy()\n",
        "\n",
        "        dfs: list[pd.DataFrame] = []\n",
        "        cat_features_list: list[np.ndarray] = []\n",
        "        offset: int = 0\n",
        "\n",
        "        if stype.categorical in tf.feat_dict:\n",
        "            feat = tf.feat_dict[stype.categorical].numpy()\n",
        "            arange = np.arange(offset, offset + feat.shape[1])\n",
        "            dfs.append(pd.DataFrame(feat, columns=arange))\n",
        "            cat_features_list.append(arange)\n",
        "            offset += feat.shape[1]\n",
        "\n",
        "        if stype.numerical in tf.feat_dict:\n",
        "            feat = tf.feat_dict[stype.numerical].numpy()\n",
        "            arange = np.arange(offset, offset + feat.shape[1])\n",
        "            dfs.append(pd.DataFrame(feat, columns=arange))\n",
        "            offset += feat.shape[1]\n",
        "\n",
        "        if stype.embedding in tf.feat_dict:\n",
        "            feat = tf.feat_dict[stype.embedding]\n",
        "            feat = feat.values\n",
        "            feat = feat.view(feat.size(0), -1).numpy()\n",
        "            arange = np.arange(offset, offset + feat.shape[1])\n",
        "            dfs.append(pd.DataFrame(feat, columns=arange))\n",
        "            offset += feat.shape[1]\n",
        "\n",
        "        # TODO Add support for other stypes.\n",
        "\n",
        "        if len(dfs) == 0:\n",
        "            raise ValueError(\"The input TensorFrame object is empty.\")\n",
        "\n",
        "        df = pd.concat(dfs, axis=1)\n",
        "        cat_features: list[int] = np.concatenate(\n",
        "            cat_features_list,\n",
        "            axis=0).tolist() if len(cat_features_list) else []\n",
        "\n",
        "        return df, y, cat_features\n",
        "\n",
        "    def _predict_helper(\n",
        "        self,\n",
        "        model: Any,\n",
        "        x: pd.DataFrame,\n",
        "    ) -> np.ndarray:\n",
        "        r\"\"\"A helper function that applies the lightgbm model on DataFrame\n",
        "        :obj:`x`.\n",
        "\n",
        "        Args:\n",
        "            model (lightgbm.Booster): The lightgbm model.\n",
        "            x (DataFrame): The input `DataFrame`.\n",
        "\n",
        "        Returns:\n",
        "            pred (numpy.ndarray): The prediction output.\n",
        "        \"\"\"\n",
        "        pred = model.predict(x)\n",
        "        if self.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
        "            pred = pred.argmax(axis=1)\n",
        "\n",
        "        return pred\n",
        "\n",
        "    def objective(\n",
        "        self,\n",
        "        trial: Any,  # optuna.trial.Trial\n",
        "        train_data: Any,  # lightgbm.Dataset\n",
        "        eval_data: Any,  # lightgbm.Dataset\n",
        "        cat_features: list[int],\n",
        "        num_boost_round: int,\n",
        "    ) -> float:\n",
        "        r\"\"\"Objective function to be optimized.\n",
        "\n",
        "        Args:\n",
        "            trial (optuna.trial.Trial): Optuna trial object.\n",
        "            train_data (lightgbm.Dataset): Train data.\n",
        "            eval_data (lightgbm.Dataset): Validation data.\n",
        "            cat_features (list[int]): Array containing indexes of\n",
        "                categorical features.\n",
        "            num_boost_round (int): Number of boosting round.\n",
        "\n",
        "        Returns:\n",
        "            float: Best objective value. Mean absolute error for\n",
        "            regression task and accuracy for classification task.\n",
        "        \"\"\"\n",
        "        self.params = {\n",
        "            \"verbosity\":\n",
        "            -1,\n",
        "            \"bagging_freq\":\n",
        "            1,\n",
        "            \"max_depth\":\n",
        "            trial.suggest_int(\"max_depth\", 3, 11),\n",
        "            \"learning_rate\":\n",
        "            trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
        "            \"num_leaves\":\n",
        "            trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
        "            \"subsample\":\n",
        "            trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
        "            \"colsample_bytree\":\n",
        "            trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
        "            'lambda_l1':\n",
        "            trial.suggest_float('lambda_l1', 1e-9, 10.0, log=True),\n",
        "            'lambda_l2':\n",
        "            trial.suggest_float('lambda_l2', 1e-9, 10.0, log=True),\n",
        "            \"min_data_in_leaf\":\n",
        "            trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "        }\n",
        "\n",
        "        if self.task_type == TaskType.REGRESSION:\n",
        "            if self.metric == Metric.RMSE:\n",
        "                self.params[\"objective\"] = \"regression\"\n",
        "                self.params[\"metric\"] = \"rmse\"\n",
        "            elif self.metric == Metric.MAE:\n",
        "                self.params[\"objective\"] = \"regression_l1\"\n",
        "                self.params[\"metric\"] = \"mae\"\n",
        "        elif self.task_type == TaskType.BINARY_CLASSIFICATION:\n",
        "            self.params[\"objective\"] = \"binary\"\n",
        "            if self.metric == Metric.ROCAUC:\n",
        "                self.params[\"metric\"] = \"auc\"\n",
        "            elif self.metric == Metric.ACCURACY:\n",
        "                self.params[\"metric\"] = \"binary_error\"\n",
        "        elif self.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
        "            self.params[\"objective\"] = \"multiclass\"\n",
        "            self.params[\"metric\"] = \"multi_error\"\n",
        "            self.params[\"num_class\"] = self._num_classes or len(\n",
        "                np.unique(train_data.label))\n",
        "        else:\n",
        "            raise ValueError(f\"{self.__class__.__name__} is not supported for \"\n",
        "                             f\"{self.task_type}.\")\n",
        "\n",
        "        boost = lightgbm.train(\n",
        "            self.params, train_data, num_boost_round=num_boost_round,\n",
        "            categorical_feature=cat_features, valid_sets=[eval_data],\n",
        "            callbacks=[\n",
        "                lightgbm.early_stopping(stopping_rounds=50, verbose=False),\n",
        "                lightgbm.log_evaluation(period=2000)\n",
        "            ])\n",
        "        pred = self._predict_helper(boost, eval_data.data)\n",
        "        score = self.compute_metric(torch.from_numpy(eval_data.label),\n",
        "                                    torch.from_numpy(pred))\n",
        "        return score\n",
        "\n",
        "    def _tune(\n",
        "        self,\n",
        "        tf_train: TensorFrame,\n",
        "        tf_val: TensorFrame,\n",
        "        num_trials: int,\n",
        "        num_boost_round=2000,\n",
        "    ):\n",
        "        if self.task_type == TaskType.REGRESSION:\n",
        "            study = optuna.create_study(direction=\"minimize\")\n",
        "        else:\n",
        "            study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "        train_x, train_y, cat_features = self._to_lightgbm_input(tf_train)\n",
        "        val_x, val_y, _ = self._to_lightgbm_input(tf_val)\n",
        "        assert train_y is not None\n",
        "        assert val_y is not None\n",
        "        train_data = lightgbm.Dataset(train_x, label=train_y,\n",
        "                                      free_raw_data=False)\n",
        "        eval_data = lightgbm.Dataset(val_x, label=val_y, free_raw_data=False)\n",
        "\n",
        "        study.optimize(\n",
        "            lambda trial: self.objective(trial, train_data, eval_data,\n",
        "                                         cat_features, num_boost_round),\n",
        "            num_trials)\n",
        "        self.params.update(study.best_params)\n",
        "\n",
        "        self.model = lightgbm.train(\n",
        "            self.params, train_data, num_boost_round=num_boost_round,\n",
        "            categorical_feature=cat_features, valid_sets=[eval_data],\n",
        "            callbacks=[\n",
        "                lightgbm.early_stopping(stopping_rounds=50, verbose=False),\n",
        "                lightgbm.log_evaluation(period=2000)\n",
        "            ])\n",
        "\n",
        "    def _predict(self, tf_test: TensorFrame) -> Tensor:\n",
        "        device = tf_test.device\n",
        "        test_x, _, _ = self._to_lightgbm_input(tf_test)\n",
        "        pred = self._predict_helper(self.model, test_x)\n",
        "        return torch.from_numpy(pred).to(device)\n",
        "\n",
        "    def _load(self, path: str) -> None:\n",
        "        self.model = lightgbm.Booster(model_file=path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2WjlN43S8792"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Evaluation"
      ],
      "metadata": {
        "id": "7WPb0L2K47xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch_frame.data.Dataset(\n",
        "    df=dfs[\"train\"],\n",
        "    col_to_stype=col_to_stype,\n",
        "    target_col=target_col_name,\n",
        "    col_to_text_embedder_cfg=TextEmbedderConfig(\n",
        "        text_embedder=GloveTextEmbedding(device=device),\n",
        "        batch_size=512,\n",
        "    ),\n",
        ")\n",
        "train_dataset = train_dataset.materialize(device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd51100-0091-4fcf-f2cf-4a4b8cc53eae",
        "id": "emJ3hEjDoEhy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 36.22it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 79.33it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 38.43it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 85.68it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 66.25it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 80.31it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 81.22it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 76.63it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 71.81it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 64.75it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 75.45it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 14/14 [00:00<00:00, 74.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now anlyze the dataset and check out the newly introduced features."
      ],
      "metadata": {
        "id": "_9ueWXuysUGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "3f5d560a-2440-46c3-d17e-8a791e716640",
        "id": "gu8KgMbon_JQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   timestamp  customer_id article_id   FN  Active club_member_status  \\\n",
              "0 2020-07-20      1277347      68263  NaN     NaN             ACTIVE   \n",
              "1 2019-12-02       705424      73070  1.0     1.0             ACTIVE   \n",
              "2 2020-07-20       208528      98623  NaN     NaN             ACTIVE   \n",
              "3 2020-07-20       208528      84867  NaN     NaN             ACTIVE   \n",
              "4 2020-07-20       208528      62642  NaN     NaN             ACTIVE   \n",
              "\n",
              "  fashion_news_frequency   age  \\\n",
              "0                   NONE  18.0   \n",
              "1              Regularly  41.0   \n",
              "2                   NONE  24.0   \n",
              "3                   NONE  24.0   \n",
              "4                   NONE  24.0   \n",
              "\n",
              "                                         postal_code  \\\n",
              "0  0584da44f04a07d5e88012ad8243f2602432f0642097a2...   \n",
              "1  d9095bf603e105fb56b80dd6a05652110b255dfb1f46f4...   \n",
              "2  f35eaf6b194d1849fd777598f86c069974f0c65ea15c00...   \n",
              "3  f35eaf6b194d1849fd777598f86c069974f0c65ea15c00...   \n",
              "4  f35eaf6b194d1849fd777598f86c069974f0c65ea15c00...   \n",
              "\n",
              "   link_pred_baseline_target_column_name  ...        index_name  \\\n",
              "0                                      1  ...        Ladieswear   \n",
              "1                                      1  ...  Lingeries/Tights   \n",
              "2                                      1  ...           Divided   \n",
              "3                                      1  ...        Ladieswear   \n",
              "4                                      1  ...        Ladieswear   \n",
              "\n",
              "  index_group_no  index_group_name section_no                    section_name  \\\n",
              "0              1        Ladieswear         15      Womens Everyday Collection   \n",
              "1              1        Ladieswear         62  Womens Nightwear, Socks & Tigh   \n",
              "2              2           Divided         53              Divided Collection   \n",
              "3              1        Ladieswear         15      Womens Everyday Collection   \n",
              "4              1        Ladieswear         16          Womens Everyday Basics   \n",
              "\n",
              "   garment_group_no garment_group_name  \\\n",
              "0              1009           Trousers   \n",
              "1              1017  Under-, Nightwear   \n",
              "2              1005       Jersey Fancy   \n",
              "3              1010            Blouses   \n",
              "4              1002       Jersey Basic   \n",
              "\n",
              "                                         detail_desc num_past_visit  \\\n",
              "0  Trousers in woven fabric. High waist with plea...              1   \n",
              "1  Knee-length dressing gown in soft pile with a ...              1   \n",
              "2  Cropped top in ribbed jersey with short sleeve...              1   \n",
              "3  Short-sleeved wrapover blouse in linen with a ...              1   \n",
              "4  Tops in soft, organic cotton jersey with narro...              1   \n",
              "\n",
              "   global_popularity_fraction  \n",
              "0                    0.555556  \n",
              "1                    0.111111  \n",
              "2                    0.111111  \n",
              "3                    0.222222  \n",
              "4                    0.111111  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-675a8181-e529-4199-a432-1a92c4ebcb3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>FN</th>\n",
              "      <th>Active</th>\n",
              "      <th>club_member_status</th>\n",
              "      <th>fashion_news_frequency</th>\n",
              "      <th>age</th>\n",
              "      <th>postal_code</th>\n",
              "      <th>link_pred_baseline_target_column_name</th>\n",
              "      <th>...</th>\n",
              "      <th>index_name</th>\n",
              "      <th>index_group_no</th>\n",
              "      <th>index_group_name</th>\n",
              "      <th>section_no</th>\n",
              "      <th>section_name</th>\n",
              "      <th>garment_group_no</th>\n",
              "      <th>garment_group_name</th>\n",
              "      <th>detail_desc</th>\n",
              "      <th>num_past_visit</th>\n",
              "      <th>global_popularity_fraction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>1277347</td>\n",
              "      <td>68263</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0584da44f04a07d5e88012ad8243f2602432f0642097a2...</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Ladieswear</td>\n",
              "      <td>1</td>\n",
              "      <td>Ladieswear</td>\n",
              "      <td>15</td>\n",
              "      <td>Womens Everyday Collection</td>\n",
              "      <td>1009</td>\n",
              "      <td>Trousers</td>\n",
              "      <td>Trousers in woven fabric. High waist with plea...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-12-02</td>\n",
              "      <td>705424</td>\n",
              "      <td>73070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>Regularly</td>\n",
              "      <td>41.0</td>\n",
              "      <td>d9095bf603e105fb56b80dd6a05652110b255dfb1f46f4...</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Lingeries/Tights</td>\n",
              "      <td>1</td>\n",
              "      <td>Ladieswear</td>\n",
              "      <td>62</td>\n",
              "      <td>Womens Nightwear, Socks &amp; Tigh</td>\n",
              "      <td>1017</td>\n",
              "      <td>Under-, Nightwear</td>\n",
              "      <td>Knee-length dressing gown in soft pile with a ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>208528</td>\n",
              "      <td>98623</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>f35eaf6b194d1849fd777598f86c069974f0c65ea15c00...</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Divided</td>\n",
              "      <td>2</td>\n",
              "      <td>Divided</td>\n",
              "      <td>53</td>\n",
              "      <td>Divided Collection</td>\n",
              "      <td>1005</td>\n",
              "      <td>Jersey Fancy</td>\n",
              "      <td>Cropped top in ribbed jersey with short sleeve...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>208528</td>\n",
              "      <td>84867</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>f35eaf6b194d1849fd777598f86c069974f0c65ea15c00...</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Ladieswear</td>\n",
              "      <td>1</td>\n",
              "      <td>Ladieswear</td>\n",
              "      <td>15</td>\n",
              "      <td>Womens Everyday Collection</td>\n",
              "      <td>1010</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>Short-sleeved wrapover blouse in linen with a ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-07-20</td>\n",
              "      <td>208528</td>\n",
              "      <td>62642</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>f35eaf6b194d1849fd777598f86c069974f0c65ea15c00...</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Ladieswear</td>\n",
              "      <td>1</td>\n",
              "      <td>Ladieswear</td>\n",
              "      <td>16</td>\n",
              "      <td>Womens Everyday Basics</td>\n",
              "      <td>1002</td>\n",
              "      <td>Jersey Basic</td>\n",
              "      <td>Tops in soft, organic cotton jersey with narro...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-675a8181-e529-4199-a432-1a92c4ebcb3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-675a8181-e529-4199-a432-1a92c4ebcb3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-675a8181-e529-4199-a432-1a92c4ebcb3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6084c278-cf26-4a41-954f-85f1e2208706\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6084c278-cf26-4a41-954f-85f1e2208706')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6084c278-cf26-4a41-954f-85f1e2208706 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training, we need to transform tables into tensors."
      ],
      "metadata": {
        "id": "pCaOFKfdshOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train = train_dataset.tensor_frame\n",
        "tf_val = train_dataset.convert_to_tensor_frame(dfs[\"val\"])\n",
        "tf_val_pred = train_dataset.convert_to_tensor_frame(dfs[\"val_pred\"])\n",
        "tf_test = train_dataset.convert_to_tensor_frame(dfs[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea8fa63-d310-4549-ac19-23d1693c465a",
        "id": "QipPWl8uoIKd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 67.19it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 69.47it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 42.37it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 72.63it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 72.81it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 79.26it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 78.32it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 77.76it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 69.67it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 65.05it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 78.11it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 13/13 [00:00<00:00, 75.26it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 75.43it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 78.25it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 48.95it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 85.51it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 78.33it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 80.19it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 58.88it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 50.82it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:01<00:00, 45.22it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 51.06it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 77.87it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 72.27it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 76.02it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 78.04it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 47.47it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 85.32it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 80.23it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 81.08it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 79.38it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 78.14it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 72.13it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:01<00:00, 45.68it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 78.79it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 47/47 [00:00<00:00, 62.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TRIALS = 10\n",
        "\n",
        "# Train LighGBM\n",
        "tune_metric = Metric.ROCAUC\n",
        "lightgbm_model = LightGBM(task_type=train_dataset.task_type,\n",
        "                          metric=tune_metric)"
      ],
      "metadata": {
        "id": "aHmPNaKhXV67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm_model.tune(tf_train=tf_train,\n",
        "                    tf_val=tf_val,\n",
        "                    num_trials=NUM_TRIALS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0c9b02-4e7e-4231-eb2b-fc4531bcddb9",
        "id": "UmOI5gQsoNQz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 22:48:16,562] A new study created in memory with name: no-name-a34e7aa9-49e4-4e5d-bd0f-62e05e1e0143\n",
            "[I 2024-12-10 22:48:50,406] Trial 0 finished with value: 0.8530609460390436 and parameters: {'max_depth': 10, 'learning_rate': 0.048499447167924634, 'num_leaves': 505, 'subsample': 0.6754336171443361, 'colsample_bytree': 0.8118279295826983, 'lambda_l1': 3.116058485973789e-06, 'lambda_l2': 0.0003298669825740467, 'min_data_in_leaf': 86}. Best is trial 0 with value: 0.8530609460390436.\n",
            "[I 2024-12-10 22:49:33,688] Trial 1 finished with value: 0.8428766292224387 and parameters: {'max_depth': 10, 'learning_rate': 0.06270376970387177, 'num_leaves': 655, 'subsample': 0.6128006014420998, 'colsample_bytree': 0.2122855353422044, 'lambda_l1': 6.293166467265311e-05, 'lambda_l2': 8.522033681757318, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.8530609460390436.\n",
            "[I 2024-12-10 22:49:50,679] Trial 2 finished with value: 0.8404196496274747 and parameters: {'max_depth': 5, 'learning_rate': 0.007895661616613857, 'num_leaves': 777, 'subsample': 0.3388701828432555, 'colsample_bytree': 0.35178560557455724, 'lambda_l1': 7.638329916002945, 'lambda_l2': 1.0128205130988551e-06, 'min_data_in_leaf': 2}. Best is trial 0 with value: 0.8530609460390436.\n",
            "[I 2024-12-10 22:50:59,252] Trial 3 finished with value: 0.8527419485589783 and parameters: {'max_depth': 9, 'learning_rate': 0.008972445521815075, 'num_leaves': 599, 'subsample': 0.60989410221966, 'colsample_bytree': 0.7400119893939493, 'lambda_l1': 8.877945930654922e-08, 'lambda_l2': 0.026487075131144695, 'min_data_in_leaf': 42}. Best is trial 0 with value: 0.8530609460390436.\n",
            "[I 2024-12-10 22:53:08,180] Trial 4 finished with value: 0.8518824527874198 and parameters: {'max_depth': 8, 'learning_rate': 0.0036228746327781045, 'num_leaves': 689, 'subsample': 0.6977755233337191, 'colsample_bytree': 0.9136988659362927, 'lambda_l1': 0.04171899256923712, 'lambda_l2': 2.4287328615402265e-08, 'min_data_in_leaf': 71}. Best is trial 0 with value: 0.8530609460390436.\n",
            "[I 2024-12-10 22:56:13,078] Trial 5 finished with value: 0.8430061708855157 and parameters: {'max_depth': 10, 'learning_rate': 0.07519532174190058, 'num_leaves': 506, 'subsample': 0.33096479691235897, 'colsample_bytree': 0.9816953757191365, 'lambda_l1': 4.9554192063938985e-09, 'lambda_l2': 0.0004196516707401151, 'min_data_in_leaf': 2}. Best is trial 0 with value: 0.8530609460390436.\n",
            "[I 2024-12-10 22:56:34,463] Trial 6 finished with value: 0.8546397747736174 and parameters: {'max_depth': 7, 'learning_rate': 0.04184572719986247, 'num_leaves': 719, 'subsample': 0.501798607416569, 'colsample_bytree': 0.45912510942813606, 'lambda_l1': 0.021923933654140422, 'lambda_l2': 6.586350158169782, 'min_data_in_leaf': 31}. Best is trial 6 with value: 0.8546397747736174.\n",
            "[I 2024-12-10 22:56:42,034] Trial 7 finished with value: 0.8430539206506024 and parameters: {'max_depth': 3, 'learning_rate': 0.0011171190074971975, 'num_leaves': 836, 'subsample': 0.34104780068728807, 'colsample_bytree': 0.8765831731150556, 'lambda_l1': 3.0218975410672246e-09, 'lambda_l2': 0.0005135951993776105, 'min_data_in_leaf': 30}. Best is trial 6 with value: 0.8546397747736174.\n",
            "[I 2024-12-10 22:57:12,459] Trial 8 finished with value: 0.8507800323554587 and parameters: {'max_depth': 8, 'learning_rate': 0.004710655292836622, 'num_leaves': 793, 'subsample': 0.4717477409147634, 'colsample_bytree': 0.9383325048868462, 'lambda_l1': 2.753673525223678e-09, 'lambda_l2': 0.00036326440909292465, 'min_data_in_leaf': 99}. Best is trial 6 with value: 0.8546397747736174.\n",
            "[I 2024-12-10 22:57:17,433] Trial 9 finished with value: 0.8477092050199708 and parameters: {'max_depth': 3, 'learning_rate': 0.05042219974385089, 'num_leaves': 591, 'subsample': 0.6275230599131448, 'colsample_bytree': 0.46488791326008, 'lambda_l1': 0.012948654694023487, 'lambda_l2': 0.00011265917544832616, 'min_data_in_leaf': 30}. Best is trial 6 with value: 0.8546397747736174.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBoost\n",
        "tune_metric = Metric.ROCAUC\n",
        "xgboost_model = XGBoost(task_type=train_dataset.task_type,\n",
        "                        metric=tune_metric)"
      ],
      "metadata": {
        "id": "WD4WzPRxx5eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_model.tune(tf_train=tf_train,\n",
        "                   tf_val=tf_val,\n",
        "                   num_trials=NUM_TRIALS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edce550d-76e5-4bb6-8056-bec8d6249768",
        "id": "1JY6anYEoR4A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:11:19,183] A new study created in memory with name: no-name-c965d43f-d8f3-4748-9676-5705938697c6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.82086\n",
            "[1]\tvalidation-auc:0.82854\n",
            "[2]\tvalidation-auc:0.83051\n",
            "[3]\tvalidation-auc:0.83089\n",
            "[4]\tvalidation-auc:0.83187\n",
            "[5]\tvalidation-auc:0.83353\n",
            "[6]\tvalidation-auc:0.83529\n",
            "[7]\tvalidation-auc:0.83518\n",
            "[8]\tvalidation-auc:0.83536\n",
            "[9]\tvalidation-auc:0.83547\n",
            "[10]\tvalidation-auc:0.84004\n",
            "[11]\tvalidation-auc:0.84095\n",
            "[12]\tvalidation-auc:0.84242\n",
            "[13]\tvalidation-auc:0.84369\n",
            "[14]\tvalidation-auc:0.83749\n",
            "[15]\tvalidation-auc:0.83949\n",
            "[16]\tvalidation-auc:0.84010\n",
            "[17]\tvalidation-auc:0.84022\n",
            "[18]\tvalidation-auc:0.84138\n",
            "[19]\tvalidation-auc:0.83780\n",
            "[20]\tvalidation-auc:0.83899\n",
            "[21]\tvalidation-auc:0.84017\n",
            "[22]\tvalidation-auc:0.84097\n",
            "[23]\tvalidation-auc:0.83908\n",
            "[24]\tvalidation-auc:0.83944\n",
            "[25]\tvalidation-auc:0.84050\n",
            "[26]\tvalidation-auc:0.84149\n",
            "[27]\tvalidation-auc:0.84274\n",
            "[28]\tvalidation-auc:0.84336\n",
            "[29]\tvalidation-auc:0.84436\n",
            "[30]\tvalidation-auc:0.84449\n",
            "[31]\tvalidation-auc:0.84240\n",
            "[32]\tvalidation-auc:0.84344\n",
            "[33]\tvalidation-auc:0.84397\n",
            "[34]\tvalidation-auc:0.84463\n",
            "[35]\tvalidation-auc:0.84524\n",
            "[36]\tvalidation-auc:0.84600\n",
            "[37]\tvalidation-auc:0.84665\n",
            "[38]\tvalidation-auc:0.84670\n",
            "[39]\tvalidation-auc:0.84716\n",
            "[40]\tvalidation-auc:0.84821\n",
            "[41]\tvalidation-auc:0.84871\n",
            "[42]\tvalidation-auc:0.84943\n",
            "[43]\tvalidation-auc:0.85021\n",
            "[44]\tvalidation-auc:0.85017\n",
            "[45]\tvalidation-auc:0.84873\n",
            "[46]\tvalidation-auc:0.84940\n",
            "[47]\tvalidation-auc:0.84971\n",
            "[48]\tvalidation-auc:0.84817\n",
            "[49]\tvalidation-auc:0.84871\n",
            "[50]\tvalidation-auc:0.84744\n",
            "[51]\tvalidation-auc:0.84826\n",
            "[52]\tvalidation-auc:0.84811\n",
            "[53]\tvalidation-auc:0.84836\n",
            "[54]\tvalidation-auc:0.84921\n",
            "[55]\tvalidation-auc:0.84728\n",
            "[56]\tvalidation-auc:0.84636\n",
            "[57]\tvalidation-auc:0.84697\n",
            "[58]\tvalidation-auc:0.84771\n",
            "[59]\tvalidation-auc:0.84791\n",
            "[60]\tvalidation-auc:0.84799\n",
            "[61]\tvalidation-auc:0.84855\n",
            "[62]\tvalidation-auc:0.84881\n",
            "[63]\tvalidation-auc:0.84905\n",
            "[64]\tvalidation-auc:0.84891\n",
            "[65]\tvalidation-auc:0.84782\n",
            "[66]\tvalidation-auc:0.84770\n",
            "[67]\tvalidation-auc:0.84791\n",
            "[68]\tvalidation-auc:0.84808\n",
            "[69]\tvalidation-auc:0.84803\n",
            "[70]\tvalidation-auc:0.84674\n",
            "[71]\tvalidation-auc:0.84546\n",
            "[72]\tvalidation-auc:0.84541\n",
            "[73]\tvalidation-auc:0.84572\n",
            "[74]\tvalidation-auc:0.84559\n",
            "[75]\tvalidation-auc:0.84581\n",
            "[76]\tvalidation-auc:0.84636\n",
            "[77]\tvalidation-auc:0.84651\n",
            "[78]\tvalidation-auc:0.84656\n",
            "[79]\tvalidation-auc:0.84672\n",
            "[80]\tvalidation-auc:0.84687\n",
            "[81]\tvalidation-auc:0.84707\n",
            "[82]\tvalidation-auc:0.84736\n",
            "[83]\tvalidation-auc:0.84755\n",
            "[84]\tvalidation-auc:0.84754\n",
            "[85]\tvalidation-auc:0.84765\n",
            "[86]\tvalidation-auc:0.84799\n",
            "[87]\tvalidation-auc:0.84813\n",
            "[88]\tvalidation-auc:0.84825\n",
            "[89]\tvalidation-auc:0.84820\n",
            "[90]\tvalidation-auc:0.84813\n",
            "[91]\tvalidation-auc:0.84858\n",
            "[92]\tvalidation-auc:0.84891\n",
            "[93]\tvalidation-auc:0.84727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:11:21,401] Trial 0 finished with value: 0.8472706061796367 and parameters: {'max_depth': 3, 'learning_rate': 0.055745809595654096, 'subsample': 0.90813823473549, 'colsample_bytree': 0.8011343972341652, 'lambda': 3.2728397828723335e-08, 'alpha': 6.846296738400049e-06}. Best is trial 0 with value: 0.8472706061796367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.80652\n",
            "[1]\tvalidation-auc:0.82711\n",
            "[2]\tvalidation-auc:0.82721\n",
            "[3]\tvalidation-auc:0.83644\n",
            "[4]\tvalidation-auc:0.84271\n",
            "[5]\tvalidation-auc:0.83794\n",
            "[6]\tvalidation-auc:0.83079\n",
            "[7]\tvalidation-auc:0.83011\n",
            "[8]\tvalidation-auc:0.83022\n",
            "[9]\tvalidation-auc:0.82180\n",
            "[10]\tvalidation-auc:0.82161\n",
            "[11]\tvalidation-auc:0.82204\n",
            "[12]\tvalidation-auc:0.82418\n",
            "[13]\tvalidation-auc:0.82308\n",
            "[14]\tvalidation-auc:0.82684\n",
            "[15]\tvalidation-auc:0.82665\n",
            "[16]\tvalidation-auc:0.82700\n",
            "[17]\tvalidation-auc:0.82818\n",
            "[18]\tvalidation-auc:0.82958\n",
            "[19]\tvalidation-auc:0.82999\n",
            "[20]\tvalidation-auc:0.83082\n",
            "[21]\tvalidation-auc:0.83368\n",
            "[22]\tvalidation-auc:0.83264\n",
            "[23]\tvalidation-auc:0.83340\n",
            "[24]\tvalidation-auc:0.83332\n",
            "[25]\tvalidation-auc:0.83415\n",
            "[26]\tvalidation-auc:0.83348\n",
            "[27]\tvalidation-auc:0.83496\n",
            "[28]\tvalidation-auc:0.83440\n",
            "[29]\tvalidation-auc:0.83462\n",
            "[30]\tvalidation-auc:0.83506\n",
            "[31]\tvalidation-auc:0.83412\n",
            "[32]\tvalidation-auc:0.83554\n",
            "[33]\tvalidation-auc:0.83469\n",
            "[34]\tvalidation-auc:0.83533\n",
            "[35]\tvalidation-auc:0.83551\n",
            "[36]\tvalidation-auc:0.83507\n",
            "[37]\tvalidation-auc:0.83519\n",
            "[38]\tvalidation-auc:0.83562\n",
            "[39]\tvalidation-auc:0.83564\n",
            "[40]\tvalidation-auc:0.83511\n",
            "[41]\tvalidation-auc:0.83505\n",
            "[42]\tvalidation-auc:0.83479\n",
            "[43]\tvalidation-auc:0.83403\n",
            "[44]\tvalidation-auc:0.83412\n",
            "[45]\tvalidation-auc:0.83427\n",
            "[46]\tvalidation-auc:0.83627\n",
            "[47]\tvalidation-auc:0.83606\n",
            "[48]\tvalidation-auc:0.83585\n",
            "[49]\tvalidation-auc:0.83577\n",
            "[50]\tvalidation-auc:0.83559\n",
            "[51]\tvalidation-auc:0.83481\n",
            "[52]\tvalidation-auc:0.83477\n",
            "[53]\tvalidation-auc:0.83451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:11:22,918] Trial 1 finished with value: 0.8338651773581507 and parameters: {'max_depth': 5, 'learning_rate': 0.2474040447483419, 'subsample': 0.7905196664933589, 'colsample_bytree': 0.803132179398331, 'lambda': 8.73242667842769e-07, 'alpha': 4.911540726451648e-06}. Best is trial 0 with value: 0.8472706061796367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.82597\n",
            "[1]\tvalidation-auc:0.83771\n",
            "[2]\tvalidation-auc:0.82338\n",
            "[3]\tvalidation-auc:0.82918\n",
            "[4]\tvalidation-auc:0.82432\n",
            "[5]\tvalidation-auc:0.82094\n",
            "[6]\tvalidation-auc:0.81998\n",
            "[7]\tvalidation-auc:0.81888\n",
            "[8]\tvalidation-auc:0.82122\n",
            "[9]\tvalidation-auc:0.82363\n",
            "[10]\tvalidation-auc:0.82520\n",
            "[11]\tvalidation-auc:0.82651\n",
            "[12]\tvalidation-auc:0.82546\n",
            "[13]\tvalidation-auc:0.82733\n",
            "[14]\tvalidation-auc:0.82632\n",
            "[15]\tvalidation-auc:0.82895\n",
            "[16]\tvalidation-auc:0.82778\n",
            "[17]\tvalidation-auc:0.82852\n",
            "[18]\tvalidation-auc:0.82967\n",
            "[19]\tvalidation-auc:0.83003\n",
            "[20]\tvalidation-auc:0.83012\n",
            "[21]\tvalidation-auc:0.83075\n",
            "[22]\tvalidation-auc:0.83150\n",
            "[23]\tvalidation-auc:0.83166\n",
            "[24]\tvalidation-auc:0.83280\n",
            "[25]\tvalidation-auc:0.83353\n",
            "[26]\tvalidation-auc:0.83387\n",
            "[27]\tvalidation-auc:0.83564\n",
            "[28]\tvalidation-auc:0.83688\n",
            "[29]\tvalidation-auc:0.83558\n",
            "[30]\tvalidation-auc:0.83641\n",
            "[31]\tvalidation-auc:0.83537\n",
            "[32]\tvalidation-auc:0.83645\n",
            "[33]\tvalidation-auc:0.83722\n",
            "[34]\tvalidation-auc:0.83826\n",
            "[35]\tvalidation-auc:0.83788\n",
            "[36]\tvalidation-auc:0.83860\n",
            "[37]\tvalidation-auc:0.83815\n",
            "[38]\tvalidation-auc:0.83879\n",
            "[39]\tvalidation-auc:0.83936\n",
            "[40]\tvalidation-auc:0.83917\n",
            "[41]\tvalidation-auc:0.83918\n",
            "[42]\tvalidation-auc:0.83966\n",
            "[43]\tvalidation-auc:0.83906\n",
            "[44]\tvalidation-auc:0.83865\n",
            "[45]\tvalidation-auc:0.83935\n",
            "[46]\tvalidation-auc:0.84002\n",
            "[47]\tvalidation-auc:0.83968\n",
            "[48]\tvalidation-auc:0.83926\n",
            "[49]\tvalidation-auc:0.83910\n",
            "[50]\tvalidation-auc:0.83872\n",
            "[51]\tvalidation-auc:0.83928\n",
            "[52]\tvalidation-auc:0.83963\n",
            "[53]\tvalidation-auc:0.84038\n",
            "[54]\tvalidation-auc:0.84068\n",
            "[55]\tvalidation-auc:0.84080\n",
            "[56]\tvalidation-auc:0.84118\n",
            "[57]\tvalidation-auc:0.84143\n",
            "[58]\tvalidation-auc:0.84168\n",
            "[59]\tvalidation-auc:0.84212\n",
            "[60]\tvalidation-auc:0.84228\n",
            "[61]\tvalidation-auc:0.84259\n",
            "[62]\tvalidation-auc:0.84291\n",
            "[63]\tvalidation-auc:0.84301\n",
            "[64]\tvalidation-auc:0.84338\n",
            "[65]\tvalidation-auc:0.84363\n",
            "[66]\tvalidation-auc:0.84394\n",
            "[67]\tvalidation-auc:0.84409\n",
            "[68]\tvalidation-auc:0.84430\n",
            "[69]\tvalidation-auc:0.84483\n",
            "[70]\tvalidation-auc:0.84499\n",
            "[71]\tvalidation-auc:0.84533\n",
            "[72]\tvalidation-auc:0.84485\n",
            "[73]\tvalidation-auc:0.84468\n",
            "[74]\tvalidation-auc:0.84510\n",
            "[75]\tvalidation-auc:0.84538\n",
            "[76]\tvalidation-auc:0.84529\n",
            "[77]\tvalidation-auc:0.84574\n",
            "[78]\tvalidation-auc:0.84596\n",
            "[79]\tvalidation-auc:0.84592\n",
            "[80]\tvalidation-auc:0.84617\n",
            "[81]\tvalidation-auc:0.84616\n",
            "[82]\tvalidation-auc:0.84643\n",
            "[83]\tvalidation-auc:0.84654\n",
            "[84]\tvalidation-auc:0.84664\n",
            "[85]\tvalidation-auc:0.84712\n",
            "[86]\tvalidation-auc:0.84668\n",
            "[87]\tvalidation-auc:0.84654\n",
            "[88]\tvalidation-auc:0.84607\n",
            "[89]\tvalidation-auc:0.84622\n",
            "[90]\tvalidation-auc:0.84627\n",
            "[91]\tvalidation-auc:0.84670\n",
            "[92]\tvalidation-auc:0.84689\n",
            "[93]\tvalidation-auc:0.84719\n",
            "[94]\tvalidation-auc:0.84752\n",
            "[95]\tvalidation-auc:0.84779\n",
            "[96]\tvalidation-auc:0.84796\n",
            "[97]\tvalidation-auc:0.84774\n",
            "[98]\tvalidation-auc:0.84768\n",
            "[99]\tvalidation-auc:0.84780\n",
            "[100]\tvalidation-auc:0.84759\n",
            "[101]\tvalidation-auc:0.84724\n",
            "[102]\tvalidation-auc:0.84696\n",
            "[103]\tvalidation-auc:0.84649\n",
            "[104]\tvalidation-auc:0.84653\n",
            "[105]\tvalidation-auc:0.84663\n",
            "[106]\tvalidation-auc:0.84673\n",
            "[107]\tvalidation-auc:0.84693\n",
            "[108]\tvalidation-auc:0.84732\n",
            "[109]\tvalidation-auc:0.84707\n",
            "[110]\tvalidation-auc:0.84731\n",
            "[111]\tvalidation-auc:0.84745\n",
            "[112]\tvalidation-auc:0.84760\n",
            "[113]\tvalidation-auc:0.84783\n",
            "[114]\tvalidation-auc:0.84791\n",
            "[115]\tvalidation-auc:0.84806\n",
            "[116]\tvalidation-auc:0.84828\n",
            "[117]\tvalidation-auc:0.84785\n",
            "[118]\tvalidation-auc:0.84793\n",
            "[119]\tvalidation-auc:0.84813\n",
            "[120]\tvalidation-auc:0.84823\n",
            "[121]\tvalidation-auc:0.84835\n",
            "[122]\tvalidation-auc:0.84844\n",
            "[123]\tvalidation-auc:0.84873\n",
            "[124]\tvalidation-auc:0.84888\n",
            "[125]\tvalidation-auc:0.84907\n",
            "[126]\tvalidation-auc:0.84922\n",
            "[127]\tvalidation-auc:0.84924\n",
            "[128]\tvalidation-auc:0.84922\n",
            "[129]\tvalidation-auc:0.84931\n",
            "[130]\tvalidation-auc:0.84950\n",
            "[131]\tvalidation-auc:0.84949\n",
            "[132]\tvalidation-auc:0.84966\n",
            "[133]\tvalidation-auc:0.84947\n",
            "[134]\tvalidation-auc:0.84963\n",
            "[135]\tvalidation-auc:0.84961\n",
            "[136]\tvalidation-auc:0.84956\n",
            "[137]\tvalidation-auc:0.84912\n",
            "[138]\tvalidation-auc:0.84929\n",
            "[139]\tvalidation-auc:0.84947\n",
            "[140]\tvalidation-auc:0.84967\n",
            "[141]\tvalidation-auc:0.84970\n",
            "[142]\tvalidation-auc:0.84996\n",
            "[143]\tvalidation-auc:0.84997\n",
            "[144]\tvalidation-auc:0.85014\n",
            "[145]\tvalidation-auc:0.85017\n",
            "[146]\tvalidation-auc:0.85021\n",
            "[147]\tvalidation-auc:0.85038\n",
            "[148]\tvalidation-auc:0.85055\n",
            "[149]\tvalidation-auc:0.85061\n",
            "[150]\tvalidation-auc:0.85084\n",
            "[151]\tvalidation-auc:0.85110\n",
            "[152]\tvalidation-auc:0.85124\n",
            "[153]\tvalidation-auc:0.85117\n",
            "[154]\tvalidation-auc:0.85136\n",
            "[155]\tvalidation-auc:0.85131\n",
            "[156]\tvalidation-auc:0.85146\n",
            "[157]\tvalidation-auc:0.85167\n",
            "[158]\tvalidation-auc:0.85187\n",
            "[159]\tvalidation-auc:0.85189\n",
            "[160]\tvalidation-auc:0.85183\n",
            "[161]\tvalidation-auc:0.85196\n",
            "[162]\tvalidation-auc:0.85216\n",
            "[163]\tvalidation-auc:0.85212\n",
            "[164]\tvalidation-auc:0.85209\n",
            "[165]\tvalidation-auc:0.85235\n",
            "[166]\tvalidation-auc:0.85237\n",
            "[167]\tvalidation-auc:0.85235\n",
            "[168]\tvalidation-auc:0.85231\n",
            "[169]\tvalidation-auc:0.85237\n",
            "[170]\tvalidation-auc:0.85240\n",
            "[171]\tvalidation-auc:0.85236\n",
            "[172]\tvalidation-auc:0.85252\n",
            "[173]\tvalidation-auc:0.85252\n",
            "[174]\tvalidation-auc:0.85251\n",
            "[175]\tvalidation-auc:0.85188\n",
            "[176]\tvalidation-auc:0.85202\n",
            "[177]\tvalidation-auc:0.85208\n",
            "[178]\tvalidation-auc:0.85196\n",
            "[179]\tvalidation-auc:0.85195\n",
            "[180]\tvalidation-auc:0.85149\n",
            "[181]\tvalidation-auc:0.85162\n",
            "[182]\tvalidation-auc:0.85123\n",
            "[183]\tvalidation-auc:0.85121\n",
            "[184]\tvalidation-auc:0.85126\n",
            "[185]\tvalidation-auc:0.85064\n",
            "[186]\tvalidation-auc:0.85075\n",
            "[187]\tvalidation-auc:0.85081\n",
            "[188]\tvalidation-auc:0.85084\n",
            "[189]\tvalidation-auc:0.85094\n",
            "[190]\tvalidation-auc:0.85095\n",
            "[191]\tvalidation-auc:0.85051\n",
            "[192]\tvalidation-auc:0.85047\n",
            "[193]\tvalidation-auc:0.85049\n",
            "[194]\tvalidation-auc:0.85038\n",
            "[195]\tvalidation-auc:0.85048\n",
            "[196]\tvalidation-auc:0.85040\n",
            "[197]\tvalidation-auc:0.85040\n",
            "[198]\tvalidation-auc:0.85062\n",
            "[199]\tvalidation-auc:0.85075\n",
            "[200]\tvalidation-auc:0.85083\n",
            "[201]\tvalidation-auc:0.85089\n",
            "[202]\tvalidation-auc:0.85116\n",
            "[203]\tvalidation-auc:0.85127\n",
            "[204]\tvalidation-auc:0.85141\n",
            "[205]\tvalidation-auc:0.85147\n",
            "[206]\tvalidation-auc:0.85138\n",
            "[207]\tvalidation-auc:0.85142\n",
            "[208]\tvalidation-auc:0.85131\n",
            "[209]\tvalidation-auc:0.85134\n",
            "[210]\tvalidation-auc:0.85140\n",
            "[211]\tvalidation-auc:0.85157\n",
            "[212]\tvalidation-auc:0.85171\n",
            "[213]\tvalidation-auc:0.85183\n",
            "[214]\tvalidation-auc:0.85182\n",
            "[215]\tvalidation-auc:0.85186\n",
            "[216]\tvalidation-auc:0.85185\n",
            "[217]\tvalidation-auc:0.85200\n",
            "[218]\tvalidation-auc:0.85201\n",
            "[219]\tvalidation-auc:0.85209\n",
            "[220]\tvalidation-auc:0.85225\n",
            "[221]\tvalidation-auc:0.85232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:11:27,734] Trial 2 finished with value: 0.8524818666635923 and parameters: {'max_depth': 4, 'learning_rate': 0.030079090812104477, 'subsample': 0.8973097478044262, 'colsample_bytree': 0.8333003438681112, 'lambda': 7.238752402364147e-05, 'alpha': 1.1854026063298904}. Best is trial 2 with value: 0.8524818666635923.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.72048\n",
            "[1]\tvalidation-auc:0.79816\n",
            "[2]\tvalidation-auc:0.81724\n",
            "[3]\tvalidation-auc:0.82673\n",
            "[4]\tvalidation-auc:0.83316\n",
            "[5]\tvalidation-auc:0.83096\n",
            "[6]\tvalidation-auc:0.83247\n",
            "[7]\tvalidation-auc:0.83438\n",
            "[8]\tvalidation-auc:0.83563\n",
            "[9]\tvalidation-auc:0.83356\n",
            "[10]\tvalidation-auc:0.83534\n",
            "[11]\tvalidation-auc:0.83639\n",
            "[12]\tvalidation-auc:0.83670\n",
            "[13]\tvalidation-auc:0.83709\n",
            "[14]\tvalidation-auc:0.83798\n",
            "[15]\tvalidation-auc:0.83805\n",
            "[16]\tvalidation-auc:0.83693\n",
            "[17]\tvalidation-auc:0.83691\n",
            "[18]\tvalidation-auc:0.83812\n",
            "[19]\tvalidation-auc:0.83871\n",
            "[20]\tvalidation-auc:0.83826\n",
            "[21]\tvalidation-auc:0.83853\n",
            "[22]\tvalidation-auc:0.83955\n",
            "[23]\tvalidation-auc:0.83963\n",
            "[24]\tvalidation-auc:0.84030\n",
            "[25]\tvalidation-auc:0.84065\n",
            "[26]\tvalidation-auc:0.84064\n",
            "[27]\tvalidation-auc:0.84013\n",
            "[28]\tvalidation-auc:0.83999\n",
            "[29]\tvalidation-auc:0.84070\n",
            "[30]\tvalidation-auc:0.84125\n",
            "[31]\tvalidation-auc:0.84127\n",
            "[32]\tvalidation-auc:0.84115\n",
            "[33]\tvalidation-auc:0.84148\n",
            "[34]\tvalidation-auc:0.84141\n",
            "[35]\tvalidation-auc:0.84197\n",
            "[36]\tvalidation-auc:0.84212\n",
            "[37]\tvalidation-auc:0.84183\n",
            "[38]\tvalidation-auc:0.84154\n",
            "[39]\tvalidation-auc:0.84148\n",
            "[40]\tvalidation-auc:0.84157\n",
            "[41]\tvalidation-auc:0.84103\n",
            "[42]\tvalidation-auc:0.84099\n",
            "[43]\tvalidation-auc:0.84093\n",
            "[44]\tvalidation-auc:0.84080\n",
            "[45]\tvalidation-auc:0.84174\n",
            "[46]\tvalidation-auc:0.84157\n",
            "[47]\tvalidation-auc:0.84134\n",
            "[48]\tvalidation-auc:0.84193\n",
            "[49]\tvalidation-auc:0.84189\n",
            "[50]\tvalidation-auc:0.84153\n",
            "[51]\tvalidation-auc:0.84151\n",
            "[52]\tvalidation-auc:0.84187\n",
            "[53]\tvalidation-auc:0.84218\n",
            "[54]\tvalidation-auc:0.84238\n",
            "[55]\tvalidation-auc:0.84216\n",
            "[56]\tvalidation-auc:0.84188\n",
            "[57]\tvalidation-auc:0.84180\n",
            "[58]\tvalidation-auc:0.84215\n",
            "[59]\tvalidation-auc:0.84229\n",
            "[60]\tvalidation-auc:0.84224\n",
            "[61]\tvalidation-auc:0.84243\n",
            "[62]\tvalidation-auc:0.84263\n",
            "[63]\tvalidation-auc:0.84267\n",
            "[64]\tvalidation-auc:0.84284\n",
            "[65]\tvalidation-auc:0.84285\n",
            "[66]\tvalidation-auc:0.84247\n",
            "[67]\tvalidation-auc:0.84278\n",
            "[68]\tvalidation-auc:0.84262\n",
            "[69]\tvalidation-auc:0.84291\n",
            "[70]\tvalidation-auc:0.84321\n",
            "[71]\tvalidation-auc:0.84311\n",
            "[72]\tvalidation-auc:0.84304\n",
            "[73]\tvalidation-auc:0.84338\n",
            "[74]\tvalidation-auc:0.84324\n",
            "[75]\tvalidation-auc:0.84326\n",
            "[76]\tvalidation-auc:0.84368\n",
            "[77]\tvalidation-auc:0.84368\n",
            "[78]\tvalidation-auc:0.84389\n",
            "[79]\tvalidation-auc:0.84383\n",
            "[80]\tvalidation-auc:0.84359\n",
            "[81]\tvalidation-auc:0.84359\n",
            "[82]\tvalidation-auc:0.84343\n",
            "[83]\tvalidation-auc:0.84330\n",
            "[84]\tvalidation-auc:0.84331\n",
            "[85]\tvalidation-auc:0.84339\n",
            "[86]\tvalidation-auc:0.84346\n",
            "[87]\tvalidation-auc:0.84389\n",
            "[88]\tvalidation-auc:0.84335\n",
            "[89]\tvalidation-auc:0.84325\n",
            "[90]\tvalidation-auc:0.84302\n",
            "[91]\tvalidation-auc:0.84307\n",
            "[92]\tvalidation-auc:0.84309\n",
            "[93]\tvalidation-auc:0.84273\n",
            "[94]\tvalidation-auc:0.84275\n",
            "[95]\tvalidation-auc:0.84288\n",
            "[96]\tvalidation-auc:0.84270\n",
            "[97]\tvalidation-auc:0.84288\n",
            "[98]\tvalidation-auc:0.84294\n",
            "[99]\tvalidation-auc:0.84317\n",
            "[100]\tvalidation-auc:0.84303\n",
            "[101]\tvalidation-auc:0.84288\n",
            "[102]\tvalidation-auc:0.84299\n",
            "[103]\tvalidation-auc:0.84286\n",
            "[104]\tvalidation-auc:0.84321\n",
            "[105]\tvalidation-auc:0.84333\n",
            "[106]\tvalidation-auc:0.84331\n",
            "[107]\tvalidation-auc:0.84327\n",
            "[108]\tvalidation-auc:0.84333\n",
            "[109]\tvalidation-auc:0.84341\n",
            "[110]\tvalidation-auc:0.84358\n",
            "[111]\tvalidation-auc:0.84346\n",
            "[112]\tvalidation-auc:0.84355\n",
            "[113]\tvalidation-auc:0.84354\n",
            "[114]\tvalidation-auc:0.84366\n",
            "[115]\tvalidation-auc:0.84365\n",
            "[116]\tvalidation-auc:0.84390\n",
            "[117]\tvalidation-auc:0.84395\n",
            "[118]\tvalidation-auc:0.84410\n",
            "[119]\tvalidation-auc:0.84446\n",
            "[120]\tvalidation-auc:0.84420\n",
            "[121]\tvalidation-auc:0.84411\n",
            "[122]\tvalidation-auc:0.84384\n",
            "[123]\tvalidation-auc:0.84381\n",
            "[124]\tvalidation-auc:0.84365\n",
            "[125]\tvalidation-auc:0.84364\n",
            "[126]\tvalidation-auc:0.84390\n",
            "[127]\tvalidation-auc:0.84369\n",
            "[128]\tvalidation-auc:0.84379\n",
            "[129]\tvalidation-auc:0.84369\n",
            "[130]\tvalidation-auc:0.84358\n",
            "[131]\tvalidation-auc:0.84373\n",
            "[132]\tvalidation-auc:0.84360\n",
            "[133]\tvalidation-auc:0.84388\n",
            "[134]\tvalidation-auc:0.84385\n",
            "[135]\tvalidation-auc:0.84376\n",
            "[136]\tvalidation-auc:0.84389\n",
            "[137]\tvalidation-auc:0.84379\n",
            "[138]\tvalidation-auc:0.84386\n",
            "[139]\tvalidation-auc:0.84387\n",
            "[140]\tvalidation-auc:0.84398\n",
            "[141]\tvalidation-auc:0.84419\n",
            "[142]\tvalidation-auc:0.84435\n",
            "[143]\tvalidation-auc:0.84425\n",
            "[144]\tvalidation-auc:0.84413\n",
            "[145]\tvalidation-auc:0.84405\n",
            "[146]\tvalidation-auc:0.84410\n",
            "[147]\tvalidation-auc:0.84430\n",
            "[148]\tvalidation-auc:0.84444\n",
            "[149]\tvalidation-auc:0.84425\n",
            "[150]\tvalidation-auc:0.84413\n",
            "[151]\tvalidation-auc:0.84410\n",
            "[152]\tvalidation-auc:0.84388\n",
            "[153]\tvalidation-auc:0.84404\n",
            "[154]\tvalidation-auc:0.84399\n",
            "[155]\tvalidation-auc:0.84400\n",
            "[156]\tvalidation-auc:0.84391\n",
            "[157]\tvalidation-auc:0.84389\n",
            "[158]\tvalidation-auc:0.84355\n",
            "[159]\tvalidation-auc:0.84350\n",
            "[160]\tvalidation-auc:0.84356\n",
            "[161]\tvalidation-auc:0.84383\n",
            "[162]\tvalidation-auc:0.84377\n",
            "[163]\tvalidation-auc:0.84375\n",
            "[164]\tvalidation-auc:0.84373\n",
            "[165]\tvalidation-auc:0.84366\n",
            "[166]\tvalidation-auc:0.84354\n",
            "[167]\tvalidation-auc:0.84347\n",
            "[168]\tvalidation-auc:0.84339\n",
            "[169]\tvalidation-auc:0.84326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:11:50,934] Trial 3 finished with value: 0.8432616684403373 and parameters: {'max_depth': 10, 'learning_rate': 0.03441864631825322, 'subsample': 0.8120883049488828, 'colsample_bytree': 0.6763690718113979, 'lambda': 2.556807890506349e-05, 'alpha': 3.2335517948689755e-09}. Best is trial 2 with value: 0.8524818666635923.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.70272\n",
            "[1]\tvalidation-auc:0.78030\n",
            "[2]\tvalidation-auc:0.80218\n",
            "[3]\tvalidation-auc:0.81739\n",
            "[4]\tvalidation-auc:0.81528\n",
            "[5]\tvalidation-auc:0.82142\n",
            "[6]\tvalidation-auc:0.82357\n",
            "[7]\tvalidation-auc:0.82562\n",
            "[8]\tvalidation-auc:0.82692\n",
            "[9]\tvalidation-auc:0.82525\n",
            "[10]\tvalidation-auc:0.82771\n",
            "[11]\tvalidation-auc:0.82686\n",
            "[12]\tvalidation-auc:0.82882\n",
            "[13]\tvalidation-auc:0.82975\n",
            "[14]\tvalidation-auc:0.83110\n",
            "[15]\tvalidation-auc:0.83359\n",
            "[16]\tvalidation-auc:0.83510\n",
            "[17]\tvalidation-auc:0.83386\n",
            "[18]\tvalidation-auc:0.83534\n",
            "[19]\tvalidation-auc:0.83783\n",
            "[20]\tvalidation-auc:0.83861\n",
            "[21]\tvalidation-auc:0.83909\n",
            "[22]\tvalidation-auc:0.84024\n",
            "[23]\tvalidation-auc:0.83885\n",
            "[24]\tvalidation-auc:0.83836\n",
            "[25]\tvalidation-auc:0.83873\n",
            "[26]\tvalidation-auc:0.83856\n",
            "[27]\tvalidation-auc:0.83875\n",
            "[28]\tvalidation-auc:0.83759\n",
            "[29]\tvalidation-auc:0.83834\n",
            "[30]\tvalidation-auc:0.83721\n",
            "[31]\tvalidation-auc:0.83798\n",
            "[32]\tvalidation-auc:0.83773\n",
            "[33]\tvalidation-auc:0.83628\n",
            "[34]\tvalidation-auc:0.83658\n",
            "[35]\tvalidation-auc:0.83662\n",
            "[36]\tvalidation-auc:0.83624\n",
            "[37]\tvalidation-auc:0.83640\n",
            "[38]\tvalidation-auc:0.83651\n",
            "[39]\tvalidation-auc:0.83693\n",
            "[40]\tvalidation-auc:0.83732\n",
            "[41]\tvalidation-auc:0.83680\n",
            "[42]\tvalidation-auc:0.83755\n",
            "[43]\tvalidation-auc:0.83662\n",
            "[44]\tvalidation-auc:0.83648\n",
            "[45]\tvalidation-auc:0.83710\n",
            "[46]\tvalidation-auc:0.83785\n",
            "[47]\tvalidation-auc:0.83765\n",
            "[48]\tvalidation-auc:0.83841\n",
            "[49]\tvalidation-auc:0.83820\n",
            "[50]\tvalidation-auc:0.83777\n",
            "[51]\tvalidation-auc:0.83762\n",
            "[52]\tvalidation-auc:0.83714\n",
            "[53]\tvalidation-auc:0.83710\n",
            "[54]\tvalidation-auc:0.83748\n",
            "[55]\tvalidation-auc:0.83730\n",
            "[56]\tvalidation-auc:0.83724\n",
            "[57]\tvalidation-auc:0.83633\n",
            "[58]\tvalidation-auc:0.83716\n",
            "[59]\tvalidation-auc:0.83686\n",
            "[60]\tvalidation-auc:0.83682\n",
            "[61]\tvalidation-auc:0.83705\n",
            "[62]\tvalidation-auc:0.83701\n",
            "[63]\tvalidation-auc:0.83759\n",
            "[64]\tvalidation-auc:0.83735\n",
            "[65]\tvalidation-auc:0.83704\n",
            "[66]\tvalidation-auc:0.83738\n",
            "[67]\tvalidation-auc:0.83758\n",
            "[68]\tvalidation-auc:0.83839\n",
            "[69]\tvalidation-auc:0.83825\n",
            "[70]\tvalidation-auc:0.83827\n",
            "[71]\tvalidation-auc:0.83812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:12:00,529] Trial 4 finished with value: 0.8380256252836277 and parameters: {'max_depth': 10, 'learning_rate': 0.14532446284305878, 'subsample': 0.671630802841204, 'colsample_bytree': 0.9815616562720384, 'lambda': 6.000402459889521e-08, 'alpha': 1.8884356627529005e-06}. Best is trial 2 with value: 0.8524818666635923.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.79575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:12:00,561] Trial 5 pruned. Trial was pruned at iteration 0.\n",
            "[I 2024-12-10 23:12:00,671] Trial 6 pruned. Trial was pruned at iteration 0.\n",
            "[I 2024-12-10 23:12:00,736] Trial 7 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.82550\n",
            "[1]\tvalidation-auc:0.83200\n",
            "[2]\tvalidation-auc:0.83174\n",
            "[3]\tvalidation-auc:0.83338\n",
            "[4]\tvalidation-auc:0.83577\n",
            "[5]\tvalidation-auc:0.83573\n",
            "[6]\tvalidation-auc:0.84034\n",
            "[7]\tvalidation-auc:0.84068\n",
            "[8]\tvalidation-auc:0.84478\n",
            "[9]\tvalidation-auc:0.83657\n",
            "[10]\tvalidation-auc:0.83951\n",
            "[11]\tvalidation-auc:0.83868\n",
            "[12]\tvalidation-auc:0.84059\n",
            "[13]\tvalidation-auc:0.84244\n",
            "[14]\tvalidation-auc:0.83997\n",
            "[15]\tvalidation-auc:0.83731\n",
            "[16]\tvalidation-auc:0.83808\n",
            "[17]\tvalidation-auc:0.83938\n",
            "[18]\tvalidation-auc:0.84090\n",
            "[19]\tvalidation-auc:0.84114\n",
            "[20]\tvalidation-auc:0.84162\n",
            "[21]\tvalidation-auc:0.83980\n",
            "[22]\tvalidation-auc:0.83920\n",
            "[23]\tvalidation-auc:0.83904\n",
            "[24]\tvalidation-auc:0.84010\n",
            "[25]\tvalidation-auc:0.84100\n",
            "[26]\tvalidation-auc:0.84196\n",
            "[27]\tvalidation-auc:0.84174\n",
            "[28]\tvalidation-auc:0.84230\n",
            "[29]\tvalidation-auc:0.84437\n",
            "[30]\tvalidation-auc:0.84245\n",
            "[31]\tvalidation-auc:0.84308\n",
            "[32]\tvalidation-auc:0.84404\n",
            "[33]\tvalidation-auc:0.84424\n",
            "[34]\tvalidation-auc:0.84509\n",
            "[35]\tvalidation-auc:0.84596\n",
            "[36]\tvalidation-auc:0.84706\n",
            "[37]\tvalidation-auc:0.84796\n",
            "[38]\tvalidation-auc:0.84750\n",
            "[39]\tvalidation-auc:0.84792\n",
            "[40]\tvalidation-auc:0.84801\n",
            "[41]\tvalidation-auc:0.84782\n",
            "[42]\tvalidation-auc:0.84836\n",
            "[43]\tvalidation-auc:0.84912\n",
            "[44]\tvalidation-auc:0.84934\n",
            "[45]\tvalidation-auc:0.84949\n",
            "[46]\tvalidation-auc:0.85041\n",
            "[47]\tvalidation-auc:0.85127\n",
            "[48]\tvalidation-auc:0.85153\n",
            "[49]\tvalidation-auc:0.85141\n",
            "[50]\tvalidation-auc:0.85037\n",
            "[51]\tvalidation-auc:0.84852\n",
            "[52]\tvalidation-auc:0.84854\n",
            "[53]\tvalidation-auc:0.84874\n",
            "[54]\tvalidation-auc:0.84972\n",
            "[55]\tvalidation-auc:0.84997\n",
            "[56]\tvalidation-auc:0.84986\n",
            "[57]\tvalidation-auc:0.85003\n",
            "[58]\tvalidation-auc:0.85002\n",
            "[59]\tvalidation-auc:0.84971\n",
            "[60]\tvalidation-auc:0.84980\n",
            "[61]\tvalidation-auc:0.84975\n",
            "[62]\tvalidation-auc:0.85034\n",
            "[63]\tvalidation-auc:0.85083\n",
            "[64]\tvalidation-auc:0.85079\n",
            "[65]\tvalidation-auc:0.85094\n",
            "[66]\tvalidation-auc:0.85071\n",
            "[67]\tvalidation-auc:0.85123\n",
            "[68]\tvalidation-auc:0.85144\n",
            "[69]\tvalidation-auc:0.85140\n",
            "[70]\tvalidation-auc:0.85285\n",
            "[71]\tvalidation-auc:0.85023\n",
            "[72]\tvalidation-auc:0.85050\n",
            "[73]\tvalidation-auc:0.85111\n",
            "[74]\tvalidation-auc:0.85098\n",
            "[75]\tvalidation-auc:0.85072\n",
            "[76]\tvalidation-auc:0.85046\n",
            "[77]\tvalidation-auc:0.85044\n",
            "[78]\tvalidation-auc:0.85136\n",
            "[79]\tvalidation-auc:0.85135\n",
            "[80]\tvalidation-auc:0.84777\n",
            "[81]\tvalidation-auc:0.84738\n",
            "[82]\tvalidation-auc:0.84715\n",
            "[83]\tvalidation-auc:0.84741\n",
            "[84]\tvalidation-auc:0.84780\n",
            "[85]\tvalidation-auc:0.84750\n",
            "[86]\tvalidation-auc:0.84782\n",
            "[87]\tvalidation-auc:0.84783\n",
            "[88]\tvalidation-auc:0.84849\n",
            "[89]\tvalidation-auc:0.84867\n",
            "[90]\tvalidation-auc:0.84696\n",
            "[91]\tvalidation-auc:0.84677\n",
            "[92]\tvalidation-auc:0.84683\n",
            "[93]\tvalidation-auc:0.84684\n",
            "[94]\tvalidation-auc:0.84739\n",
            "[95]\tvalidation-auc:0.84761\n",
            "[96]\tvalidation-auc:0.84776\n",
            "[97]\tvalidation-auc:0.84787\n",
            "[98]\tvalidation-auc:0.84793\n",
            "[99]\tvalidation-auc:0.84818\n",
            "[100]\tvalidation-auc:0.84808\n",
            "[101]\tvalidation-auc:0.84775\n",
            "[102]\tvalidation-auc:0.84869\n",
            "[103]\tvalidation-auc:0.84877\n",
            "[104]\tvalidation-auc:0.84909\n",
            "[105]\tvalidation-auc:0.85009\n",
            "[106]\tvalidation-auc:0.84999\n",
            "[107]\tvalidation-auc:0.85000\n",
            "[108]\tvalidation-auc:0.85047\n",
            "[109]\tvalidation-auc:0.85042\n",
            "[110]\tvalidation-auc:0.85050\n",
            "[111]\tvalidation-auc:0.85091\n",
            "[112]\tvalidation-auc:0.85095\n",
            "[113]\tvalidation-auc:0.85076\n",
            "[114]\tvalidation-auc:0.85081\n",
            "[115]\tvalidation-auc:0.85064\n",
            "[116]\tvalidation-auc:0.85050\n",
            "[117]\tvalidation-auc:0.85045\n",
            "[118]\tvalidation-auc:0.85060\n",
            "[119]\tvalidation-auc:0.85065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:12:02,591] Trial 8 finished with value: 0.8509406658332547 and parameters: {'max_depth': 3, 'learning_rate': 0.0933620125770937, 'subsample': 0.637933556195867, 'colsample_bytree': 0.6912506175835335, 'lambda': 0.0024297405841102702, 'alpha': 0.0001113233561046967}. Best is trial 2 with value: 0.8524818666635923.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.73217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-10 23:12:02,691] Trial 9 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation-auc:0.82597\n",
            "[1]\tvalidation-auc:0.83771\n",
            "[2]\tvalidation-auc:0.82338\n",
            "[3]\tvalidation-auc:0.82918\n",
            "[4]\tvalidation-auc:0.82432\n",
            "[5]\tvalidation-auc:0.82094\n",
            "[6]\tvalidation-auc:0.81998\n",
            "[7]\tvalidation-auc:0.81888\n",
            "[8]\tvalidation-auc:0.82122\n",
            "[9]\tvalidation-auc:0.82363\n",
            "[10]\tvalidation-auc:0.82520\n",
            "[11]\tvalidation-auc:0.82651\n",
            "[12]\tvalidation-auc:0.82546\n",
            "[13]\tvalidation-auc:0.82733\n",
            "[14]\tvalidation-auc:0.82632\n",
            "[15]\tvalidation-auc:0.82895\n",
            "[16]\tvalidation-auc:0.82778\n",
            "[17]\tvalidation-auc:0.82852\n",
            "[18]\tvalidation-auc:0.82967\n",
            "[19]\tvalidation-auc:0.83003\n",
            "[20]\tvalidation-auc:0.83012\n",
            "[21]\tvalidation-auc:0.83075\n",
            "[22]\tvalidation-auc:0.83150\n",
            "[23]\tvalidation-auc:0.83166\n",
            "[24]\tvalidation-auc:0.83280\n",
            "[25]\tvalidation-auc:0.83353\n",
            "[26]\tvalidation-auc:0.83387\n",
            "[27]\tvalidation-auc:0.83564\n",
            "[28]\tvalidation-auc:0.83688\n",
            "[29]\tvalidation-auc:0.83558\n",
            "[30]\tvalidation-auc:0.83641\n",
            "[31]\tvalidation-auc:0.83537\n",
            "[32]\tvalidation-auc:0.83645\n",
            "[33]\tvalidation-auc:0.83722\n",
            "[34]\tvalidation-auc:0.83826\n",
            "[35]\tvalidation-auc:0.83788\n",
            "[36]\tvalidation-auc:0.83860\n",
            "[37]\tvalidation-auc:0.83815\n",
            "[38]\tvalidation-auc:0.83879\n",
            "[39]\tvalidation-auc:0.83936\n",
            "[40]\tvalidation-auc:0.83917\n",
            "[41]\tvalidation-auc:0.83918\n",
            "[42]\tvalidation-auc:0.83966\n",
            "[43]\tvalidation-auc:0.83906\n",
            "[44]\tvalidation-auc:0.83865\n",
            "[45]\tvalidation-auc:0.83935\n",
            "[46]\tvalidation-auc:0.84002\n",
            "[47]\tvalidation-auc:0.83968\n",
            "[48]\tvalidation-auc:0.83926\n",
            "[49]\tvalidation-auc:0.83910\n",
            "[50]\tvalidation-auc:0.83872\n",
            "[51]\tvalidation-auc:0.83928\n",
            "[52]\tvalidation-auc:0.83963\n",
            "[53]\tvalidation-auc:0.84038\n",
            "[54]\tvalidation-auc:0.84068\n",
            "[55]\tvalidation-auc:0.84080\n",
            "[56]\tvalidation-auc:0.84118\n",
            "[57]\tvalidation-auc:0.84143\n",
            "[58]\tvalidation-auc:0.84168\n",
            "[59]\tvalidation-auc:0.84212\n",
            "[60]\tvalidation-auc:0.84228\n",
            "[61]\tvalidation-auc:0.84259\n",
            "[62]\tvalidation-auc:0.84291\n",
            "[63]\tvalidation-auc:0.84301\n",
            "[64]\tvalidation-auc:0.84338\n",
            "[65]\tvalidation-auc:0.84363\n",
            "[66]\tvalidation-auc:0.84394\n",
            "[67]\tvalidation-auc:0.84409\n",
            "[68]\tvalidation-auc:0.84430\n",
            "[69]\tvalidation-auc:0.84483\n",
            "[70]\tvalidation-auc:0.84499\n",
            "[71]\tvalidation-auc:0.84533\n",
            "[72]\tvalidation-auc:0.84485\n",
            "[73]\tvalidation-auc:0.84468\n",
            "[74]\tvalidation-auc:0.84510\n",
            "[75]\tvalidation-auc:0.84538\n",
            "[76]\tvalidation-auc:0.84529\n",
            "[77]\tvalidation-auc:0.84574\n",
            "[78]\tvalidation-auc:0.84596\n",
            "[79]\tvalidation-auc:0.84592\n",
            "[80]\tvalidation-auc:0.84617\n",
            "[81]\tvalidation-auc:0.84616\n",
            "[82]\tvalidation-auc:0.84643\n",
            "[83]\tvalidation-auc:0.84654\n",
            "[84]\tvalidation-auc:0.84664\n",
            "[85]\tvalidation-auc:0.84712\n",
            "[86]\tvalidation-auc:0.84668\n",
            "[87]\tvalidation-auc:0.84654\n",
            "[88]\tvalidation-auc:0.84607\n",
            "[89]\tvalidation-auc:0.84622\n",
            "[90]\tvalidation-auc:0.84627\n",
            "[91]\tvalidation-auc:0.84670\n",
            "[92]\tvalidation-auc:0.84689\n",
            "[93]\tvalidation-auc:0.84719\n",
            "[94]\tvalidation-auc:0.84752\n",
            "[95]\tvalidation-auc:0.84779\n",
            "[96]\tvalidation-auc:0.84796\n",
            "[97]\tvalidation-auc:0.84774\n",
            "[98]\tvalidation-auc:0.84768\n",
            "[99]\tvalidation-auc:0.84780\n",
            "[100]\tvalidation-auc:0.84759\n",
            "[101]\tvalidation-auc:0.84724\n",
            "[102]\tvalidation-auc:0.84696\n",
            "[103]\tvalidation-auc:0.84649\n",
            "[104]\tvalidation-auc:0.84653\n",
            "[105]\tvalidation-auc:0.84663\n",
            "[106]\tvalidation-auc:0.84673\n",
            "[107]\tvalidation-auc:0.84693\n",
            "[108]\tvalidation-auc:0.84732\n",
            "[109]\tvalidation-auc:0.84707\n",
            "[110]\tvalidation-auc:0.84731\n",
            "[111]\tvalidation-auc:0.84745\n",
            "[112]\tvalidation-auc:0.84760\n",
            "[113]\tvalidation-auc:0.84783\n",
            "[114]\tvalidation-auc:0.84791\n",
            "[115]\tvalidation-auc:0.84806\n",
            "[116]\tvalidation-auc:0.84828\n",
            "[117]\tvalidation-auc:0.84785\n",
            "[118]\tvalidation-auc:0.84793\n",
            "[119]\tvalidation-auc:0.84813\n",
            "[120]\tvalidation-auc:0.84823\n",
            "[121]\tvalidation-auc:0.84835\n",
            "[122]\tvalidation-auc:0.84844\n",
            "[123]\tvalidation-auc:0.84873\n",
            "[124]\tvalidation-auc:0.84888\n",
            "[125]\tvalidation-auc:0.84907\n",
            "[126]\tvalidation-auc:0.84922\n",
            "[127]\tvalidation-auc:0.84924\n",
            "[128]\tvalidation-auc:0.84922\n",
            "[129]\tvalidation-auc:0.84931\n",
            "[130]\tvalidation-auc:0.84950\n",
            "[131]\tvalidation-auc:0.84949\n",
            "[132]\tvalidation-auc:0.84966\n",
            "[133]\tvalidation-auc:0.84947\n",
            "[134]\tvalidation-auc:0.84963\n",
            "[135]\tvalidation-auc:0.84961\n",
            "[136]\tvalidation-auc:0.84956\n",
            "[137]\tvalidation-auc:0.84912\n",
            "[138]\tvalidation-auc:0.84929\n",
            "[139]\tvalidation-auc:0.84947\n",
            "[140]\tvalidation-auc:0.84967\n",
            "[141]\tvalidation-auc:0.84970\n",
            "[142]\tvalidation-auc:0.84996\n",
            "[143]\tvalidation-auc:0.84997\n",
            "[144]\tvalidation-auc:0.85014\n",
            "[145]\tvalidation-auc:0.85017\n",
            "[146]\tvalidation-auc:0.85021\n",
            "[147]\tvalidation-auc:0.85038\n",
            "[148]\tvalidation-auc:0.85055\n",
            "[149]\tvalidation-auc:0.85061\n",
            "[150]\tvalidation-auc:0.85084\n",
            "[151]\tvalidation-auc:0.85110\n",
            "[152]\tvalidation-auc:0.85124\n",
            "[153]\tvalidation-auc:0.85117\n",
            "[154]\tvalidation-auc:0.85136\n",
            "[155]\tvalidation-auc:0.85131\n",
            "[156]\tvalidation-auc:0.85146\n",
            "[157]\tvalidation-auc:0.85167\n",
            "[158]\tvalidation-auc:0.85187\n",
            "[159]\tvalidation-auc:0.85189\n",
            "[160]\tvalidation-auc:0.85183\n",
            "[161]\tvalidation-auc:0.85196\n",
            "[162]\tvalidation-auc:0.85216\n",
            "[163]\tvalidation-auc:0.85212\n",
            "[164]\tvalidation-auc:0.85209\n",
            "[165]\tvalidation-auc:0.85235\n",
            "[166]\tvalidation-auc:0.85237\n",
            "[167]\tvalidation-auc:0.85235\n",
            "[168]\tvalidation-auc:0.85231\n",
            "[169]\tvalidation-auc:0.85237\n",
            "[170]\tvalidation-auc:0.85240\n",
            "[171]\tvalidation-auc:0.85236\n",
            "[172]\tvalidation-auc:0.85252\n",
            "[173]\tvalidation-auc:0.85252\n",
            "[174]\tvalidation-auc:0.85251\n",
            "[175]\tvalidation-auc:0.85188\n",
            "[176]\tvalidation-auc:0.85202\n",
            "[177]\tvalidation-auc:0.85208\n",
            "[178]\tvalidation-auc:0.85196\n",
            "[179]\tvalidation-auc:0.85195\n",
            "[180]\tvalidation-auc:0.85149\n",
            "[181]\tvalidation-auc:0.85162\n",
            "[182]\tvalidation-auc:0.85123\n",
            "[183]\tvalidation-auc:0.85121\n",
            "[184]\tvalidation-auc:0.85126\n",
            "[185]\tvalidation-auc:0.85064\n",
            "[186]\tvalidation-auc:0.85075\n",
            "[187]\tvalidation-auc:0.85081\n",
            "[188]\tvalidation-auc:0.85084\n",
            "[189]\tvalidation-auc:0.85094\n",
            "[190]\tvalidation-auc:0.85095\n",
            "[191]\tvalidation-auc:0.85051\n",
            "[192]\tvalidation-auc:0.85047\n",
            "[193]\tvalidation-auc:0.85049\n",
            "[194]\tvalidation-auc:0.85038\n",
            "[195]\tvalidation-auc:0.85048\n",
            "[196]\tvalidation-auc:0.85040\n",
            "[197]\tvalidation-auc:0.85040\n",
            "[198]\tvalidation-auc:0.85062\n",
            "[199]\tvalidation-auc:0.85075\n",
            "[200]\tvalidation-auc:0.85083\n",
            "[201]\tvalidation-auc:0.85089\n",
            "[202]\tvalidation-auc:0.85116\n",
            "[203]\tvalidation-auc:0.85127\n",
            "[204]\tvalidation-auc:0.85141\n",
            "[205]\tvalidation-auc:0.85147\n",
            "[206]\tvalidation-auc:0.85138\n",
            "[207]\tvalidation-auc:0.85142\n",
            "[208]\tvalidation-auc:0.85131\n",
            "[209]\tvalidation-auc:0.85134\n",
            "[210]\tvalidation-auc:0.85140\n",
            "[211]\tvalidation-auc:0.85157\n",
            "[212]\tvalidation-auc:0.85171\n",
            "[213]\tvalidation-auc:0.85183\n",
            "[214]\tvalidation-auc:0.85182\n",
            "[215]\tvalidation-auc:0.85186\n",
            "[216]\tvalidation-auc:0.85185\n",
            "[217]\tvalidation-auc:0.85200\n",
            "[218]\tvalidation-auc:0.85201\n",
            "[219]\tvalidation-auc:0.85209\n",
            "[220]\tvalidation-auc:0.85225\n",
            "[221]\tvalidation-auc:0.85232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... or you can load our pre-trained weights."
      ],
      "metadata": {
        "id": "sF4bxrkmm4KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "lightgbm_checkpoint = \"/content/relbench_hm_lightgmb_checkpoint\"\n",
        "xgboost_checkpoint = \"/content/relbench_hm_xgboost_checkpoint\"\n",
        "\n",
        "checkpoint_url = \"https://drive.google.com/uc?id=1WaZTfw-Ni_oCqZ3L4DupTbTo6xbSzvCk\"\n",
        "gdown.download(checkpoint_url, lightgbm_checkpoint, quiet=False)\n",
        "lightgbm_model.load(lightgbm_checkpoint)\n",
        "\n",
        "\n",
        "checkpoint_url = \"https://drive.google.com/uc?id=1NXAyzlIv_DLcj_qsXOZT8149MwNeHAB1\"\n",
        "gdown.download(checkpoint_url, xgboost_checkpoint, quiet=False)\n",
        "xgboost_model.load(xgboost_checkpoint)"
      ],
      "metadata": {
        "id": "Y9owAQcD0Jea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2416bc0c-541f-4c70-fbba-a3b904fddd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WaZTfw-Ni_oCqZ3L4DupTbTo6xbSzvCk\n",
            "To: /content/relbench_hm_lightgmb_checkpoint\n",
            "100%|██████████| 3.39M/3.39M [00:00<00:00, 178MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NXAyzlIv_DLcj_qsXOZT8149MwNeHAB1\n",
            "To: /content/relbench_hm_xgboost_checkpoint\n",
            "100%|██████████| 1.29M/1.29M [00:00<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(\n",
        "    model_output: pd.DataFrame,\n",
        "    src_entity_name: str,\n",
        "    dst_entity_name: str,\n",
        "    timestamp_col_name: str,\n",
        "    eval_k: int,\n",
        "    pred_score: str,\n",
        "    train_table: Table,\n",
        "    task: RecommendationTask,\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Evaluates the model predictions by computing recommendation metrics.\n",
        "\n",
        "    Args:\n",
        "        model_output (pd.DataFrame): DataFrame containing model predictions.\n",
        "        src_entity_name (str): Name of the source entity column.\n",
        "        dst_entity_name (str): Name of the destination entity column.\n",
        "        timestamp_col_name (str): Name of the timestamp column.\n",
        "        eval_k (int): Number of top-k predictions to evaluate.\n",
        "        pred_score (str): Name of the prediction score column.\n",
        "        train_table (Table): Training table to merge for past dst entities.\n",
        "        task (RecommendationTask): Task containing evaluation logic.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, float]: Computed metrics for the model.\n",
        "    \"\"\"\n",
        "    def adjust_past_dst_entities(values):\n",
        "        if len(values) < eval_k:\n",
        "            return values + [-1] * (eval_k - len(values))\n",
        "        else:\n",
        "            return values[:eval_k]\n",
        "\n",
        "    grouped_df = (\n",
        "        model_output.sort_values(pred_score, ascending=False)\n",
        "        .groupby([src_entity_name, timestamp_col_name])[dst_entity_name]\n",
        "        .apply(list)\n",
        "        .reset_index()\n",
        "    )\n",
        "    grouped_df = train_table.df[[src_entity_name, timestamp_col_name]].merge(\n",
        "        grouped_df, on=[src_entity_name, timestamp_col_name], how=\"left\"\n",
        "    )\n",
        "\n",
        "    dst_entity_array = (\n",
        "        grouped_df[dst_entity_name].apply(adjust_past_dst_entities).tolist()\n",
        "    )\n",
        "    dst_entity_array = np.array(dst_entity_array, dtype=int)\n",
        "    metrics = task.evaluate(dst_entity_array, train_table)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def evaluate_model(model_name, model, splits, pred_col_name, task, eval_k):\n",
        "    \"\"\"\n",
        "    Evaluates a model on multiple splits and prints the results.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model (e.g., 'LightGBM', 'XGBoost').\n",
        "        model: Trained model to evaluate.\n",
        "        splits (dict): Dictionary containing split data (train, val, test).\n",
        "        pred_col_name (str): Name of the prediction score column.\n",
        "        task (RecommendationTask): Task containing evaluation logic.\n",
        "        eval_k (int): Number of top-k predictions to evaluate.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*10} Evaluating {model_name} {'='*10}\\n\")\n",
        "\n",
        "    metrics_results = {}\n",
        "\n",
        "    for split_name, (tf_data, df_data, table) in splits.items():\n",
        "        pred = model.predict(tf_test=tf_data).cpu().numpy()\n",
        "        df_data[pred_col_name] = pred\n",
        "\n",
        "        metrics = evaluate(\n",
        "            df_data,\n",
        "            src_entity,\n",
        "            dst_entity,\n",
        "            sampled_train_table.time_col,\n",
        "            eval_k,\n",
        "            pred_col_name,\n",
        "            table,\n",
        "            task,\n",
        "        )\n",
        "\n",
        "        metrics_results[split_name] = metrics\n",
        "        print(f\"{split_name.capitalize()} Metrics: {json.dumps(metrics, indent=2)}\")\n",
        "\n",
        "    print(f\"\\n{'='*10} {model_name} Evaluation Complete {'='*10}\\n\")\n",
        "    return metrics_results\n",
        "\n",
        "\n",
        "# Prepare split information\n",
        "splits = {\n",
        "    \"train\": (tf_train, dfs[\"train\"], sampled_train_table),\n",
        "    \"val\": (tf_val_pred, dfs[\"val_pred\"], sampled_val_table),\n",
        "    \"test\": (tf_test, dfs[\"test\"], sampled_test_table),\n",
        "}\n",
        "\n",
        "# Evaluate both models\n",
        "lightgbm_metrics = evaluate_model(\n",
        "    model_name=\"LightGBM\",\n",
        "    model=lightgbm_model,\n",
        "    splits=splits,\n",
        "    pred_col_name=PRED_SCORE_COL_NAME,\n",
        "    task=task,\n",
        "    eval_k=task.eval_k,\n",
        ")\n",
        "\n",
        "xgboost_metrics = evaluate_model(\n",
        "    model_name=\"XGBoost\",\n",
        "    model=xgboost_model,\n",
        "    splits=splits,\n",
        "    pred_col_name=PRED_SCORE_COL_NAME,\n",
        "    task=task,\n",
        "    eval_k=task.eval_k,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vZTD8IJrJJP",
        "outputId": "30d4b1bc-8078-4a79-ab66-276a89cff3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Evaluating LightGBM ==========\n",
            "\n",
            "Train Metrics: {\n",
            "  \"link_prediction_precision\": 0.26075,\n",
            "  \"link_prediction_recall\": 0.9848450240702075,\n",
            "  \"link_prediction_map\": 0.9085766007620526\n",
            "}\n",
            "Val Metrics: {\n",
            "  \"link_prediction_precision\": 0.00125,\n",
            "  \"link_prediction_recall\": 0.006019444444444444,\n",
            "  \"link_prediction_map\": 0.0016770370370370368\n",
            "}\n",
            "Test Metrics: {\n",
            "  \"link_prediction_precision\": 0.003083333333333333,\n",
            "  \"link_prediction_recall\": 0.011755952380952379,\n",
            "  \"link_prediction_map\": 0.003882435966810967\n",
            "}\n",
            "\n",
            "========== LightGBM Evaluation Complete ==========\n",
            "\n",
            "\n",
            "========== Evaluating XGBoost ==========\n",
            "\n",
            "Train Metrics: {\n",
            "  \"link_prediction_precision\": 0.262,\n",
            "  \"link_prediction_recall\": 0.9861884777783351,\n",
            "  \"link_prediction_map\": 0.9190281326405677\n",
            "}\n",
            "Val Metrics: {\n",
            "  \"link_prediction_precision\": 0.002083333333333333,\n",
            "  \"link_prediction_recall\": 0.009221464646464646,\n",
            "  \"link_prediction_map\": 0.0033639911014911013\n",
            "}\n",
            "Test Metrics: {\n",
            "  \"link_prediction_precision\": 0.003333333333333333,\n",
            "  \"link_prediction_recall\": 0.011622619047619047,\n",
            "  \"link_prediction_map\": 0.002937766955266955\n",
            "}\n",
            "\n",
            "========== XGBoost Evaluation Complete ==========\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer-Based Encoders"
      ],
      "metadata": {
        "id": "SGeEhiM2WCWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Do Large Language Models make accurate personalized recommendations? (Kumo.ai)](https://kumo.ai/resources/blog/improving-predictions-with-large-language-models/)\n",
        "\n",
        "Five researchers at Kumo.ai have compared the efficacy of (unsupervised) state-of-the-art transformer-based encoders and (supervised) GNNs on the `rel-hm` recommendation task.\n",
        "\n",
        "In both cases, recommendations are produced by taking the embedding of a given customer and identifying 12 products whose embeddings have the highest cosine similarities with the customer embedding.\n",
        "\n",
        "* **Transformer-based encoders**.\n",
        "   * First, they textify products by concatenating all the product information into a single long sentence.\n",
        "      * E.g., `“Product name: <name>. Product description: <description>. Color: <color>. Material: <material>, …”`\n",
        "   * Then, they embed them with OpenAI `text-embedding-3-large`.\n",
        "   * User embeddings are computed as the average of purchased product embeddings.\n",
        "\n",
        "* **GNNs**.\n",
        "   * Kumo's GNNs are used to embed users and products.\n",
        "   * They try different text encoder for feature initialization.\n",
        "      * GloVe (average word embeddings).\n",
        "      * `intfloat/e5-base-v2`.\n",
        "      * `text-embedding-3-large` (1024 output dimensions).\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "| Method                          | MAP@12     | PRECISION@12 | RECALL@12   | F1@12      |\n",
        "|---------------------------------|------------|--------------|-------------|------------|\n",
        "| **LLM-only:** <br> OpenAI text-embedding-3-large | 0.00190 (-93.33%) | 0.00329 (-67.84%) | 0.00119 (-97.73%) | 0.0071 (-54.60%) |\n",
        "| **Kumo-GNN-only:** <br> uses GloVe for text embeddings | 0.02856           | 0.01023          | 0.05234          | 0.01564          |\n",
        "| **Kumo-GNN+HuggingFace:** <br> uses intfloat/e5-base-v2 for text embeddings | 0.0297 (+4.00%)  | 0.01099 (+7.43%) | 0.05531 (+5.67%) | 0.01673 (+6.97%) |\n",
        "| **Kumo-GNN+OpenAI:** <br> uses text-embedding-3-large for text embeddings | 0.02976 (+4.20%) | 0.01139 (+11.34%)| 0.0567 (+8.33%)  | 0.0173 (+10.61%) |\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=18sNn5NT2jqpmjcLp0iGtD5do3Ilv2-9Z\" width=\"650\">"
      ],
      "metadata": {
        "id": "8_E9qGa2WPU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🤖 ContextGNN"
      ],
      "metadata": {
        "id": "nmHCVv1-U61S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1mvITYIirr4enLM5NJlYBkjiIthN61n3L\" width=\"650\">"
      ],
      "metadata": {
        "id": "YIUfTVhXMu7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A recent GNN architecture proposed by Kumo.AI [[Yuan et al., 2024](https://arxiv.org/pdf/2411.19513)] for link prediction in recommendation systems."
      ],
      "metadata": {
        "id": "4iBQedWuJAZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem\n",
        "\n",
        "Traditionally, recommendation systems are modeled via different variants of a **two-tower paradigm**, where one tower embeds users and the other tower embeds items, which are then matched and ranked via an inner-product decoder.\n",
        "\n",
        "This scheme proves to be highly efficient for scaling up recommendation systems during the inference phase, as it allows to pre-compute user and item representations and to perform the final ranking via fast (approximate) maximum inner product search.\n",
        "\n",
        "However, one key limitation of two-tower based architectures for recommendation is that they learn a **pair-agnostic representation for users and items**.\n",
        "* That is, the user representation is not aware of the item under consideration, and similarly, the item representation is not aware of the user and thus item representations are not capturing the uniqueness of user's view on the items. As such, **neither of the representations on both ends capture knowledge about the pair-wise dependency they are making a prediction for**.\n",
        "* For example, consider a user who restocks their cosmetic products on a regular basis. In this scenario, the fine-grained context of user-cosmetic pairs is crucial, which cannot be adequately captured by two independent user and item representations alone. Such lack of knowledge has severe consequences on the quality of predictions, since, **e.g., the model is unable to distinguish between scenarios such as familiar purchases (i.e. users who repeatedly interact with the similar set of items) vs. exploratory purchases (i.e. users who like to explore new items).**"
      ],
      "metadata": {
        "id": "8XHGXMotG7IO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proposed Method"
      ],
      "metadata": {
        "id": "_RwoohyAL8AS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ContextGNN fuses both pair-wise representations and two-tower representations into a single architecture, enabling GNN-based recommendation systems to capture both repeated patterns and exploratory user preferences.\n",
        "\n",
        "It proposes to use two separate GNN architectures sitting behind the same GNN backbone.\n",
        "\n",
        "* First, pair-wise representations are learned within a user-centric subgraph using a bidirectional GNN, enabling the model to capture fine-grained local interaction signals such as repeat purchases and collaborative filtering. The root user node in the subgraph is augmented with a special ID embedding. This embedding explicitly identifies the node as the \"seed\" (the focal user), distinguishing it from other nodes in the subgraph.\n",
        "* Second, a two-tower model with shallow item embeddings complements these local scores by handling exploratory recommendations and items outside the user subgraph.\n",
        "\n",
        "Finally, a user-specific fusion score, produced by an MLP on the user GNN representation, is added to the scores of the pair-wise representation mode. It captures how exploratory a specific user is."
      ],
      "metadata": {
        "id": "UOzcG9s8L91y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Theoretical Formulation\n",
        "\n",
        "Context-based Graph Neural Network (ContextGNN) introduces a novel approach to information modeling, addressing the expressive and efficiency limitations of the previously discussed GraphSAGE and ID-GNN methodologies. This is achieved by combining two distinct representation models to generate more meaningful data embeddings.\n",
        "\n",
        "The first model leverages pairwise representations derived from the item candidate set within the local user-centric subgraph. In contrast, the second model employs a two-tower architecture built on shallow item representations, enabling the prediction of rankings for all user-item pairs beyond the user's immediate subgraph.\n",
        "\n",
        "To integrate these models, a user-specific fusion score is computed using an MLP applied to the user's GNN representation. This score is combined with the outputs of the pairwise representation model, aligning the distinct scoring mechanisms of the two models. It also accounts for the user's exploratory behavior, assigning greater or lesser importance to each model as needed."
      ],
      "metadata": {
        "id": "vAl6XXVEHyW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define the temporal recommendation problem on a **heterogeneous graph snapshot** $\\mathcal{G}^{(-\\infty, T]} = (\\mathcal{V}, \\mathcal{E}, \\phi, \\psi)$ up to timestamp $T$. Here:\n",
        "\n",
        "- $\\mathcal{V}$ represents the set of nodes.\n",
        "- $\\mathcal{E} \\subseteq \\mathcal{V} \\times \\mathcal{V}$ denotes the set of edges.\n",
        "- Each node $v \\in \\mathcal{V}$ belongs to a **node type** $\\phi(v)$.\n",
        "- Each edge $e \\in \\mathcal{E}$ belongs to an **edge type** $\\psi(e)$.\n",
        "\n",
        "We define two subsets of nodes within this heterogeneous graph:\n",
        "- $\\mathcal{L} \\subset \\mathcal{V}$, representing the set of users.\n",
        "- $\\mathcal{R} \\subset \\mathcal{V}$, representing the set of items.\n",
        "\n",
        "The goal is to predict the set of ground-truth items $\\mathcal{Y}_v^{(T, T+i]} \\subseteq \\mathcal{R}$, where a link exists between a user $v \\in \\mathcal{L} $ and an item within the time interval $(T, T+i]$ for a given interval size $i$. The model is restricted to using only historical information available up to timestamp $T$ for making predictions."
      ],
      "metadata": {
        "id": "qJ8XGukTK_xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Pair-wise Representation**\n",
        "\n",
        "Rather than learning a pair-wise representation via two **indipendent** user and item representations $h_v^{(k)}$ and $h_w^{(k)}$, ContextGNN utilizes the user specific subgraph and reads out GNN's item representations from it.\n",
        "\n",
        "More in details, the pair-wise model processes information following these steps:\n",
        "1. Sample a $k$-hop subgraph  $$ \\tilde{\\mathcal{G}} \\gets \\mathcal{G}_k^{(-\\infty, T]}[v] $$ with node set $\\tilde{\\mathcal{V}}$ around user $v \\in \\mathcal{L}$. To further facilitate the extraction of meaningful item node representations, the sampled sub-graph is transformed into a **bidirectional** graph.\n",
        "\n",
        "2. Add an indicator representation to the user seed node:  \n",
        "   $$ h_v^{(0)} \\gets h_v^{(0)} + \\text{INDICATOR}_\\theta $$\n",
        "\n",
        "3. Read out <u>both GNN user and item representations</u> at layer $k$:  \n",
        "   $$ h_v^{(k)}, \\{ h_w^{(k)} : w \\in \\tilde{\\mathcal{V}} \\cap \\mathcal{R} \\} \\gets \\text{GNN}_{\\theta}^{(k)}(\\tilde{\\mathcal{G}}, \\mathbf{H}^{(0)}) $$\n",
        "\n",
        "4. Compute the final ranking for all items $w \\in \\tilde{\\mathcal{V}} \\cap \\mathcal{R}$:  $$ y_{(v, w)}^{(\\text{pair})} \\gets h_v^{(k)} \\cdot h_w^{(k)}$$\n",
        "\n",
        "where $\\text{INDICATOR}_\\theta$ is a $d$-dimensional representation added to the seed user node to differentitate it and bias its embedding with respect to the other sampled neighbouring nodes.\n",
        "\n",
        "This approach efficiently handles temporal, heterogeneous graphs by integrating multi-behavior signals through GNNs. It captures user-item interactions like recency and clicks, requiring only a single GNN pass for predictions, with a complexity of $\\mathcal{O}(\\lvert \\mathcal{L} \\rvert)$, outperforming two-tower models. While adaptable to new users and items, its limited candidate set restricts its suitability for diverse recommendation needs."
      ],
      "metadata": {
        "id": "Rep_wlYXH0tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Two-Tower Representation**\n",
        "As a fallback mechanism to supplement the pair-wise representations, ContextGNN's two-tower model ranks all user-item pairs **outside** the user's subgraph.\n",
        "\n",
        "Instead of using another GNN network -- whose problems of over-squashed representations in dense edge configurations are well-known -- ContextGNN introduces a shallow embedding matrix $\\mathbf{W} \\in \\mathbb{R}^{\\lvert \\mathcal{R} \\rvert \\times d}$ to learn item representations. While these embedding matrices retain high expressive power, they also support training against a much larger corpus of negative samples, a critical issue of previous GNN-only-based architectures directly affecting the model performances.\n"
      ],
      "metadata": {
        "id": "LjQcTi2wH3YX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Unified Representation**\n",
        "\n",
        "Shallow item embeddings $\\omega_w \\in \\mathbf{W}$ are injected within the user's GNN forward pass to better align user representtions to the corresponding item representations. Such conditioning mechanism can be summarized as follow:\n",
        "1. Sample a $k$-hop subgraph  \n",
        "   $$ \\tilde{\\mathcal{G}} \\gets \\mathcal{G}_k^{(-\\infty, T]}[v] $$  \n",
        "   with node set $\\tilde{\\mathcal{V}}$ around user $v \\in \\mathcal{L}$\n",
        "\n",
        "2. Add the shallow embedding to all sampled items $w \\in \\tilde{\\mathcal{V}} \\cap \\mathcal{R}$:  \n",
        "   $$ h_w^{(0)} \\gets h_w^{(0)} + \\omega_w $$\n",
        "\n",
        "3. Read out the GNN user representation at layer $k$:  \n",
        "   $$ h_v^{(k)} \\gets \\text{GNN}_{\\theta}^{(k)}(\\tilde{\\mathcal{G}}, \\mathbf{H}^{(0)})$$\n",
        "\n",
        "4. Compute the final ranking for all items $w \\in \\mathcal{R} \\setminus \\tilde{\\mathcal{V}}$:  \n",
        "   $$ y_{(v, w)}^{(\\text{tower})} \\gets h_v^{(k)} \\cdot w_w $$\n",
        "\n",
        "\n",
        "ContexGNN then fuses both pair-wise and two-tower representations into a single architecture. Namely, for all items $w \\in \\tilde{\\mathcal{V}} \\cup \\mathcal{R}$ inside the locak user subgraph, we leverage the $y^{(\\text{pair})}_{(v,w)}$ score for entities within the sampled subgraph and the two-tower $y^{(\\text{tower})}_{(v,w)}$ scores for all items $w \\in \\tilde{\\mathcal{V}} \\setminus \\mathcal{R} $ outside the sampled subgraph.\n",
        "\n",
        "\n",
        "To align diverse user behaviors, CONTEXTGNN incorporates a user-specific fusion score, predicted from the GNN’s user embeddings $h_v^{(k)}$ using an MLP parameterized by $\\theta$. This personalized fusion score adjusts the distinct scores by learning whether a user favors familiar items or exploratory purchases, refining the final ranking scores accordingly. As a result, the final score is computed as follows:\n",
        "\n",
        "$$\n",
        "y_{(v, w)} =\n",
        "\\begin{cases}\n",
        "y_{(v, w)}^{(\\text{pair})} + \\text{MLP}_\\theta \\left( h_v^{(k)} \\right) & \\text{if } w \\in \\tilde{\\mathcal{V}} \\cup \\mathcal{R}, \\\\\n",
        "y_{(v, w)}^{(\\text{tower})} & \\text{otherwise.}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "This approach ensures that CONTEXTGNN is highly computationally efficient. The model is trained end-to-end, jointly optimizing both item scores and the fusion score to maximize its predictive performance for future user-item interactions. In practice, cross-entropy loss is used for optimization.\n"
      ],
      "metadata": {
        "id": "Nhav8bGgH6mV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation and Experiments\n",
        "We can download the offial code from https://github.com/yiweny/ContextGNN."
      ],
      "metadata": {
        "id": "uKR17fhmqg0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!git clone https://github.com/yiweny/ContextGNN.git\n",
        "%cd ContextGNN\n",
        "\n",
        "# install dependencies\n",
        "!pip install -e '.[full]'"
      ],
      "metadata": {
        "id": "DQahtJ5AqnZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import libraries\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import json\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, NamedTuple, Optional, Tuple, Union, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from relbench.base import Dataset, RecommendationTask, TaskType\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.modeling.graph import get_link_train_table_input\n",
        "from relbench.modeling.loader import SparseTensor\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from relbench.tasks import get_task\n",
        "from torch import Tensor\n",
        "from torch_frame import stype\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.seed import seed_everything\n",
        "from torch_geometric.typing import NodeType\n",
        "from torch_geometric.utils.cross_entropy import sparse_cross_entropy\n",
        "from tqdm import tqdm\n",
        "from torch import Tensor\n",
        "from torch_frame import stype\n",
        "from torch_frame.config import TextEmbedderConfig\n",
        "from torch_frame.data import Dataset as TorchFrameDataset\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.typing import NodeType\n",
        "from torch_geometric.utils import sort_edge_index\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from contextgnn.nn.models import IDGNN, ContextGNN, ShallowRHSGNN\n",
        "from contextgnn.utils import RHSEmbeddingMode\n",
        "\n",
        "\n",
        "from relbench.base import Database, EntityTask, RecommendationTask, Table, TaskType\n",
        "from relbench.modeling.utils import remove_pkey_fkey, to_unix_time\n",
        "\n",
        "random_seed = 42  # Random seed for reproducibility\n",
        "\n",
        "# Setup device and random seed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_num_threads(1)\n",
        "seed_everything(random_seed)\n",
        "\n",
        "\n",
        "\n",
        "class GloveTextEmbedding:\n",
        "    def __init__(self, device: Optional[torch.device\n",
        "                                       ] = None):\n",
        "        self.model = SentenceTransformer(\n",
        "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    def __call__(self, sentences: List[str]) -> Tensor:\n",
        "        return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n",
        "def make_pkey_fkey_graph(\n",
        "    db: Database,\n",
        "    col_to_stype_dict: Dict[str, Dict[str, stype]],\n",
        "    text_embedder_cfg: Optional[TextEmbedderConfig] = None,\n",
        "    cache_dir: Optional[str] = None,\n",
        ") -> Tuple[HeteroData, Dict[str, Dict[str, Dict[StatType, Any]]]]:\n",
        "    r\"\"\"Given a :class:`Database` object, construct a heterogeneous graph with primary-\n",
        "    foreign key relationships, together with the column stats of each table.\n",
        "\n",
        "    Args:\n",
        "        db: A database object containing a set of tables.\n",
        "        col_to_stype_dict: Column to stype for\n",
        "            each table.\n",
        "        text_embedder_cfg: Text embedder config.\n",
        "        cache_dir: A directory for storing materialized tensor\n",
        "            frames. If specified, we will either cache the file or use the\n",
        "            cached file. If not specified, we will not use cached file and\n",
        "            re-process everything from scratch without saving the cache.\n",
        "\n",
        "    Returns:\n",
        "        HeteroData: The heterogeneous :class:`PyG` object with\n",
        "            :class:`TensorFrame` feature.\n",
        "    \"\"\"\n",
        "    data = HeteroData()\n",
        "    col_stats_dict = dict()\n",
        "    if cache_dir is not None:\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "    for table_name, table in db.table_dict.items():\n",
        "        # Materialize the tables into tensor frames:\n",
        "        df = table.df\n",
        "        # Ensure that pkey is consecutive.\n",
        "        if table.pkey_col is not None:\n",
        "            assert (df[table.pkey_col].values == np.arange(len(df))).all()\n",
        "\n",
        "        col_to_stype = col_to_stype_dict[table_name]\n",
        "\n",
        "        # Remove pkey, fkey columns since they will not be used as input\n",
        "        # feature.\n",
        "        remove_pkey_fkey(col_to_stype, table)\n",
        "\n",
        "        if len(col_to_stype) == 0:  # Add constant feature in case df is empty:\n",
        "            col_to_stype = {\"__const__\": stype.numerical}\n",
        "            # We need to add edges later, so we need to also keep the fkeys\n",
        "            fkey_dict = {key: df[key] for key in table.fkey_col_to_pkey_table}\n",
        "            df = pd.DataFrame({\"__const__\": np.ones(len(table.df)), **fkey_dict})\n",
        "\n",
        "        path = (\n",
        "            None if cache_dir is None else os.path.join(cache_dir, f\"{table_name}.pt\")\n",
        "        )\n",
        "\n",
        "        dataset_list = []\n",
        "\n",
        "        dataset = TorchFrameDataset(\n",
        "            df=df,\n",
        "            col_to_stype=col_to_stype,\n",
        "            col_to_text_embedder_cfg=text_embedder_cfg,\n",
        "        ).materialize(path=path, device=\"cuda\")\n",
        "\n",
        "        data[table_name].tf = dataset.tensor_frame\n",
        "        col_stats_dict[table_name] = dataset.col_stats\n",
        "\n",
        "        # Add time attribute:\n",
        "        if table.time_col is not None:\n",
        "            data[table_name].time = torch.from_numpy(\n",
        "                to_unix_time(table.df[table.time_col])\n",
        "            )\n",
        "\n",
        "        # Add edges:\n",
        "        for fkey_name, pkey_table_name in table.fkey_col_to_pkey_table.items():\n",
        "            pkey_index = df[fkey_name]\n",
        "            # Filter out dangling foreign keys\n",
        "            mask = ~pkey_index.isna()\n",
        "            fkey_index = torch.arange(len(pkey_index))\n",
        "            # Filter dangling foreign keys:\n",
        "            pkey_index = torch.from_numpy(pkey_index[mask].astype(int).values)\n",
        "            fkey_index = fkey_index[torch.from_numpy(mask.values)]\n",
        "            # Ensure no dangling fkeys\n",
        "            assert (pkey_index < len(db.table_dict[pkey_table_name])).all()\n",
        "\n",
        "            # fkey -> pkey edges\n",
        "            edge_index = torch.stack([fkey_index, pkey_index], dim=0)\n",
        "            edge_type = (table_name, f\"f2p_{fkey_name}\", pkey_table_name)\n",
        "            data[edge_type].edge_index = sort_edge_index(edge_index)\n",
        "\n",
        "            # pkey -> fkey edges.\n",
        "            # \"rev_\" is added so that PyG loader recognizes the reverse edges\n",
        "            edge_index = torch.stack([pkey_index, fkey_index], dim=0)\n",
        "            edge_type = (pkey_table_name, f\"rev_f2p_{fkey_name}\", table_name)\n",
        "            data[edge_type].edge_index = sort_edge_index(edge_index)\n",
        "\n",
        "    data.validate()\n",
        "\n",
        "    return data, col_stats_dict"
      ],
      "metadata": {
        "id": "5-kLMNmfAt-V",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's re-defined some function we used above for the sake of clear code and easy running."
      ],
      "metadata": {
        "id": "2bgUjAul7rEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"rel-hm\"               # Dataset to use\n",
        "task_name = \"user-item-purchase\"      # Task to evaluate\n",
        "tune_metric = \"link_prediction_map\"\n",
        "\n",
        "learning_rate = 0.001                                           # Learning rate for training\n",
        "epochs = 1                                                      # Number of training epochs\n",
        "eval_epochs_interval = 1                                        # Evaluation interval\n",
        "batch_size = 1                                                  # Batch size for training\n",
        "channels = 128                                                   # Number of channels in the model\n",
        "aggregation = \"sum\"                                             # Aggregation method\n",
        "num_layers = 4                                                  # Number of layers in the model\n",
        "num_neighbors = 128                                              # Number of neighbors for sampling\n",
        "temporal_strategy = \"last\"                                      # Temporal sampling strategy\n",
        "max_steps_per_epoch = 2000                                      # Max steps per epoch\n",
        "num_workers = 0                                                 # Number of data loader workers\n",
        "cache_dir = os.path.expanduser(\"~/.cache/relbench_examples\")    # Cache directory"
      ],
      "metadata": {
        "id": "on6f3AoR7UT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset and task\n",
        "dataset: Dataset = get_dataset(dataset_name, download=True)\n",
        "task: RecommendationTask = get_task(dataset_name, task_name, download=True)"
      ],
      "metadata": {
        "id": "bh0T7DSd7lms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load column types and statistics\n",
        "stypes_cache_path = Path(f\"{cache_dir}/{dataset_name}/stypes.json\")\n",
        "dataset_cache_dir = \"/content/cache/materialized\"\n",
        "\n",
        "try:\n",
        "    with open(stypes_cache_path, \"r\") as f:\n",
        "        col_to_stype_dict = json.load(f)\n",
        "    for table, col_to_stype in col_to_stype_dict.items():\n",
        "        for col, stype_str in col_to_stype.items():\n",
        "            col_to_stype[col] = stype(stype_str)\n",
        "except FileNotFoundError:\n",
        "    col_to_stype_dict = get_stype_proposal(dataset.get_db())\n",
        "    Path(stypes_cache_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(stypes_cache_path, \"w\") as f:\n",
        "        json.dump(col_to_stype_dict, f, indent=2, default=str)\n",
        "\n",
        "# Prepare graph data and column statistics\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    dataset.get_db(),\n",
        "    col_to_stype_dict=col_to_stype_dict,\n",
        "    text_embedder_cfg=TextEmbedderConfig(\n",
        "        text_embedder=GloveTextEmbedding(device=device), batch_size=512),\n",
        "    cache_dir=dataset_cache_dir,\n",
        ")\n",
        "\n",
        "# Define neighbors per layer\n",
        "num_neighbors_per_layer = [\n",
        "    int(num_neighbors // 2**i) for i in range(num_layers)\n",
        "]\n",
        "\n",
        "# Prepare loaders for train, val, and test sets\n",
        "loader_dict: Dict[str, NeighborLoader] = {}\n",
        "dst_nodes_dict: Dict[str, Tuple[NodeType, Tensor]] = {}\n",
        "num_dst_nodes_dict: Dict[str, int] = {}\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    table = task.get_table(split)\n",
        "    table_input = get_link_train_table_input(table, task)\n",
        "    dst_nodes_dict[split] = table_input.dst_nodes\n",
        "    num_dst_nodes_dict[split] = table_input.num_dst_nodes\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=num_neighbors_per_layer,\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.src_nodes,\n",
        "        input_time=table_input.src_time,\n",
        "        subgraph_type=\"bidirectional\",\n",
        "        batch_size=batch_size,\n",
        "        temporal_strategy=temporal_strategy,\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=num_workers,\n",
        "        persistent_workers=num_workers > 0,\n",
        "    )"
      ],
      "metadata": {
        "id": "lBk228At7p7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaddcd0-e3c8-4eff-e1a3-72ca34e7a450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Database object from /root/.cache/relbench/rel-hm/db...\n",
            "Done in 14.31 seconds.\n",
            "Loading Database object from /root/.cache/relbench/rel-hm/db...\n",
            "Done in 2.90 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Select** model type\n",
        "model_type = \"contextgnn\"\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=['contextgnn', 'idgnn'],\n",
        "    value='contextgnn',\n",
        "    description='Select:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "def on_dropdown_change(change):\n",
        "    global model_type\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        model_type = change['new']\n",
        "\n",
        "dropdown.observe(on_dropdown_change)\n",
        "display(dropdown)"
      ],
      "metadata": {
        "id": "RHq1s2Ki7jlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "24969bc48b85454a839d2adfda63d433",
            "a7d72d5963a642d588581328bad5b63b",
            "8c2fdbcfba5341e780e5ba96ce7ace7f"
          ]
        },
        "cellView": "form",
        "outputId": "41f6fb86-cccf-4d9b-e1f4-d8caebdc3d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Select:', options=('contextgnn', 'idgnn'), value='contextgnn')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24969bc48b85454a839d2adfda63d433"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "if model_type == \"idgnn\":\n",
        "    model = IDGNN(\n",
        "        data=data,\n",
        "        col_stats_dict=col_stats_dict,\n",
        "        num_layers=num_layers,\n",
        "        channels=channels,\n",
        "        out_channels=1,\n",
        "        aggr=aggregation,\n",
        "        norm=\"layer_norm\",\n",
        "        torch_frame_model_kwargs={\n",
        "            \"channels\": channels,\n",
        "            \"num_layers\": num_layers,\n",
        "        },\n",
        "    ).to(device)\n",
        "else:\n",
        "    #model_type == \"contextgnn\"\n",
        "    model = ContextGNN(\n",
        "        data=data,\n",
        "        col_stats_dict=col_stats_dict,\n",
        "        rhs_emb_mode=RHSEmbeddingMode.FUSION,\n",
        "        dst_entity_table=task.dst_entity_table,\n",
        "        num_nodes=num_dst_nodes_dict[\"train\"],\n",
        "        num_layers=num_layers,\n",
        "        channels=channels,\n",
        "        aggr=\"sum\",\n",
        "        norm=\"layer_norm\",\n",
        "        embedding_dim=64,\n",
        "        torch_frame_model_kwargs={\n",
        "            \"channels\": channels,\n",
        "            \"num_layers\": num_layers,\n",
        "        },\n",
        "    ).to(device)"
      ],
      "metadata": {
        "id": "V2hRhaK775nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now define the training and evaluation functions, which follow a slightly different processing workflow for ContextGNN compared to the original ID-GNN version."
      ],
      "metadata": {
        "id": "qUuABAkPj592"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "def train() -> float:\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "\n",
        "    Returns:\n",
        "        float: The average training loss for the epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    steps = 0\n",
        "    total_steps = min(len(loader_dict[\"train\"]), max_steps_per_epoch)\n",
        "    sparse_tensor = SparseTensor(dst_nodes_dict[\"train\"][1], device=device)\n",
        "\n",
        "    for batch in tqdm(loader_dict[\"train\"], total=total_steps, desc=\"Train\"):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # Get ground-truth source and destination indices\n",
        "        input_id = batch[task.src_entity_table].input_id\n",
        "        src_batch, dst_index = sparse_tensor[input_id]\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if model_type == 'idgnn':\n",
        "            # Forward pass for IDGNN\n",
        "            out = model(batch, task.src_entity_table, task.dst_entity_table).flatten()\n",
        "            batch_size = batch[task.src_entity_table].batch_size\n",
        "\n",
        "            # Compute target labels for IDGNN\n",
        "            target = torch.isin(\n",
        "                batch[task.dst_entity_table].batch +\n",
        "                batch_size * batch[task.dst_entity_table].n_id,\n",
        "                src_batch + batch_size * dst_index,\n",
        "            ).float()\n",
        "\n",
        "            # Compute binary cross-entropy loss\n",
        "            loss = F.binary_cross_entropy_with_logits(out, target)\n",
        "            numel = out.numel()\n",
        "\n",
        "        else:\n",
        "            # model_type in ['contextgnn', 'shallowrhsgnn']:\n",
        "            # Forward pass for ContextGNN and ShallowRHSGNN\n",
        "            logits = model(batch, task.src_entity_table, task.dst_entity_table)\n",
        "\n",
        "            # Construct edge label index\n",
        "            edge_label_index = torch.stack([src_batch, dst_index], dim=0)\n",
        "\n",
        "            # Compute sparse cross-entropy loss\n",
        "            loss = sparse_cross_entropy(logits, edge_label_index)\n",
        "            numel = len(batch[task.dst_entity_table].batch)\n",
        "\n",
        "        # Backward pass and optimizer step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss and count\n",
        "        loss_accum += float(loss) * numel\n",
        "        count_accum += numel\n",
        "\n",
        "        # Log training loss to wandb\n",
        "        print({\"batch_train_loss\": float(loss)})\n",
        "\n",
        "        # Increment step counter and check early stopping condition\n",
        "        steps += 1\n",
        "        if steps > max_steps_per_epoch:\n",
        "            break\n",
        "\n",
        "    if count_accum == 0:\n",
        "        warnings.warn(\n",
        "            f\"Did not sample a single '{task.dst_entity_table}' node in any mini-batch. \"\n",
        "            f\"Try increasing the number of layers/hops or decreasing the batch size.\"\n",
        "        )\n",
        "\n",
        "    # Log average training loss to wandb\n",
        "    avg_loss = loss_accum / count_accum if count_accum > 0 else float(\"nan\")\n",
        "    print({\"train_loss\": avg_loss})\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader: NeighborLoader, desc: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Evaluate the model using a data loader.\n",
        "\n",
        "    Args:\n",
        "        loader (NeighborLoader): Data loader for evaluation (val/test).\n",
        "        desc (str): Description of the evaluation phase (e.g., \"Validation\").\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Top-K predictions for the task.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    pred_list: List[Tensor] = []\n",
        "\n",
        "\n",
        "    for batch in tqdm(loader, desc=desc):\n",
        "        batch = batch.to(device)\n",
        "        batch_size = batch[task.src_entity_table].batch_size\n",
        "\n",
        "        if model_type == \"idgnn\":\n",
        "            # Forward pass for IDGNN\n",
        "            logits = model(batch, task.src_entity_table, task.dst_entity_table).detach().flatten()\n",
        "            scores = torch.zeros(batch_size, task.num_dst_nodes, device=logits.device)\n",
        "            scores[batch[task.dst_entity_table].batch, batch[task.dst_entity_table].n_id] = torch.sigmoid(logits)\n",
        "\n",
        "        else:\n",
        "            #model_type in [\"contextgnn\", \"shallowrhsgnn\"]:\n",
        "            # Forward pass for ContextGNN and ShallowRHSGNN\n",
        "            logits = model(batch, task.src_entity_table, task.dst_entity_table).detach()\n",
        "            scores = torch.sigmoid(logits)\n",
        "\n",
        "        # Collect top-K predictions\n",
        "        _, pred_mini = torch.topk(scores, k=task.eval_k, dim=1)\n",
        "        pred_list.append(pred_mini)\n",
        "\n",
        "    # Concatenate predictions and return as a NumPy array\n",
        "    pred = torch.cat(pred_list, dim=0).cpu().numpy()\n",
        "    return pred"
      ],
      "metadata": {
        "id": "DA_l84oW9v4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"EVALUATION BEFORE TRAINING...\")\n",
        "val_pred = test(loader_dict[\"val\"], desc=\"Best Validation\")\n",
        "val_metrics = task.evaluate(val_pred, task.get_table(\"val\"))\n",
        "print(f\"Best Validation Metrics: {json.dumps(val_metrics, indent=2)}\")\n",
        "\n",
        "test_pred = test(loader_dict[\"test\"], desc=\"Test\")\n",
        "test_metrics = task.evaluate(test_pred, task.get_table(\"test\"))\n",
        "print(f\"Test Metrics: {json.dumps(test_metrics, indent=2)}\")"
      ],
      "metadata": {
        "id": "5LcfXr_68Jy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation loop\n",
        "best_state = None\n",
        "best_val_metric = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # Train the model for one epoch\n",
        "    train_loss = train()\n",
        "\n",
        "    if epoch % eval_epochs_interval == 0:\n",
        "        # Evaluate on the validation set\n",
        "        val_pred = test(loader_dict[\"val\"], desc=\"Validation\")\n",
        "        val_metrics = task.evaluate(val_pred, task.get_table(\"val\"))\n",
        "        print(f\"Epoch: {epoch:02d}, Train loss: {train_loss:.4f}, Val metrics: {val_metrics}\")\n",
        "\n",
        "        # Save the best model state\n",
        "        if val_metrics[tune_metric] > best_val_metric:\n",
        "            best_val_metric = val_metrics[tune_metric]\n",
        "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "\n",
        "# Ensure the best model state is saved\n",
        "assert best_state is not None\n",
        "model.load_state_dict(best_state)"
      ],
      "metadata": {
        "id": "xEnPMJMu8LCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... or load our pretrained checkpoint"
      ],
      "metadata": {
        "id": "kWtkRMaUs1Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Checkpoint configuration\n",
        "#\"config\": {\n",
        "#    \"model_type\": \"contextgnn\",\n",
        "#    \"seed\": 42,\n",
        "#    \"learning_rate\": 0.001,\n",
        "#    \"epochs\": 20,\n",
        "#    \"eval_epochs_interval\": 5,\n",
        "#    \"batch_size\": 200,\n",
        "#    \"channels\": 128,\n",
        "#    \"aggregation\": \"sum\",\n",
        "#    \"num_layers\": 4,\n",
        "#    \"num_neighbors\": 128,\n",
        "#    \"temporal_strategy\": \"last\",\n",
        "#    \"max_steps_per_epoch\": 2000,\n",
        "#    \"num_workers\": 0,\n",
        "#    \"embedding_dim\": 64\n",
        "#}\n",
        "\n",
        "checkpoint_url = \"https://drive.google.com/uc?id=1IK0F5iII2fC9MdU07JD-C9PySMP4uRje\"\n",
        "gdown.download(checkpoint_url, \"/content/relbench_hm_contextgnn_checkpoint\", quiet=False)\n",
        "\n",
        "state_dict = torch.load(\"/content/relbench_hm_contextgnn_checkpoint\")\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5lLasVYk9Tv",
        "outputId": "10496a35-1410-41ee-de3c-a1c5b21b769f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1IK0F5iII2fC9MdU07JD-C9PySMP4uRje\n",
            "From (redirected): https://drive.google.com/uc?id=1IK0F5iII2fC9MdU07JD-C9PySMP4uRje&confirm=t&uuid=b3f19611-96d0-4247-824c-bdc86f588622\n",
            "To: /content/relbench_hm_contextgnn_checkpoint\n",
            "100%|██████████| 37.7M/37.7M [00:01<00:00, 22.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the validation set using the best model\n",
        "print(\"EVALUATION AFTER TRAINING...\")\n",
        "# Evaluate on the validation set using the best model\n",
        "val_pred = test(loader_dict[\"val\"], desc=\"Best Validation\")\n",
        "val_metrics = task.evaluate(val_pred, task.get_table(\"val\"))\n",
        "print(f\"Best Validation Metrics: {val_metrics}\")\n",
        "\n",
        "# Evaluate on the test set using the best model\n",
        "test_pred = test(loader_dict[\"test\"], desc=\"Test\")\n",
        "test_metrics = task.evaluate(test_pred, task.get_table(\"test\"))\n",
        "print(f\"Test Metrics: {json.dumps(test_metrics, indent=2)}\")"
      ],
      "metadata": {
        "id": "KzHTg3s88L0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3fd6d7-8a2f-49ae-e08b-357e1d8ff8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION AFTER TRAINING...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best Validation: 100%|██████████| 74575/74575 [25:54<00:00, 47.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Metrics: {'link_prediction_precision': 0.006614146832048273, 'link_prediction_recall': 0.034180961287795825, 'link_prediction_map': 0.021203250508317745}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|█████████▉| 67094/67144 [22:21<00:00, 55.03it/s]"
          ]
        }
      ]
    }
  ]
}