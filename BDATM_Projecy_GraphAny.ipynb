{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcNraNGefTp8"
      },
      "source": [
        "# Downloading GraphAny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC3-4ki8fWY3",
        "outputId": "32c66dde-ea62-464e-9841-02ad935c7742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GraphAny'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 76 (delta 24), reused 40 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (76/76), 576.89 KiB | 10.88 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DeepGraphLearning/GraphAny.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHVlit_sfoks"
      },
      "source": [
        "# Imports and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MKSI8hbjDr2",
        "outputId": "8ce9b27c-7b73-496e-9a62-1ab3175dec26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  33% 0.32888066179517556/1 [00:18<00:03,  5.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  30% 0.296996090404566/1 [00:18<00:31, 45.25s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  35% 0.3478656096189204/1 [00:18<00:03,  5.38s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  30% 0.29950694063904093/1 [00:18<00:30, 43.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  30% 0.3029607798756037/1 [00:18<00:26, 38.48s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  60% 0.603382505387115/1 [00:18<00:10, 25.33s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  31% 0.30563068849597297/1 [00:18<00:27, 39.86s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  61% 0.6079615636354805/1 [00:18<00:09, 24.30s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  31% 0.30819834529683876/1 [00:18<00:31, 45.13s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  42% 0.42121654439247996/1 [00:19<00:04,  7.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  31% 0.31051605320558484/1 [00:19<00:35, 51.40s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  62% 0.6156772767839762/1 [00:19<00:12, 32.54s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  31% 0.3125724509089331/1 [00:19<00:35, 51.83s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  62% 0.6200273821199235/1 [00:19<00:11, 30.17s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  31% 0.3145834033591687/1 [00:19<00:35, 52.51s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  62% 0.6236677334273739/1 [00:19<00:11, 29.97s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  32% 0.3165375492430134/1 [00:19<00:36, 54.11s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  63% 0.627239398861099/1 [00:19<00:10, 29.43s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  32% 0.31854850169324894/1 [00:19<00:36, 52.88s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  63% 0.6316810853620135/1 [00:19<00:10, 27.43s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  32% 0.3209002935418296/1 [00:19<00:34, 51.01s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  64% 0.6357793424943006/1 [00:19<00:09, 26.89s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  32% 0.32321800145057566/1 [00:19<00:33, 49.72s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  64% 0.6399004949178294/1 [00:19<00:09, 26.10s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  55% 0.5462487260195671/1 [00:19<00:02,  6.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  33% 0.32525167652736753/1 [00:19<00:35, 53.15s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  33% 0.32716037715809965/1 [00:20<00:36, 53.54s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  65% 0.6476162080663252/1 [00:20<00:09, 27.79s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  58% 0.5781779564504107/1 [00:20<00:02,  6.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  33% 0.3294440011270112/1 [00:20<00:35, 52.84s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  60% 0.5958205342260119/1 [00:20<00:02,  6.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  33% 0.33155720539675027/1 [00:20<00:35, 52.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  61% 0.613654879151348/1 [00:20<00:02,  6.67s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  33% 0.3336590483532112/1 [00:20<00:35, 53.12s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  34% 0.3357040847432813/1 [00:20<00:34, 52.15s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  66% 0.6636429119356043/1 [00:20<00:09, 27.26s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  34% 0.3380445152785837/1 [00:20<00:32, 49.11s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  67% 0.6680388078540351/1 [00:20<00:08, 26.61s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  34% 0.34010091298193196/1 [00:20<00:32, 49.15s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  67% 0.6733963060046227/1 [00:20<00:07, 23.90s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  34% 0.34241862089067804/1 [00:20<00:32, 48.91s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  68% 0.6787538041552102/1 [00:20<00:07, 22.15s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  71% 0.7066619467727241/1 [00:20<00:01,  5.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  35% 0.345270310523498/1 [00:20<00:31, 48.72s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  73% 0.7259345453210712/1 [00:20<00:01,  5.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  35% 0.3474630439861842/1 [00:21<00:31, 48.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  75% 0.7475083496662357/1 [00:21<00:01,  5.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  35% 0.34953080300281064/1 [00:21<00:34, 52.54s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  77% 0.7678356675381242/1 [00:21<00:01,  5.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  35% 0.3522007116231799/1 [00:21<00:32, 49.71s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  79% 0.7949707192255978/1 [00:21<00:01,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  35% 0.3543934450858661/1 [00:21<00:31, 48.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  82% 0.8152021535226188/1 [00:21<00:00,  5.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  36% 0.35646120410249255/1 [00:21<00:35, 54.92s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  83% 0.8344747520709659/1 [00:21<00:00,  5.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  71% 0.7131654268916766/1 [00:21<00:06, 23.73s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  36% 0.3583358207933901/1 [00:21<00:39, 62.33s/it] \n",
            "pytorch-2.2.1        | 1.34 GB   | :  36% 0.36016499223117504/1 [00:21<00:38, 60.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  87% 0.8744582027906709/1 [00:21<00:00,  5.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  36% 0.3620850541751853/1 [00:21<00:38, 59.95s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  89% 0.8916213626919351/1 [00:21<00:00,  5.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  73% 0.725574674744747/1 [00:21<00:08, 29.26s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  36% 0.36416417450508987/1 [00:22<00:37, 58.99s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  73% 0.7296271412945504/1 [00:22<00:07, 28.00s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  37% 0.3659365393764839/1 [00:22<00:37, 58.50s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  73% 0.7343664665816086/1 [00:22<00:06, 26.24s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  37% 0.36795885313999765/1 [00:22<00:35, 56.06s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  74% 0.739884231770889/1 [00:22<00:06, 23.73s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  37% 0.37110593691804994/1 [00:22<00:29, 46.47s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  74% 0.7442114418155944/1 [00:22<00:06, 23.86s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  37% 0.3732986703807362/1 [00:22<00:30, 47.96s/it] \n",
            "pytorch-2.2.1        | 1.34 GB   | :  38% 0.3755822943496478/1 [00:22<00:29, 46.83s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  38% 0.3777409438724995/1 [00:22<00:29, 47.96s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  38% 0.3801722649140273/1 [00:22<00:29, 47.06s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  38% 0.3823081918103227/1 [00:22<00:32, 52.90s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  39% 0.38529621720248064/1 [00:23<00:28, 47.13s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  39% 0.3878865966299027/1 [00:23<00:27, 44.50s/it] \n",
            "pytorch-2.2.1        | 1.34 GB   | :  39% 0.39057922787682836/1 [00:23<00:26, 42.88s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  39% 0.3931809686175286/1 [00:23<00:25, 41.56s/it] \n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.3956463735988909/1 [00:23<00:24, 41.30s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  79% 0.7939400143928431/1 [00:23<00:04, 21.25s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.398100417266975/1 [00:23<00:24, 41.21s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :   0% 0.00011179919674215067/1 [00:23<58:28:14, 210518.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.4012020557919146/1 [00:23<00:22, 38.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :   3% 0.027726200792053363/1 [00:23<09:42, 598.76s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.40383788047244934/1 [00:23<00:23, 38.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :   6% 0.05534060238736458/1 [00:23<03:55, 249.09s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.40641689858659324/1 [00:23<00:23, 38.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :   8% 0.08474379113055021/1 [00:23<02:01, 133.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.40959806630448004/1 [00:23<00:21, 36.64s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  11% 0.11258179111934571/1 [00:23<01:13, 83.07s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.4133813836261097/1 [00:24<00:19, 33.17s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  14% 0.1416495822723049/1 [00:24<00:46, 53.94s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.41640349295810214/1 [00:24<00:22, 38.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  17% 0.1674751967197417/1 [00:24<00:31, 38.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.41911884683158407/1 [00:24<00:22, 39.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  19% 0.19162382321604624/1 [00:24<00:22, 28.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.4217433101988407/1 [00:24<00:22, 39.00s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  21% 0.21476625694167142/1 [00:24<00:16, 21.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.42475405821755496/1 [00:24<00:21, 37.29s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  85% 0.8457291631818563/1 [00:24<00:03, 20.35s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.42748077340431506/1 [00:24<00:23, 41.72s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  85% 0.8513614048273458/1 [00:24<00:02, 19.54s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.43032110172385685/1 [00:24<00:22, 40.33s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  86% 0.8577949816662993/1 [00:24<00:02, 18.37s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.43327504317618026/1 [00:24<00:21, 38.75s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  86% 0.863404328020547/1 [00:24<00:02, 18.22s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4364107656409544/1 [00:24<00:21, 38.29s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  87% 0.8694715801996312/1 [00:24<00:02, 18.14s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.43905795163476735/1 [00:25<00:21, 38.39s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  38% 0.3797818713330858/1 [00:25<00:03,  5.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4416937763153021/1 [00:25<00:22, 39.48s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  41% 0.40616648176423337/1 [00:25<00:03,  5.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.44425007180288967/1 [00:25<00:22, 40.14s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  89% 0.8871925356208055/1 [00:25<00:02, 18.23s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.4467609220373646/1 [00:25<00:22, 40.21s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  45% 0.4547991323470689/1 [00:25<00:02,  5.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.44989664450213873/1 [00:25<00:20, 37.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  48% 0.4772707708922412/1 [00:25<00:02,  5.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.452566553122508/1 [00:25<00:23, 43.16s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  50% 0.5019783933722565/1 [00:25<00:02,  4.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4554296040686061/1 [00:25<00:22, 41.57s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  52% 0.5241146343272023/1 [00:25<00:02,  4.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.45790637036324655/1 [00:25<00:22, 41.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  55% 0.5526234294964507/1 [00:25<00:01,  4.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4604740271641123/1 [00:25<00:22, 41.38s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  58% 0.5835918069940265/1 [00:25<00:01,  4.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.46301896133842174/1 [00:26<00:21, 40.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  61% 0.61288319654047/1 [00:26<00:01,  3.89s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.46549572763306213/1 [00:26<00:22, 41.39s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  64% 0.6392678069716174/1 [00:26<00:01,  4.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.46793840998786806/1 [00:26<00:23, 43.41s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  67% 0.6691181925017717/1 [00:26<00:01,  3.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4702674792098923/1 [00:26<00:24, 46.63s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  70% 0.6955028029329193/1 [00:26<00:01,  3.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.47319869803565945/1 [00:26<00:22, 42.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  72% 0.7209930197901296/1 [00:26<00:01,  3.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.47619808474109554/1 [00:26<00:20, 39.99s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  75% 0.7490546181724095/1 [00:26<00:01,  4.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.478743018915405/1 [00:26<00:21, 40.56s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  78% 0.7789050037025637/1 [00:26<00:00,  3.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.4814015662224961/1 [00:26<00:21, 41.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  81% 0.8106559755773345/1 [00:26<00:00,  3.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | : 100% 1.0/1 [00:26<00:00,  5.08s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.4848099602059462/1 [00:26<00:19, 37.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  85% 0.8475497105022441/1 [00:26<00:00,  3.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   0% 0.0001518791001574902/1 [00:26<49:14:57, 177324.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  97% 0.9659523374926912/1 [00:26<00:00, 20.72s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.48753667539270634/1 [00:27<00:20, 40.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  88% 0.877847292819367/1 [00:27<00:00,  3.59s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.4905019781583079/1 [00:27<00:19, 38.49s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   6% 0.06257418926488596/1 [00:27<03:57, 253.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  91% 0.9062442887918732/1 [00:27<00:00,  3.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.4934786422371877/1 [00:27<00:18, 37.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   9% 0.08960866909291923/1 [00:27<02:15, 148.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  93% 0.9324053008295365/1 [00:27<00:00,  4.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.4962280800505041/1 [00:27<00:18, 37.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  12% 0.11983261002425978/1 [00:27<01:19, 89.93s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.9883897229096819/1 [00:27<00:00, 21.13s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.49893207261070793/1 [00:27<00:20, 40.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  15% 0.14671521075213553/1 [00:27<00:52, 60.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.9931748387792237/1 [00:27<00:00, 21.29s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.5014883680982956/1 [00:27<00:20, 40.28s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  17% 0.1720790204784364/1 [00:27<00:35, 43.20s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | : 100% 0.9980744311049747/1 [00:27<00:00, 21.06s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.5040105796460486/1 [00:27<00:22, 44.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.506623681700027/1 [00:27<00:21, 43.62s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.508998196175164/1 [00:27<00:21, 44.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5118158018681493/1 [00:28<00:20, 41.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5179849949781942/1 [00:28<00:17, 36.53s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5213933889616442/1 [00:28<00:16, 34.13s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5243586917272459/1 [00:28<00:16, 35.73s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.527426246312351/1 [00:28<00:16, 35.23s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5302892972584491/1 [00:28<00:16, 36.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5330841803248781/1 [00:28<00:17, 37.28s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.535788172885082/1 [00:28<00:19, 41.81s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.5386171398913455/1 [00:29<00:18, 40.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.541298409824993/1 [00:29<00:18, 39.52s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.5447295264349995/1 [00:29<00:16, 36.11s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5475471321279849/1 [00:29<00:17, 38.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.550410183074083/1 [00:29<00:17, 38.81s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5530346464413396/1 [00:29<00:17, 39.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5562726207256172/1 [00:29<00:16, 37.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5601013833003595/1 [00:29<00:14, 33.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5634529707174188/1 [00:29<00:14, 32.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5666000544954711/1 [00:30<00:14, 33.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5871867541555099/1 [00:30<00:15, 37.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | : 100% 1.0/1 [00:30<00:00,  4.57s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5910836846099212/1 [00:30<00:13, 33.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.594401188087146/1 [00:31<00:13, 32.79s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.5975028266120856/1 [00:31<00:14, 35.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6008771366557012/1 [00:31<00:13, 33.96s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6046718152906091/1 [00:31<00:12, 31.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6081142932138937/1 [00:31<00:12, 31.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6116476616434037/1 [00:31<00:12, 30.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6149197198675158/1 [00:31<00:13, 33.90s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6179418291995082/1 [00:31<00:13, 35.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.620850325398719/1 [00:32<00:15, 41.88s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6233838982597503/1 [00:32<00:16, 42.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  51% 0.5072565019384792/1 [00:32<00:03,  7.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6279511461975734/1 [00:32<00:18, 49.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6300757117805906/1 [00:32<00:18, 50.16s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6322343613034425/1 [00:32<00:18, 49.68s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6343021203200688/1 [00:32<00:18, 51.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  67% 0.6714670837317882/1 [00:32<00:01,  4.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.636290350143748/1 [00:32<00:18, 52.18s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  70% 0.7016703853201025/1 [00:32<00:01,  4.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6384944449197125/1 [00:32<00:18, 52.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  73% 0.7306019689468036/1 [00:32<00:01,  4.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6410280177807437/1 [00:33<00:17, 48.11s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  76% 0.7638256006939494/1 [00:33<00:00,  3.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6433116417496554/1 [00:33<00:17, 48.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  80% 0.7986388798931118/1 [00:33<00:00,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6458338532974084/1 [00:33<00:16, 45.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  83% 0.8290011462266277/1 [00:33<00:00,  3.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6480493093866511/1 [00:33<00:17, 50.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  86% 0.8579327298533288/1 [00:33<00:00,  3.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6500943457767211/1 [00:33<00:17, 50.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  89% 0.8870232782252316/1 [00:33<00:00,  3.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  39% 0.38606170609610596/1 [00:33<00:14, 23.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6527983383369249/1 [00:33<00:16, 48.63s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6548774586668294/1 [00:33<00:17, 49.61s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  96% 0.9561729423879513/1 [00:33<00:00,  3.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6569111337436213/1 [00:33<00:18, 53.80s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  98% 0.9843097022886441/1 [00:33<00:00,  3.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6592970095320364/1 [00:33<00:17, 50.40s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6618646663329022/1 [00:34<00:16, 47.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6639892319159194/1 [00:34<00:16, 48.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  75% 0.7470701505769056/1 [00:34<00:01,  4.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6680906660093378/1 [00:34<00:17, 51.44s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6702493155321895/1 [00:34<00:16, 51.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6724874942479885/1 [00:34<00:16, 49.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.7045036750658633/1 [00:36<00:11, 40.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | : 100% 1.0/1 [00:36<00:00,  2.53s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7079234303625916/1 [00:36<00:10, 36.27s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7108432878750806/1 [00:36<00:10, 35.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.713865397207073/1 [00:36<00:10, 35.09s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [00:36<00:00,  3.70s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7167398094664492/1 [00:36<00:09, 35.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :   0% 0.0006420630790921862/1 [00:36<15:45:18, 56755.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7196142217258256/1 [00:36<00:10, 37.47s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  14% 0.14061181432118877/1 [00:36<02:36, 182.37s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.722636331057818/1 [00:36<00:10, 36.16s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  28% 0.28058156556328534/1 [00:36<00:54, 75.68s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.725431214124247/1 [00:36<00:09, 36.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7282260971906762/1 [00:36<00:09, 36.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  72% 0.7158913117522208/1 [00:36<00:02, 10.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  58% 0.5810670865784284/1 [00:36<00:10, 24.17s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7310209802571053/1 [00:36<00:10, 39.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  74% 0.738372540956014/1 [00:36<00:04, 15.37s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  88% 0.8770581660399263/1 [00:37<00:01, 10.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7336227209978056/1 [00:37<00:12, 46.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7479379757282961/1 [00:37<00:09, 37.80s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | : 100% 1.0/1 [00:37<00:00, 10.69s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7520394098217145/1 [00:37<00:08, 32.90s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7551296870333759/1 [00:37<00:09, 38.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7581517963653683/1 [00:38<00:08, 36.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7610148473114664/1 [00:38<00:08, 36.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :  81% 0.8095691765460006/1 [00:38<00:03, 17.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7638324530044519/1 [00:38<00:08, 36.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  77% 0.7674794345667435/1 [00:38<00:07, 33.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  77% 0.7707855767306901/1 [00:38<00:07, 32.96s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  77% 0.7738644926290734/1 [00:38<00:07, 34.27s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  78% 0.7768184340813968/1 [00:38<00:07, 35.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.2 MB   | :  83% 0.8295627578919095/1 [00:38<00:02, 17.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  78% 0.780090492305509/1 [00:38<00:07, 33.86s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  78% 0.7830671563843887/1 [00:38<00:07, 34.44s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  79% 0.7859870138968778/1 [00:39<00:07, 37.19s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  79% 0.7887137290836378/1 [00:39<00:07, 37.11s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | :  93% 0.9284749037193442/1 [00:39<00:01, 19.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  79% 0.7920766778139753/1 [00:39<00:07, 34.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  80% 0.7952919294716966/1 [00:39<00:07, 35.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :  23% 0.22776305763944413/1 [00:39<01:33, 121.12s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  80% 0.7981663417310728/1 [00:39<00:07, 37.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  80% 0.8012338963161779/1 [00:39<00:07, 36.13s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | : 100% 1.0/1 [00:39<00:00, 19.80s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :   0% 0.000997983748775134/1 [00:39<11:01:02, 39701.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  80% 0.8046763742394626/1 [00:39<00:06, 34.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  81% 0.8076189543785078/1 [00:39<00:07, 38.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  81% 0.8105274505777186/1 [00:39<00:07, 37.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  82% 0.8174578516774006/1 [00:40<00:06, 33.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | : 100% 1.0/1 [00:40<00:00, 17.81s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  82% 0.820548128889062/1 [00:40<00:06, 34.51s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  82% 0.8240928586318501/1 [00:40<00:05, 32.64s/it]\n",
            "\n",
            "dgl-2.1.0.cu118      | 577.9 MB  | : 100% 1/1 [00:40<00:00, 40.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  47% 0.47044940437152877/1 [00:40<00:25, 48.66s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "dgl-2.1.0.cu118      | 577.9 MB  | : 100% 1/1 [00:40<00:00, 40.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [00:40<00:00, 16.04s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [00:40<00:00, 16.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  83% 0.8272172197833461/1 [00:40<00:05, 34.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  77% 0.7732440534054718/1 [00:40<00:05, 23.79s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  83% 0.830205245175504/1 [00:40<00:06, 38.09s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  84% 0.838839843266911/1 [00:40<00:05, 36.98s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | : 100% 1.0/1 [00:40<00:00, 23.79s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  99% 0.9894908573354066/1 [00:45<00:00, 30.96s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [00:59<00:00, 31.19s/it]               \n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.2.0    | 177.1 MB  | : 100% 1.0/1 [01:14<00:00, 23.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2023.1.0         | 171.5 MB  | : 100% 1.0/1 [01:21<00:00,  6.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcublas-12.1.0.26  | 329.0 MB  | : 100% 1.0/1 [01:43<00:00,  8.89s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | : 100% 1.0/1 [01:48<00:00,  5.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | : 100% 1.0/1 [02:07<00:00,  3.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | : 100% 1.0/1 [02:08<00:00,  4.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | : 100% 1.0/1 [02:15<00:00,  2.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | : 100% 1.0/1 [02:17<00:00, 10.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | : 100% 1.0/1 [02:19<00:00,  4.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | : 100% 1.0/1 [02:23<00:00, 17.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.2 MB   | : 100% 1.0/1 [02:23<00:00, 17.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | : 100% 1.0/1 [02:24<00:00, 19.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | : 100% 1.0/1 [02:28<00:00, 17.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [02:35<00:00,  3.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [02:36<00:00, 16.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | : 100% 1.0/1 [02:39<00:00, 23.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | : 100% 1.0/1 [03:26<00:00, 21.06s/it]\u001b[A\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [06:52<00:00, 31.19s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Installing pip dependencies: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| Ran pip subprocess with arguments:\n",
            "['/usr/local/miniconda/envs/graphany/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/GraphAny/condaenv.6ay5ra1b.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting ogb (from -r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1))\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting rootutils (from -r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 2))\n",
            "  Downloading rootutils-1.0.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting hydra_colorlog (from -r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 3))\n",
            "  Downloading hydra_colorlog-1.2.0-py3-none-any.whl.metadata (949 bytes)\n",
            "Collecting codetiming (from -r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 4))\n",
            "  Downloading codetiming-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting humanfriendly (from -r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting torch_frame (from -r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading torch_frame-1.7.5-py3-none-any.whl.metadata (763 bytes)\n",
            "Collecting pytorch-frame[full] (from -r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading pytorch_frame-0.2.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (1.6.1)\n",
            "Collecting pandas>=0.24.0 (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1))\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2.3.0)\n",
            "Collecting outdated>=0.2.0 (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1))\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting python-dotenv>=0.20.0 (from rootutils->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 2))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting colorlog (from hydra_colorlog->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 3))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra_colorlog->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 3)) (1.3.2)\n",
            "Collecting termcolor (from torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opencv-python (from torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tabulate (from torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting transformers>=4.25.1 (from torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting accelerate>=0.16.0 (from torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diffusers (from torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6)) (6.0.2)\n",
            "Collecting pyarrow (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (9.4.0)\n",
            "Collecting xgboost<2.0.0,>=1.7.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting optuna>=3.0.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting optuna-integration (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading optuna_integration-4.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (1.3.0)\n",
            "Collecting catboost (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting lightgbm (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting datasets (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (1.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6)) (7.0.0)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 3)) (4.9.3)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (75.8.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1))\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2025.1)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1))\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2025.2.0)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting graphviz (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting matplotlib (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy>=1.16.0 (from ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting plotly (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from diffusers->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6)) (8.6.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torchmetrics->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (0.12.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (1.18.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (2025.1.31)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from importlib-metadata->diffusers->torch_frame->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 6)) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 1)) (3.0.2)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7)) (3.2.1)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.6ay5ra1b.requirements.txt (line 7))\n",
            "  Downloading narwhals-1.29.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "Downloading rootutils-1.0.7-py3-none-any.whl (6.4 kB)\n",
            "Downloading hydra_colorlog-1.2.0-py3-none-any.whl (3.6 kB)\n",
            "Downloading codetiming-1.4.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading torch_frame-1.7.5-py3-none-any.whl (46 kB)\n",
            "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "    13.1/13.1 MB 121.4 MB/s eta 0:00:00\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "    10.0/10.0 MB 121.8 MB/s eta 0:00:00\n",
            "Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "    200.3/200.3 MB 69.0 MB/s eta 0:00:00\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "    98.7/98.7 MB 60.0 MB/s eta 0:00:00\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "    18.2/18.2 MB 163.9 MB/s eta 0:00:00\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "    42.1/42.1 MB 53.7 MB/s eta 0:00:00\n",
            "Downloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "    3.2/3.2 MB 80.3 MB/s eta 0:00:00\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "    3.6/3.6 MB 110.5 MB/s eta 0:00:00\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "    63.0/63.0 MB 67.4 MB/s eta 0:00:00\n",
            "Downloading optuna_integration-4.2.1-py3-none-any.whl (97 kB)\n",
            "Downloading pytorch_frame-0.2.5-py3-none-any.whl (144 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "    781.7/781.7 kB 38.3 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "    3.1/3.1 MB 85.6 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "    3.0/3.0 MB 109.9 MB/s eta 0:00:00\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "    8.6/8.6 MB 121.3 MB/s eta 0:00:00\n",
            "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
            "    14.8/14.8 MB 132.3 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "    4.6/4.6 MB 83.8 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
            "    599.5/599.5 kB 27.7 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "    1.6/1.6 MB 75.2 MB/s eta 0:00:00\n",
            "Downloading narwhals-1.29.0-py3-none-any.whl (305 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: xxhash, tzdata, termcolor, tabulate, safetensors, regex, python-dotenv, pyarrow, numpy, narwhals, Mako, littleutils, kiwisolver, humanfriendly, greenlet, graphviz, fsspec, fonttools, dill, cycler, colorlog, codetiming, sqlalchemy, rootutils, plotly, pandas, outdated, opencv-python, multiprocess, huggingface-hub, contourpy, xgboost, tokenizers, pytorch-frame, matplotlib, lightgbm, hydra_colorlog, diffusers, alembic, accelerate, transformers, optuna, ogb, catboost, torch_frame, optuna-integration, datasets\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.3\n",
            "    Uninstalling numpy-2.2.3:\n",
            "      Successfully uninstalled numpy-2.2.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.2.0\n",
            "    Uninstalling fsspec-2025.2.0:\n",
            "      Successfully uninstalled fsspec-2025.2.0\n",
            "Successfully installed Mako-1.3.9 accelerate-1.4.0 alembic-1.14.1 catboost-1.2.7 codetiming-1.4.0 colorlog-6.9.0 contourpy-1.3.1 cycler-0.12.1 datasets-3.3.2 diffusers-0.32.2 dill-0.3.8 fonttools-4.56.0 fsspec-2024.12.0 graphviz-0.20.3 greenlet-3.1.1 huggingface-hub-0.29.1 humanfriendly-10.0 hydra_colorlog-1.2.0 kiwisolver-1.4.8 lightgbm-4.6.0 littleutils-0.2.4 matplotlib-3.10.1 multiprocess-0.70.16 narwhals-1.29.0 numpy-1.26.4 ogb-1.3.6 opencv-python-4.11.0.86 optuna-4.2.1 optuna-integration-4.2.1 outdated-0.2.2 pandas-2.2.3 plotly-6.0.0 pyarrow-19.0.1 python-dotenv-1.0.1 pytorch-frame-0.2.5 regex-2024.11.6 rootutils-1.0.7 safetensors-0.5.3 sqlalchemy-2.0.38 tabulate-0.9.0 termcolor-2.5.0 tokenizers-0.21.0 torch_frame-1.7.5 transformers-4.49.0 tzdata-2025.1 xgboost-1.7.6 xxhash-3.5.0\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate graphany\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'name': 'graphany',\n",
        "    'channels': [\n",
        "        'pytorch',\n",
        "        'pyg',\n",
        "        'nvidia',\n",
        "        'conda-forge',\n",
        "        'defaults',\n",
        "        'dglteam/label/cu118'\n",
        "    ],\n",
        "    'dependencies': [\n",
        "        'python=3.10',\n",
        "        'cudatoolkit=11.8',\n",
        "        'pyg',\n",
        "        'pytorch=2.2.1',\n",
        "        'torchvision',\n",
        "        'torchaudio',\n",
        "        'torchdata=0.7.1',\n",
        "        'dgl',\n",
        "        'lightning=2.*',\n",
        "        'pydantic',\n",
        "        'wandb',\n",
        "        'rich',\n",
        "        'hydra-core',\n",
        "        'jupyter',\n",
        "        'einops',\n",
        "        'tensorboard',\n",
        "        'pip',\n",
        "        {\n",
        "            'pip': [\n",
        "                'ogb',\n",
        "                'rootutils',\n",
        "                'hydra_colorlog',\n",
        "                # For time logging\n",
        "                'codetiming',\n",
        "                'humanfriendly',\n",
        "                'torch_frame',\n",
        "                'pytorch-frame[full]'\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "sys.path.insert(0,'/content/GraphAny')\n",
        "\n",
        "\n",
        "with open('GraphAny/environment.yaml', 'w') as file:\n",
        "    yaml.dump(data, file)\n",
        "\n",
        "\n",
        "\n",
        "!wget -O Miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda.sh -b -p /usr/local/miniconda\n",
        "\n",
        "os.environ['PATH'] = '/usr/local/miniconda/bin:' + os.environ['PATH']\n",
        "\n",
        "!conda update conda -y -q\n",
        "!source /usr/local/etc/profile.d/conda.sh\n",
        "!conda init\n",
        "!conda install -n root _license -y -q\n",
        "\n",
        "!conda env create -f GraphAny/environment.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwHPwzzJfr1y",
        "outputId": "50d31bb7-c414-4f7d-b34d-3adf2ec213c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '/env/python', '/usr/local/miniconda/envs/graphany/lib/python310.zip', '/usr/local/miniconda/envs/graphany/lib/python3.10', '/usr/local/miniconda/envs/graphany/lib/python3.10/lib-dynload', '/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages', '/usr/local/lib/python3.10/site-packages']\n",
            "Python version\n",
            "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate graphany\n",
        "\n",
        "python\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "# some simple python commands\n",
        "sys.path.append('/usr/local/lib/python3.10/site-packages')\n",
        "print(sys.path)\n",
        "\n",
        "print(\"Python version\")\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda config --add channels pytorch\n",
        "!source activate graphany && conda config --add channels pyg\n",
        "!source activate graphany && conda config --add channels nvidia\n",
        "!source activate graphany && conda config --add channels conda-forge\n",
        "!source activate graphany && conda config --add channels dglteam/label/cu118"
      ],
      "metadata": {
        "id": "ENRRADzupiU6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda list torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBhCyXx32AXi",
        "outputId": "4e595342-896a-496b-9424-11c5d9bc5267"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# packages in environment at /usr/local/miniconda/envs/graphany:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "pytorch                   2.2.1           py3.10_cuda12.1_cudnn8.9.2_0    pytorch\n",
            "pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n",
            "pytorch-frame             0.2.5                    pypi_0    pypi\n",
            "pytorch-lightning         2.5.0.post0        pyh101cb37_0    conda-forge\n",
            "pytorch-mutex             1.0                        cuda    pytorch\n",
            "torch-frame               1.7.5                    pypi_0    pypi\n",
            "torchaudio                2.2.1               py310_cu121    pytorch\n",
            "torchdata                 0.7.1                     py310    pytorch\n",
            "torchmetrics              1.6.2              pyhd8ed1ab_0    conda-forge\n",
            "torchtriton               2.2.0                     py310    pytorch\n",
            "torchvision               0.17.1              py310_cu121    pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wg0WnaJhM3f"
      },
      "source": [
        "# F1 and H&M Datasets Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKbBdLDuhaLT"
      },
      "source": [
        "## Update `configs/data.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIuYTpWCjgcK"
      },
      "outputs": [],
      "source": [
        "# leggiamo tutto il file yaml\n",
        "file_path = 'GraphAny/configs/data.yaml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# aggiungo i metadati del dataset F1 al file yaml\n",
        "data['_ds_meta_data']['F1'] = 'relbench, f1_3_classes_remastered'\n",
        "# aggiungo i metadati del dataset H&M al file yaml\n",
        "data['_ds_meta_data']['HM'] = 'relbench, hm_3_classes'\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "453-Ir-Okjtc"
      },
      "outputs": [],
      "source": [
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "# Aggiungo il nuovo elemento _dataset_lookup\n",
        "data['_dataset_lookup']['F1Debug'] = {\n",
        "    'train': ['Wisconsin'],\n",
        "    'eval': ['F1']\n",
        "}\n",
        "data['_dataset_lookup']['HMDebug'] = {\n",
        "    'train': ['Wisconsin'],\n",
        "    'eval': ['HM']\n",
        "}\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCjvqIMLmVON"
      },
      "source": [
        "## Implement the dataset interface and update `GraphDataset` class in `data.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l5Y0yWWBowc-"
      },
      "outputs": [],
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import os.path\n",
        "import os.path as osp\n",
        "import re\n",
        "import ssl\n",
        "import sys\n",
        "import urllib\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "#from torch_frame import TensorFrame\n",
        "import requests\n",
        "\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import OmegaConf\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.manifold._utils import (\n",
        "    _binary_search_perplexity as sklearn_binary_search_perplexity,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from graphany.utils import logger, timer\n",
        "\n",
        "\n",
        "def get_entropy_normed_cond_gaussian_prob(X, entropy, metric=\"euclidean\"):\n",
        "\n",
        "    #Parameters\n",
        "    #----------\n",
        "    #X:              The matrix for pairwise similarity\n",
        "    #entropy:     Perplexity of the conditional prob distribution\n",
        "    #Returns the entropy-normalized conditional gaussian probability based on distances.\n",
        "    #-------\n",
        "\n",
        "\n",
        "    # Compute pairwise distances\n",
        "    perplexity = np.exp2(entropy)\n",
        "    distances = pdist(X, metric=metric)\n",
        "    distances = squareform(distances)\n",
        "\n",
        "    # Compute the squared distances\n",
        "    distances **= 2\n",
        "    distances = distances.astype(np.float32)\n",
        "    return sklearn_binary_search_perplexity(distances, perplexity, verbose=0)\n",
        "\n",
        "\n",
        "def sample_k_nodes_per_label(label, visible_nodes, k, num_class):\n",
        "    ref_node_idx = [\n",
        "        (label[visible_nodes] == lbl).nonzero().view(-1) for lbl in range(num_class)\n",
        "    ]\n",
        "    sampled_indices = [\n",
        "        label_indices[torch.randperm(len(label_indices))[:k]]\n",
        "        for label_indices in ref_node_idx\n",
        "    ]\n",
        "    return visible_nodes[torch.cat(sampled_indices)]\n",
        "\n",
        "\n",
        "def get_data_split_masks(n_nodes, labels, num_train_nodes, label_idx=None, seed=42):\n",
        "    label_idx = np.arange(n_nodes)\n",
        "    test_rate_in_labeled_nodes = (len(labels) - num_train_nodes) / len(labels)\n",
        "    train_idx, test_and_valid_idx = train_test_split(\n",
        "        label_idx,\n",
        "        test_size=test_rate_in_labeled_nodes,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels,\n",
        "    )\n",
        "    valid_idx, test_idx = train_test_split(\n",
        "        test_and_valid_idx,\n",
        "        test_size=0.5,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels[test_and_valid_idx],\n",
        "    )\n",
        "    train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[train_idx] = True\n",
        "    val_mask[valid_idx] = True\n",
        "    test_mask[test_idx] = True\n",
        "\n",
        "    return train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def download_url(url: str, folder: str, log: bool = True, filename=None):\n",
        "    #Modified from torch_geometric.data.download_url\n",
        "\n",
        "    #Downloads the content of an URL to a specific folder.\n",
        "\n",
        "    #Args:\n",
        "        #url (str): The URL.\n",
        "        #folder (str): The folder.\n",
        "        #log (bool, optional): If :obj:`False`, will not print anything to the\n",
        "            #console. (default: :obj:`True`)\n",
        "\n",
        "\n",
        "    if filename is None:\n",
        "        filename = url.rpartition(\"/\")[2]\n",
        "        filename = filename if filename[0] == \"?\" else filename.split(\"?\")[0]\n",
        "\n",
        "    path = osp.join(folder, filename)\n",
        "\n",
        "    if osp.exists(path):  # pragma: no cover\n",
        "        if log and \"pytest\" not in sys.modules:\n",
        "            print(f\"Using existing file {filename}\", file=sys.stderr)\n",
        "        return path\n",
        "\n",
        "    if log and \"pytest\" not in sys.modules:\n",
        "        print(f\"Downloading {url}\", file=sys.stderr)\n",
        "\n",
        "    os.makedirs(osp.expanduser(osp.normpath(folder)), exist_ok=True)\n",
        "\n",
        "    context = ssl._create_unverified_context()\n",
        "    data = urllib.request.urlopen(url, context=context)\n",
        "\n",
        "    with open(path, \"wb\") as f:\n",
        "        # workaround for https://bugs.python.org/issue42853\n",
        "        while True:\n",
        "            chunk = data.read(10 * 1024 * 1024)\n",
        "            if not chunk:\n",
        "                break\n",
        "            f.write(chunk)\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "def download_file_from_google_drive(url, destination, filename=\"data.pkl\"):\n",
        "    path = osp.join(destination, filename)\n",
        "    os.makedirs(osp.expanduser(osp.normpath(destination)), exist_ok=True)\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(url, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {'confirm' : token }\n",
        "        response = session.get(url, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, path)\n",
        "    return path\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 10 * 1024 * 1024\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "'''\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url, raw_dir)\n",
        "    download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "'''\n",
        "\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url[0], raw_dir)\n",
        "    # download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(raw_dir, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def load_heterophilous_dataset(url, raw_dir):\n",
        "    # Wrap Heterophilous to DGL Graph Dataset format https://arxiv.org/pdf/2302.11640.pdf\n",
        "    download_path = download_url(url, raw_dir)\n",
        "    data = np.load(download_path)\n",
        "    node_features = torch.tensor(data[\"node_features\"])\n",
        "    labels = torch.tensor(data[\"node_labels\"])\n",
        "    edges = torch.tensor(data[\"edges\"])\n",
        "\n",
        "    #\n",
        "    '''\n",
        "    print(f\"node_features  un: {type(data['node_features'])} con size: {data['node_features'].shape}\")\n",
        "    print(data['node_features'][0])\n",
        "    print(f\"node_labels  un: {type(data['node_labels'])} con size: {data['node_labels'].shape}\")\n",
        "    print(data['node_labels'][0])\n",
        "    print(f\"edges  un: {type(data['edges'])} con size: {data['edges'].shape}\")\n",
        "    print(data['edges'][0])\n",
        "    '''\n",
        "    #\n",
        "\n",
        "    graph = dgl.graph(\n",
        "        (edges[:, 0], edges[:, 1]), num_nodes=len(node_features), idtype=torch.int\n",
        "    )\n",
        "    num_classes = len(labels.unique())\n",
        "    num_targets = 1 if num_classes == 2 else num_classes\n",
        "    if num_targets == 1:\n",
        "        labels = labels.float()\n",
        "    train_masks = torch.tensor(data[\"train_masks\"]).T\n",
        "    val_masks = torch.tensor(data[\"val_masks\"]).T\n",
        "    test_masks = torch.tensor(data[\"test_masks\"]).T\n",
        "\n",
        "    '''\n",
        "    print(f\"la size della train mask : {data['train_masks'].shape}\")\n",
        "    print(data['train_masks'][0])\n",
        "    print(data['train_masks'][1])\n",
        "    print(data['train_masks'][2])\n",
        "    '''\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_masks, val_masks, test_masks\n",
        "\n",
        "\n",
        "class CombinedDataset(pl.LightningDataModule):\n",
        "    def __init__(self, train_ds_dict, eval_ds_dict, cfg):\n",
        "        super().__init__()\n",
        "        self.train_ds_dict = train_ds_dict\n",
        "        self.eval_ds_dict = eval_ds_dict\n",
        "        self.all_ds = list(self.train_ds_dict.values()) + list(\n",
        "            self.eval_ds_dict.values()\n",
        "        )\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def to(self, device):\n",
        "        for ds in self.all_ds:\n",
        "            ds.to(device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.train_dataloader() for name, ds in self.train_ds_dict.items()\n",
        "        }\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"min_size\")\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.val_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.test_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "\n",
        "class GraphDataset(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            cfg,\n",
        "            ds_name,\n",
        "            cache_dir,\n",
        "            train_batch_size=256,\n",
        "            val_test_batch_size=256,\n",
        "            n_hops=1,\n",
        "            preprocess_device=torch.device(\"cpu\"),\n",
        "            permute_label=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.name = ds_name\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.permute_label = permute_label  # For checking label equivariance\n",
        "        self.val_test_batch_size = val_test_batch_size\n",
        "        self.preprocess_device = preprocess_device\n",
        "\n",
        "        self.n_hops = n_hops\n",
        "\n",
        "        self.data_source, ds_alias = cfg[\"_ds_meta_data\"][ds_name].split(\", \")\n",
        "        self.gidtype = None\n",
        "        self.dist = None\n",
        "        self.unmasked_pred = None\n",
        "        if self.data_source == \"pyg\":\n",
        "            components = ds_alias.split(\".\")\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"torch_geometric.datasets.{ds_alias}\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}/\",\n",
        "            }\n",
        "            if len(components) == 2:  # If sub-dataset\n",
        "                ds_init_args[\"_target_\"] = f\"torch_geometric.datasets.{components[0]}\"\n",
        "                ds_init_args[\"name\"] = components[1]\n",
        "        elif self.data_source == \"dgl\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"dgl.data.{ds_alias}\",\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "            }\n",
        "        elif self.data_source == \"ogb\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"ogb.nodeproppred.DglNodePropPredDataset\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"name\": ds_alias,\n",
        "            }\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            target = \"graphany.data.load_heterophilous_dataset\"\n",
        "            url = f\"https://raw.githubusercontent.com/yandex-research/heterophilous-graphs/main/data/{ds_alias}.npz\"\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"url\": url,\n",
        "            }\n",
        "        elif self.data_source == \"relbench\":\n",
        "            target = \"graphany.data.load_relbench_dataset\"\n",
        "            # url = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}.pkl\"\n",
        "            '''\n",
        "            if ds_alias == \"f1_3_classes\":\n",
        "                url = \"https://drive.google.com/file/d/16pyMEgYqX-5hnctXVSa0oB1YCOxFsSa_/view?usp=sharing\"\n",
        "            else:\n",
        "                url1 = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}3.pkl\"\n",
        "                url2 = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}3.pkl\"\n",
        "            '''\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}.pkl\",\n",
        "                # \"url\": url,\n",
        "                \"url\" : \"\",\n",
        "            }\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        self.data_init_args = OmegaConf.create(ds_init_args)\n",
        "        # self.cache_f_name = osp.join(\n",
        "        #     cache_dir, f'{self.name}_{n_hops}')\n",
        "        if cfg.get(\"feat_chn\"):\n",
        "            all_channels = \"+\".join([cfg.feat_chn, cfg.pred_chn])\n",
        "            all_hops = re.findall(r\"\\d+\", all_channels)\n",
        "            n_hops = max(max([int(_) for _ in all_hops]), n_hops)\n",
        "\n",
        "        self.split_index = 0\n",
        "        (\n",
        "            self.g,\n",
        "            self.label,\n",
        "            self.feat,\n",
        "            self.train_mask,\n",
        "            self.val_mask,\n",
        "            self.test_mask,\n",
        "            self.num_class,\n",
        "        ) = self.load_dataset(self.data_init_args)\n",
        "        self.n_nodes, self.n_edges = self.g.num_nodes(), self.g.num_edges()\n",
        "        self.cache_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}.pt\",\n",
        "        )\n",
        "\n",
        "        self.dist_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}_{cfg.feat_chn}_entropy={cfg.entropy}_dist.pt\",\n",
        "        )\n",
        "\n",
        "        self.gidtype = self.g.idtype\n",
        "        self.train_indices = self.train_mask.nonzero().view(-1)\n",
        "\n",
        "        (\n",
        "            self.features,\n",
        "            self.unmasked_pred,\n",
        "            self.dist,\n",
        "        ) = self.prepare_prop_features_logits_and_dist_features(\n",
        "            self.g, self.feat, n_hops=cfg.n_hops\n",
        "        )\n",
        "        # Remove the graph, as GraphAny doesn't use it in training\n",
        "        del self.g\n",
        "        del self.feat\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def to(self, device):  # Supports nested dictionary\n",
        "        def to_device(input):\n",
        "            if input is None:\n",
        "                return None\n",
        "            elif isinstance(input, dict):\n",
        "                return {key: to_device(value) for key, value in input.items()}\n",
        "            elif isinstance(input, list):\n",
        "                return [to_device(item) for item in input]\n",
        "            elif hasattr(input, \"to\"):\n",
        "                return input.to(device)\n",
        "            else:\n",
        "                return (\n",
        "                    input  # Return as is if it's not a tensor or any nested structure\n",
        "                )\n",
        "\n",
        "        # Apply to_device to all attributes that may contain tensors\n",
        "        attrs = [\n",
        "            \"label\",\n",
        "            \"feat\",\n",
        "            \"train_mask\",\n",
        "            \"val_mask\",\n",
        "            \"test_mask\",\n",
        "            \"train_indices\",\n",
        "            \"unmasked_pred\",\n",
        "        ]\n",
        "        for attr in attrs:\n",
        "            if hasattr(self, attr):\n",
        "                setattr(self, attr, to_device(getattr(self, attr)))\n",
        "\n",
        "    def load_dataset(self, data_init_args):\n",
        "        dataset = instantiate(data_init_args)\n",
        "\n",
        "        if self.data_source == \"ogb\":\n",
        "            split_idx = dataset.get_idx_split()\n",
        "            train_indices, valid_indices, test_indices = (\n",
        "                split_idx[\"train\"],\n",
        "                split_idx[\"valid\"],\n",
        "                split_idx[\"test\"],\n",
        "            )\n",
        "            # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)\n",
        "            g, label = dataset[0]\n",
        "            label = label.view(-1)\n",
        "\n",
        "            def to_mask(indices):\n",
        "                mask = torch.BoolTensor(g.number_of_nodes()).fill_(False)\n",
        "                mask[indices] = 1\n",
        "                return mask\n",
        "\n",
        "            train_mask, val_mask, test_mask = map(\n",
        "                to_mask, (train_indices, valid_indices, test_indices)\n",
        "            )\n",
        "\n",
        "            num_class = label.max().item() + 1\n",
        "\n",
        "            feat = g.ndata[\"feat\"]\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"relbench\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"dgl\":\n",
        "            g = dataset[0]\n",
        "            num_class = dataset.num_classes\n",
        "\n",
        "            # get node feature\n",
        "            feat = g.ndata[\"feat\"]\n",
        "\n",
        "            # get data split\n",
        "            train_mask = g.ndata[\"train_mask\"]\n",
        "            val_mask = g.ndata[\"val_mask\"]\n",
        "            test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "            label = g.ndata[\"label\"]\n",
        "        elif self.data_source == \"pyg\":\n",
        "            g = dgl.graph((dataset.edge_index[0], dataset.edge_index[1]))\n",
        "            n_nodes = dataset.x.shape[0]\n",
        "            num_class = dataset.num_classes\n",
        "            # get node feature\n",
        "            feat = dataset.x\n",
        "            label = dataset.y\n",
        "\n",
        "            if (\n",
        "                    hasattr(dataset, \"train_mask\")\n",
        "                    and hasattr(dataset, \"val_mask\")\n",
        "                    and hasattr(dataset, \"test_mask\")\n",
        "            ):\n",
        "                train_mask, val_mask, test_mask = (\n",
        "                    dataset.train_mask,\n",
        "                    dataset.val_mask,\n",
        "                    dataset.test_mask,\n",
        "                )\n",
        "            else:\n",
        "                if label.ndim > 1:\n",
        "                    raise NotImplementedError(\n",
        "                        \"Multi-Label classification currently unsupported.\"\n",
        "                    )\n",
        "                logging.warning(\n",
        "                    f\"No dataset split found for {self.name}, splitting with semi-supervised settings!!\"\n",
        "                )\n",
        "                train_mask, val_mask, test_mask = get_data_split_masks(\n",
        "                    n_nodes, label, 20 * num_class, seed=self.cfg.seed\n",
        "                )\n",
        "\n",
        "                self.split_index = self.cfg.seed\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        if train_mask.ndim == 1:\n",
        "            pass  # only one train/val/test split\n",
        "        elif train_mask.ndim == 2:\n",
        "            # ! Multiple splits\n",
        "            # Modified: Use the ${seed} split if not specified!\n",
        "            split_index = self.data_init_args.get(\"split\", self.cfg.seed)\n",
        "            # Avoid invalid split index\n",
        "            self.split_index = split_index = (split_index % train_mask.ndim)\n",
        "            train_mask = train_mask[:, split_index].squeeze()\n",
        "            val_mask = val_mask[:, split_index].squeeze()\n",
        "            if test_mask.ndim == 2:\n",
        "                test_mask = test_mask[:, split_index].squeeze()\n",
        "        else:\n",
        "            raise ValueError(\"train/val/test masks have more than 2 dimensions\")\n",
        "        print(\n",
        "            f\"{self.name} {g.num_nodes()} {g.num_edges()} {feat.shape[1]} {num_class} {len(train_mask.nonzero())}\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.add_self_loop:\n",
        "            g = dgl.add_self_loop(g)\n",
        "        else:\n",
        "            g = dgl.remove_self_loop(g)\n",
        "        if self.cfg.to_bidirected:\n",
        "            g = dgl.to_bidirected(g)\n",
        "        g = dgl.to_simple(g)  # Remove duplicate edges.\n",
        "        return g, label, feat, train_mask, val_mask, test_mask, num_class\n",
        "\n",
        "    def compute_linear_gnn_logits(\n",
        "            self, features, n_per_label_examples, visible_nodes, bootstrap=False\n",
        "    ):\n",
        "        # Compute and save LinearGNN logits into a dict. Note the computation is on CPU as torch does not support\n",
        "        # the gelss driver on GPU currently.\n",
        "        preds = {}\n",
        "        label, num_class, device = self.label, self.num_class, torch.device(\"cpu\")\n",
        "        label = label.to(device)\n",
        "        visible_nodes = visible_nodes.to(device)\n",
        "        for channel, F in features.items():\n",
        "            F = F.to(device)\n",
        "            if bootstrap:\n",
        "                ref_nodes = sample_k_nodes_per_label(\n",
        "                    label, visible_nodes, n_per_label_examples, num_class\n",
        "                )\n",
        "            else:\n",
        "                ref_nodes = visible_nodes\n",
        "            Y_L = torch.nn.functional.one_hot(label[ref_nodes], num_class).float()\n",
        "            with timer(\n",
        "                    f\"Solving with CPU driver (N={len(ref_nodes)}, d={F.shape[1]}, k={num_class})\",\n",
        "                    logger.debug,\n",
        "            ):\n",
        "                W = torch.linalg.lstsq(\n",
        "                    F[ref_nodes.cpu()].cpu(), Y_L.cpu(), driver=\"gelss\"\n",
        "                )[0]\n",
        "            preds[channel] = F @ W\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def compute_channel_logits(self, features, visible_nodes, sample, device):\n",
        "        pred_logits = self.compute_linear_gnn_logits(\n",
        "            {\n",
        "                c: features[c]\n",
        "                for c in set(self.cfg.feat_channels + self.cfg.pred_channels)\n",
        "            },\n",
        "            self.cfg.n_per_label_examples,\n",
        "            visible_nodes,\n",
        "            bootstrap=sample,\n",
        "        )\n",
        "        return {c: logits.to(device) for c, logits in pred_logits.items()}\n",
        "\n",
        "    def prepare_prop_features_logits_and_dist_features(self, g, input_feats, n_hops):\n",
        "        # Calculate Low-pass features containing AX, A^2X and High-pass features\n",
        "        # (I-A)X, and (I-A)^2X\n",
        "        if not os.path.exists(self.cache_f_name):\n",
        "            g = g.to(self.preprocess_device)\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} message passing and normalized predictions to file {self.cache_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                dim = input_feats.size(1)\n",
        "                LP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "                HP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "\n",
        "                g.ndata[\"LP\"] = input_feats.to(self.preprocess_device)\n",
        "                g.ndata[\"HP\"] = input_feats.to(self.preprocess_device)\n",
        "                for hop_idx in range(n_hops):\n",
        "                    # D^-1 A filter\n",
        "                    g.update_all(fn.copy_u(\"LP\", \"temp\"), fn.mean(\"temp\", \"LP\"))\n",
        "\n",
        "                    # (I - D^-1A) filter\n",
        "                    g.update_all(fn.copy_u(\"HP\", \"temp\"), fn.mean(\"temp\", \"HP_out\"))\n",
        "                    g.ndata[\"HP\"] = g.ndata[\"HP\"] - g.ndata[\"HP_out\"]\n",
        "\n",
        "                    LP[hop_idx] = g.ndata[\"LP\"].clone()\n",
        "                    HP[hop_idx] = g.ndata[\"HP\"].clone()\n",
        "                lp_feat_dict = {f\"L{l + 1}\": x for l, x in enumerate(LP)}\n",
        "                hp_feat_dict = {f\"H{l + 1}\": x for l, x in enumerate(HP)}\n",
        "\n",
        "                features = {\"X\": input_feats, **lp_feat_dict, **hp_feat_dict}\n",
        "                unmasked_pred = self.compute_channel_logits(\n",
        "                    features,\n",
        "                    self.train_indices,\n",
        "                    sample=False,\n",
        "                    device=self.preprocess_device,\n",
        "                )\n",
        "                torch.save((features, unmasked_pred), self.cache_f_name)\n",
        "        else:\n",
        "            features, unmasked_pred = torch.load(self.cache_f_name, map_location=\"cpu\")\n",
        "        if not os.path.exists(self.dist_f_name):\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} conditional gaussian distances \"\n",
        "                    f\"and save to {self.dist_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                # y_feat: n_nodes, n_channels, n_labels\n",
        "                y_feat = np.stack(\n",
        "                    [unmasked_pred[c].cpu().numpy() for c in self.cfg.feat_channels],\n",
        "                    axis=1,\n",
        "                )\n",
        "                # Conditional gaussian probability\n",
        "                bsz, n_channel, n_class = y_feat.shape\n",
        "                dist_feat_dim = n_channel * (n_channel - 1)\n",
        "                # Conditional gaussian probability\n",
        "                cond_gaussian_prob = np.zeros((bsz, n_channel, n_channel))\n",
        "                for i in range(bsz):\n",
        "                    cond_gaussian_prob[i, :, :] = get_entropy_normed_cond_gaussian_prob(\n",
        "                        y_feat[i, :, :], self.cfg.entropy\n",
        "                    )\n",
        "                dist = np.zeros((bsz, dist_feat_dim), dtype=np.float32)\n",
        "\n",
        "                # Compute pairwise distances between channels n_channels(n_channels-1)/2 total features\n",
        "                pair_index = 0\n",
        "                for c in range(n_channel):\n",
        "                    for c_prime in range(n_channel):\n",
        "                        if c != c_prime:  # Diagonal distances are useless\n",
        "                            dist[:, pair_index] = cond_gaussian_prob[:, c, c_prime]\n",
        "                            pair_index += 1\n",
        "\n",
        "                dist = torch.from_numpy(dist)\n",
        "                torch.save(dist, self.dist_f_name)\n",
        "        else:\n",
        "            dist = torch.load(self.dist_f_name, map_location=\"cpu\")\n",
        "        return features, unmasked_pred, dist\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_mask.nonzero().view(-1),\n",
        "            batch_size=self.train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "riTRCN1OnR2k"
      },
      "outputs": [],
      "source": [
        "path_name = 'GraphAny/graphany/data.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFSPf9jrIEfg"
      },
      "source": [
        "# Testing GraphAny on F1 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XMxpGG22Lc10"
      },
      "outputs": [],
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqd5y77pmiyI",
        "outputId": "404db92f-988a-4ed6-f941-f38f2e03331a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[15:28:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mMar4-15\u001b[0m:\u001b[1;36m28\u001b[0m-\u001b[1;36m2e114737\u001b[0m/                                                         \u001b[2mexperiment.py:56\u001b[0m\n",
            "Done loading data from cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "F1 97605 455432 300 3 66303\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 message passing and normalized predictions to file                                                            \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:17\u001b[0m                                            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:28:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 message passing and normalized predictions to file                                                           \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:23\u001b[0m, running time = \u001b[1;36m6.27\u001b[0m seconds.              \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 conditional gaussian distances and save to                                                                    \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:23\u001b[0m               \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:28:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 conditional gaussian distances and save to                                                                   \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:28\u001b[0m, running time \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         = \u001b[1;36m4.95\u001b[0m seconds.                                                                                                                    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:28\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.30it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m[15:28:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                                \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.16it/s]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 205.56it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 71.38it/s] \n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:289\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                                   \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                               \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:29\u001b[0m, running time = \u001b[1;36m12.97\u001b[0m seconds.                                                                     \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing GraphAny on H&M Dataset"
      ],
      "metadata": {
        "id": "kDmsHZrZERak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"HMDebug\" # we want to use the H&M dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ],
      "metadata": {
        "id": "r2Go5bLSEYCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFwz2SRNEbcR",
        "outputId": "b8f1b941-66d1-4c33-f0d2-a9af671f4299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "\u001b[2;36m[11:29:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mFeb20-11\u001b[0m:\u001b[1;36m29\u001b[0m-67b5ea93/                                                        \u001b[2mexperiment.py:56\u001b[0m\n",
            "Downloading /content/data/dgl/wisconsin.zip from https://data.dgl.ai/dataset/wisconsin.zip...\n",
            "/content/data/dgl/wisconsin.zip: 100% 41.2k/41.2k [00:00<00:00, 8.90MB/s]\n",
            "Extracting file to /content/data/dgl/wisconsin_5bfc48b0\n",
            "Done saving data into cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Wisconsin message passing and normalized predictions to file                                                     \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:00\u001b[0m                                     \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[11:29:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Wisconsin message passing and normalized predictions to file                                                    \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:01\u001b[0m, running time = \u001b[1;36m0.69\u001b[0m seconds.       \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Wisconsin conditional gaussian distances and save to                                                             \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:01\u001b[0m        \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Wisconsin conditional gaussian distances and save to                                                            \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:01\u001b[0m,       \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         running time = \u001b[1;36m0.02\u001b[0m seconds.                                                                                                       \u001b[2m              \u001b[0m\n",
            "Downloading https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/hm_3_classes.pkl\n",
            "HM 11147 5816 300 3 5957\n",
            "\u001b[2;36m[11:29:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing HM message passing and normalized predictions to file                                                            \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:02\u001b[0m                                            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing HM message passing and normalized predictions to file                                                           \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:02\u001b[0m, running time = \u001b[1;36m0.54\u001b[0m seconds.              \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing HM conditional gaussian distances and save to                                                                    \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:02\u001b[0m               \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[11:29:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing HM conditional gaussian distances and save to                                                                   \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:03\u001b[0m, running time \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         = \u001b[1;36m0.46\u001b[0m seconds.                                                                                                                    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:28\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.19it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.08it/s]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/hm_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 111.66it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_test_acc'\u001b[0m: \u001b[1;36m99.97000122070312\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m99.97000122070312\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m99.97000122070312\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 52.62it/s] \n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/hm_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    99.97000122070312    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    99.97000122070312    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    99.97000122070312    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:289\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_test_acc'\u001b[0m: \u001b[1;36m99.97\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m99.97\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m99.97\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:03\u001b[0m, running time = \u001b[1;36m3.97\u001b[0m seconds.                                                                      \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing GraphAny on F1 Dataset prediction files"
      ],
      "metadata": {
        "id": "j_34PmXAZ3_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import rootutils\n",
        "\n",
        "root = rootutils.setup_root(__file__, dotenv=True, pythonpath=True, cwd=False)\n",
        "from graphany.utils import logger, timer\n",
        "from graphany.utils.experiment import init_experiment\n",
        "from graphany.data import GraphDataset, CombinedDataset\n",
        "from graphany.model import GraphAny\n",
        "\n",
        "import torch\n",
        "import hydra\n",
        "from omegaconf import DictConfig\n",
        "import wandb\n",
        "import numpy as np\n",
        "import torchmetrics\n",
        "from rich.pretty import pretty_repr\n",
        "\n",
        "import os\n",
        "\n",
        "mean = lambda input: np.round(np.mean(input).item(), 2)\n",
        "\n",
        "\n",
        "class InductiveNodeClassification(pl.LightningModule):\n",
        "    def __init__(self, cfg, combined_dataset, checkpoint=None):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if checkpoint:\n",
        "            # Initialize from previous checkpoint using previous graphany config\n",
        "            ckpt = torch.load(checkpoint, map_location=\"cpu\")\n",
        "            logger.critical(f\"Loaded checkpoint at {checkpoint}\")\n",
        "            self.gnn_model = GraphAny(**ckpt[\"graph_any_config\"])\n",
        "            self.load_state_dict(ckpt[\"state_dict\"])\n",
        "        else:\n",
        "            self.gnn_model = GraphAny(**cfg.graph_any)\n",
        "        self.combined_dataset = combined_dataset\n",
        "        self.attn_dict, self.loss_dict, self.res_dict = {}, {}, {}\n",
        "        # Initialize accuracy metrics for validation and testing\n",
        "        self.metrics = {}\n",
        "        held_out_datasets = list(\n",
        "            set(self.cfg._all_datasets) - set(self.cfg._trans_datasets)\n",
        "        )  # 27 datasets in total\n",
        "        self.heldout_metrics = [\n",
        "            f\"{setting}/{d.lower()[:4]}_{split}_acc\"\n",
        "            for split in [\"val\", \"test\"]\n",
        "            for d in held_out_datasets\n",
        "            for setting in [\"trans\", \"ind\"]\n",
        "        ]\n",
        "        for split in (\"val\", \"test\"):\n",
        "            self.metrics[split] = {\n",
        "                k: torchmetrics.Accuracy(task=\"multiclass\", num_classes=v.num_class)\n",
        "                for k, v in combined_dataset.eval_ds_dict.items()\n",
        "            }\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def on_train_end(self):\n",
        "        checkpoint_path = f\"{self.cfg.dirs.output}{self.cfg.dataset}_val_acc={self.res_dict['val_acc']}.pt\"\n",
        "        self.save_checkpoint(checkpoint_path)\n",
        "\n",
        "    def save_checkpoint(self, file_path):\n",
        "        checkpoint = {\n",
        "            \"state_dict\": self.state_dict(),\n",
        "            \"optimizer_state_dict\": [\n",
        "                opt.state_dict() for opt in self.trainer.optimizers\n",
        "            ],\n",
        "            \"graph_any_config\": self.cfg.graph_any,\n",
        "        }\n",
        "        torch.save(checkpoint, file_path)\n",
        "        logger.critical(f\"Checkpoint saved to {file_path}\")\n",
        "\n",
        "    def get_metric_name(self, ds_name, split):\n",
        "        if ds_name in self.cfg.train_datasets:\n",
        "            return f\"trans/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "        else:\n",
        "            return f\"ind/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # start with all the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {\"params\": decay_params, \"weight_decay\": self.cfg.weight_decay},\n",
        "            {\"params\": nodecay_params, \"weight_decay\": 0.0},\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        logger.info(\n",
        "            f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\"\n",
        "        )\n",
        "        logger.info(\n",
        "            f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.optimizer == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=self.cfg.lr)\n",
        "        else:  # AdamW\n",
        "            optimizer = torch.optim.AdamW(\n",
        "                optim_groups,\n",
        "                lr=self.cfg.lr,\n",
        "                weight_decay=self.cfg.weight_decay,\n",
        "            )\n",
        "        return optimizer\n",
        "\n",
        "    def on_fit_start(self):\n",
        "        super().on_fit_start()\n",
        "        # move all datasets to the correct GPU device\n",
        "        print(f\"moving train and eval datasets to {self.device}\")\n",
        "        self.combined_dataset.to(self.device)\n",
        "        self.move_metrics_to_device()\n",
        "\n",
        "    def move_metrics_to_device(self):\n",
        "        for metrics_dict in self.metrics.values():\n",
        "            for metric in metrics_dict.values():\n",
        "                metric.to(self.device)\n",
        "\n",
        "    def predict(self, ds, nodes, input, is_training=False):\n",
        "        # Use preprocessed distance during evaluation\n",
        "        dist = ds.dist if not is_training else None\n",
        "        dist = dist.to(nodes.device)[nodes] if dist is not None else dist\n",
        "\n",
        "        preds, attn = self.gnn_model(\n",
        "            {c: chn_pred[nodes] for c, chn_pred in input.items()}, dist=dist\n",
        "        )\n",
        "\n",
        "        self.attn_dict.update(\n",
        "            {\n",
        "                f\"Attention/{ds.name}-{c}\": v\n",
        "                for c, v in zip(self.cfg.feat_channels, attn)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        def softmax(logits):\n",
        "          exp_logits = np.exp(logits - np.max(logits))  # Stabilizza l'esponenziale\n",
        "          return exp_logits / exp_logits.sum(axis=0)\n",
        "\n",
        "        # Scrittura delle predizioni in un file\n",
        "        with open(\"predizioni.txt\", \"a\") as file:  # Modalit append\n",
        "            for node, pred in zip(nodes.cpu().numpy(), preds.cpu().numpy()):\n",
        "                line = f\"Nodo:{node}\\tPredizione:{pred}\\tClasse:{np.argmax(softmax(pred))}\"\n",
        "                file.write(line + os.linesep)  # Scrive il nodo e la predizione\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        loss = {}\n",
        "        for ds_name, batch_nodes in batch.items():\n",
        "            ds = self.combined_dataset.train_ds_dict[ds_name]\n",
        "            train_target_idx = batch_nodes\n",
        "            # Batch nodes are not visible to avoid trivial solution and overfitting\n",
        "            visible_nodes = list(\n",
        "                set(ds.train_indices.tolist()) - set(batch_nodes.tolist())\n",
        "            )\n",
        "            ref_nodes = torch.tensor(visible_nodes, dtype=torch.long).to(self.device)\n",
        "            ds_too_small = len(visible_nodes) < len(batch_nodes)\n",
        "            if ds_too_small:\n",
        "                # Visible nodes are too few, add first half of the batch to visible nodes\n",
        "                ref_nodes = torch.cat((ref_nodes, batch_nodes[: len(batch_nodes) // 2]))\n",
        "\n",
        "            input = ds.compute_channel_logits(\n",
        "                ds.features, ref_nodes, sample=True, device=self.device\n",
        "            )\n",
        "\n",
        "            preds = self.predict(ds, train_target_idx, input, is_training=True)\n",
        "            loss[f\"loss/{ds_name}_loss\"] = self.criterion(\n",
        "                preds, ds.label[train_target_idx]\n",
        "            )\n",
        "\n",
        "        detached_loss = {k: v.detach().cpu() for k, v in loss.items()}\n",
        "        avg_loss = mean(list(detached_loss.values()))\n",
        "        self.loss_dict.update({\"loss/avg_loss\": avg_loss, **detached_loss})\n",
        "        return sum(loss.values())\n",
        "\n",
        "    def evaluation_step(self, split, batch, batch_idx):\n",
        "        self.move_metrics_to_device()\n",
        "        for ds_name, eval_idx in batch.items():\n",
        "            if eval_idx is None:  # Skip if dataset is already evaluated (empty batch)\n",
        "                continue\n",
        "            ds = self.combined_dataset.eval_ds_dict[ds_name]\n",
        "            ds.to(self.device)\n",
        "            eval_idx.to(self.device)\n",
        "            # Use unmasked feature for evaluation\n",
        "            processed_feat = ds.unmasked_pred\n",
        "            preds = self.predict(\n",
        "                ds, eval_idx, processed_feat, is_training=False\n",
        "            ).argmax(-1)\n",
        "            self.metrics[split][ds_name].update(preds, ds.label[eval_idx])\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"val\", batch, batch_idx)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"test\", batch, batch_idx)\n",
        "\n",
        "    def compute_and_log_metrics(self, split):\n",
        "        # Compute metrics from collected outputs\n",
        "        res = {}\n",
        "        for ds_name, metric in self.metrics[split].items():\n",
        "            metric_name = self.get_metric_name(ds_name, split)\n",
        "            accuracy = metric.compute().cpu().numpy()\n",
        "            res[metric_name] = np.round(accuracy * 100, 2)\n",
        "            metric.reset()  # Reset metrics for the next epoch\n",
        "\n",
        "        combined_res = {f\"{split}_acc\": np.round(sum(res.values()) / len(res), 2)}\n",
        "        combined_res[f\"trans_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"trans\")]\n",
        "        )\n",
        "        combined_res[f\"ind_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"ind\")]\n",
        "        )\n",
        "\n",
        "        combined_res[f\"heldout_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k in self.heldout_metrics]\n",
        "        )\n",
        "        self.log_dict(res, prog_bar=False, logger=True, add_dataloader_idx=False)\n",
        "        self.log_dict(\n",
        "            combined_res, prog_bar=True, logger=True, add_dataloader_idx=False\n",
        "        )\n",
        "        self.res_dict.update({**res, **combined_res})\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log_dict(self.loss_dict, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if len(self.attn_dict):\n",
        "            self.log_dict(self.attn_dict, on_epoch=True, prog_bar=False, logger=True)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"val\")\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"test\")\n",
        "\n",
        "\n",
        "@timer()\n",
        "@hydra.main(config_path=f\"{root}/configs\", config_name=\"main\", version_base=None)\n",
        "def main(cfg: DictConfig):\n",
        "    cfg, logger = init_experiment(cfg)\n",
        "    # Define the default step metric for all metrics\n",
        "    wandb.define_metric(\"*\", step_metric=\"epoch\")\n",
        "    if torch.cuda.is_available() and cfg.preprocess_device == \"gpu\":\n",
        "        preprocess_device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        preprocess_device = torch.device(\"cpu\")\n",
        "\n",
        "    def construct_ds_dict(datasets):\n",
        "        datasets = [datasets] if isinstance(datasets, str) else datasets\n",
        "        ds_dict = {\n",
        "            dataset: GraphDataset(\n",
        "                cfg,\n",
        "                dataset,\n",
        "                cfg.dirs.data_cache,\n",
        "                cfg.train_batch_size,\n",
        "                cfg.val_test_batch_size,\n",
        "                cfg.n_hops,\n",
        "                preprocess_device,\n",
        "            )\n",
        "            for dataset in datasets\n",
        "        }\n",
        "        return ds_dict\n",
        "\n",
        "    train_ds_dict = construct_ds_dict(cfg.train_datasets)\n",
        "    eval_ds_dict = construct_ds_dict(cfg.eval_datasets)\n",
        "\n",
        "    combined_dataset = CombinedDataset(train_ds_dict, eval_ds_dict, cfg)\n",
        "\n",
        "    model = InductiveNodeClassification(cfg, combined_dataset, cfg.get(\"prev_ckpt\"))\n",
        "    # Set up the checkpoint callback to save only at the end of training\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=cfg.dirs.output,  # specify where to save\n",
        "        filename=\"final_checkpoint.pt\",  # set a filename\n",
        "        save_top_k=0,  # do not save based on metric, just save last\n",
        "        save_last=True,  # ensures only the last checkpoint is kept\n",
        "        save_on_train_epoch_end=True,  # save at the end of training epoch\n",
        "    )\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=cfg.total_steps,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        limit_train_batches=cfg.limit_train_batches,\n",
        "        check_val_every_n_epoch=cfg.eval_freq,\n",
        "        logger=logger,\n",
        "        accelerator=\"gpu\" if torch.cuda.is_available() and cfg.gpus > 0 else \"cpu\",\n",
        "        default_root_dir=cfg.dirs.lightning_root,\n",
        "    )\n",
        "    dataloaders = {\n",
        "        \"train\": combined_dataset.train_dataloader(),\n",
        "        \"val\": combined_dataset.val_dataloader(),\n",
        "        \"test\": combined_dataset.test_dataloader(),\n",
        "    }\n",
        "    if cfg.total_steps > 0:\n",
        "        trainer.fit(\n",
        "            model,\n",
        "            train_dataloaders=dataloaders[\"train\"],\n",
        "            val_dataloaders=dataloaders[\"val\"],\n",
        "        )\n",
        "    trainer.validate(model, dataloaders=dataloaders[\"val\"])\n",
        "    trainer.test(model, dataloaders=dataloaders[\"test\"])\n",
        "    final_results = model.res_dict\n",
        "    logger.critical(pretty_repr(final_results))\n",
        "    logger.wandb_summary_update(final_results, finish_wandb=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AVs-Ye68aWpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_name = 'GraphAny/graphany/run.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ],
      "metadata": {
        "id": "mXAnRZB-becd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ],
      "metadata": {
        "id": "PsPPVWujbv5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulyl08LlbwbJ",
        "outputId": "2ab8f322-2bc6-44d6-a1c1-744af6e1e046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[09:20:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mFeb25-9\u001b[0m:\u001b[1;36m20\u001b[0m-13783a79/                                                         \u001b[2mexperiment.py:56\u001b[0m\n",
            "Done loading data from cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "Using existing file f1_9_classes3.pkl\n",
            "F1 12553 11362 300 9 9720\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:32\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.55it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m[09:20:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m91.33000183105469\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m91.33000183105469\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m91.33000183105469\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.26it/s]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    91.33000183105469    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    91.33000183105469    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    91.33000183105469    \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00,  2.67it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.37999725341797\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.37999725341797\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.37999725341797\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00,  2.55it/s]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.37999725341797    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.37999725341797    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.37999725341797    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:304\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m91.33\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m91.33\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m91.33\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.38\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.38\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.38\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m02\u001b[0m-\u001b[1;36m25\u001b[0m \u001b[1;92m09:20:24\u001b[0m, running time = \u001b[1;36m1.59\u001b[0m seconds.                                                                      \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "def build_comparison_file(download_path, output_file):\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    # Scrittura dei nodi e delle rispettive classi nel test set\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"Nodo,Classe\\n\")  # Header del file\n",
        "        for node in range(len(test_mask)):\n",
        "            if test_mask[node]:  # Controllo se il nodo  nel test set\n",
        "                f.write(f\"{node},{labels[node].item()}\\n\")  # Scrivo nodo e classe\n",
        "\n",
        "    return labels, node_features, train_mask, val_mask, test_mask"
      ],
      "metadata": {
        "id": "qr4Mo4bMatiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "output_file = \"true_labels.txt\"\n",
        "\n",
        "# URL del file da scaricare\n",
        "download_url = 'https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/f1_9_classes3.pkl'\n",
        "local_file_path = 'f1_9_classes3.pkl'\n",
        "\n",
        "\n",
        "response = requests.get(download_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(local_file_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(\"File scaricato e salvato come:\", local_file_path)\n",
        "else:\n",
        "    print(\"Errore nel download del file:\", response.status_code)\n",
        "\n",
        "labels, node_features, train_mask, val_mask, test_mask = build_comparison_file(local_file_path, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsIbiBPybzba",
        "outputId": "d3d8c9f7-4bf6-46a2-ea01-198c279c7e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File scaricato e salvato come: f1_9_classes3.pkl\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}