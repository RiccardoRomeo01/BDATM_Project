{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcNraNGefTp8"
      },
      "source": [
        "# Downloading GraphAny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC3-4ki8fWY3",
        "outputId": "5fee605d-cc3d-41ce-ede1-5bd196d07518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GraphAny'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 76 (delta 24), reused 40 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (76/76), 576.89 KiB | 16.97 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DeepGraphLearning/GraphAny.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHVlit_sfoks"
      },
      "source": [
        "# Imports and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MKSI8hbjDr2",
        "outputId": "cd0e5755-3088-4ddb-a11f-c7da9406d783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  76% 0.7606103307559025/1 [00:27<00:01,  7.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  83% 0.8258102598014666/1 [00:27<00:06, 38.43s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  72% 0.719763228625966/1 [00:27<00:01,  7.11s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.4151764711240601/1 [00:27<00:39, 68.05s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  83% 0.8297253546038191/1 [00:27<00:06, 35.29s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  74% 0.7375393009079679/1 [00:27<00:01,  6.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.416732971043169/1 [00:27<00:40, 69.54s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  75% 0.7525203932714161/1 [00:27<00:01,  6.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  83% 0.8325872660090475/1 [00:27<00:06, 40.71s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.418232664395887/1 [00:27<00:40, 68.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  77% 0.7670542888478957/1 [00:27<00:01,  7.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.41976644168843963/1 [00:27<00:40, 69.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  83% 0.8323955654559052/1 [00:28<00:01,  6.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  84% 0.8378989735771514/1 [00:28<00:06, 39.78s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.42124341241460134/1 [00:28<00:46, 80.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  80% 0.7964574775910813/1 [00:28<00:01,  7.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  85% 0.8475716385636239/1 [00:28<00:01,  8.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.4230044159727172/1 [00:28<00:48, 84.59s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  84% 0.8404861414874779/1 [00:28<00:08, 56.21s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  86% 0.8605797012273829/1 [00:28<00:01,  9.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.42510625892917814/1 [00:28<00:43, 76.34s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  84% 0.8443325504161049/1 [00:28<00:07, 47.20s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  88% 0.8756353293104372/1 [00:28<00:01,  8.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  84% 0.8406181603042309/1 [00:28<00:01,  7.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  85% 0.8474234147337516/1 [00:28<00:06, 43.14s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.4264696165225582/1 [00:28<00:49, 85.46s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  86% 0.8573880398155534/1 [00:28<00:01,  7.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  85% 0.8504226978864309/1 [00:28<00:06, 41.73s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.4277307222964347/1 [00:28<00:49, 86.87s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  85% 0.8533075045829012/1 [00:28<00:05, 40.90s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  88% 0.8763939032617191/1 [00:28<00:00,  7.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.4289122988773641/1 [00:28<00:51, 90.52s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  86% 0.8570852276378026/1 [00:28<00:05, 37.24s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  90% 0.8958469634948533/1 [00:28<00:00,  6.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.43066194112220185/1 [00:28<00:45, 80.57s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  86% 0.8607026836540114/1 [00:29<00:05, 35.96s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.4319344082093566/1 [00:29<00:51, 90.73s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  98% 0.9775318201765486/1 [00:29<00:00,  7.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  86% 0.8635645950592398/1 [00:29<00:05, 41.57s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.4338885540932013/1 [00:29<00:44, 78.74s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  93% 0.9258091482217496/1 [00:29<00:00,  8.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4357858934106552/1 [00:29<00:39, 69.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  94% 0.9383306582568706/1 [00:29<00:00,  8.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.43785365242728164/1 [00:29<00:35, 63.61s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  95% 0.9537589474072873/1 [00:29<00:00,  7.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.439512404165894/1 [00:29<00:35, 63.97s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  97% 0.969858031738157/1 [00:29<00:00,  7.55s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.44111434933811555/1 [00:29<00:35, 63.59s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  99% 0.9890874935778069/1 [00:29<00:00,  7.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4432161922945765/1 [00:29<00:34, 62.28s/it] \n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.44507944767219587/1 [00:29<00:34, 62.11s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.44686317385686813/1 [00:29<00:34, 61.48s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.44868098398137485/1 [00:30<00:32, 59.58s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.4508169108776703/1 [00:30<00:33, 60.92s/it] \n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.4524756626162827/1 [00:30<00:34, 62.14s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.4546115895125781/1 [00:30<00:32, 60.23s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.45628170256446865/1 [00:30<00:34, 63.30s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.45787228642341204/1 [00:30<00:36, 66.83s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  91% 0.9114844396283842/1 [00:30<00:02, 30.83s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | : 100% 1.0/1 [00:31<00:00,  6.44s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   0% 0.0001518791001574902/1 [00:31<57:44:39, 207911.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | : 100% 1.0/1 [00:31<00:00,  7.07s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   0% 0.00015896474520165442/1 [00:31<55:14:58, 198930.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   0% 0.003796977503937255/1 [00:31<1:39:05, 5968.42s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   0% 0.00397411863004136/1 [00:31<1:34:37, 5700.39s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   1% 0.0053157685055121575/1 [00:31<1:03:06, 3806.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   1% 0.005881695572461213/1 [00:31<56:07, 3387.68s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   1% 0.0068345595070870594/1 [00:32<41:45, 2523.05s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   1% 0.007630307769679412/1 [00:32<36:51, 2228.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   1% 0.008505229608819451/1 [00:32<27:25, 1659.39s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   1% 0.009537884712099265/1 [00:32<24:09, 1463.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   1% 0.010327778810709334/1 [00:32<18:02, 1093.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   1% 0.011445461654519117/1 [00:32<16:20, 992.35s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   1% 0.011998448912441726/1 [00:32<12:39, 768.65s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.45938334108940826/1 [00:32<03:19, 369.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   1% 0.01382099811433161/1 [00:32<08:47, 534.56s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  91% 0.9147584662759655/1 [00:32<00:15, 176.76s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   2% 0.015419580284560478/1 [00:32<07:52, 479.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   2% 0.015491668216064002/1 [00:32<06:27, 393.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   2% 0.01732715722698033/1 [00:32<05:43, 350.04s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   2% 0.017314217417953883/1 [00:32<04:40, 285.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   2% 0.019234734169400185/1 [00:32<04:14, 259.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   2% 0.019136766619843766/1 [00:32<03:29, 213.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   2% 0.02130127585702169/1 [00:32<03:08, 192.87s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   2% 0.02095931582173365/1 [00:32<02:41, 164.51s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   2% 0.023208852799441543/1 [00:32<02:28, 151.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4604626658508341/1 [00:33<03:36, 402.05s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  92% 0.9171166812738737/1 [00:33<00:15, 186.72s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   3% 0.03306466700194412/1 [00:33<00:53, 55.19s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   4% 0.04358930174519969/1 [00:33<00:25, 26.17s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4616442424317635/1 [00:33<02:53, 323.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   6% 0.06120142690263695/1 [00:33<00:16, 17.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   7% 0.06971250697228801/1 [00:33<00:12, 12.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4630303226516999/1 [00:33<02:14, 249.61s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   8% 0.08234373801445698/1 [00:33<00:10, 11.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   9% 0.08945678999276173/1 [00:33<00:09,  9.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  93% 0.9283124786911272/1 [00:33<00:05, 77.11s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.46431415105213275/1 [00:33<01:50, 206.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  11% 0.11345368781764519/1 [00:33<00:06,  7.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  93% 0.9319528299985778/1 [00:33<00:04, 62.49s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.46593881885091065/1 [00:33<01:24, 158.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  14% 0.13684306924189868/1 [00:33<00:05,  6.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4677339063488611/1 [00:33<01:06, 125.41s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  16% 0.15530855606201635/1 [00:33<00:05,  6.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  16% 0.15780238506363234/1 [00:33<00:05,  6.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.46905181868912843/1 [00:33<01:00, 113.75s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  94% 0.9387298362061586/1 [00:33<00:03, 50.90s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4706196799215155/1 [00:33<00:52, 98.25s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  21% 0.2080848514689656/1 [00:33<00:03,  4.96s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4724147674194659/1 [00:33<00:44, 84.05s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  22% 0.21673147592473854/1 [00:33<00:03,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  23% 0.2311347395232055/1 [00:33<00:03,  4.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4741757709775818/1 [00:34<00:40, 76.70s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  24% 0.2448291094538742/1 [00:34<00:03,  4.60s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  26% 0.2587946051882934/1 [00:34<00:03,  4.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.47572090958341257/1 [00:34<00:38, 73.76s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  27% 0.270800435580805/1 [00:34<00:03,  4.40s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  29% 0.289315836267011/1 [00:34<00:02,  4.12s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.4774137452618594/1 [00:34<00:36, 69.88s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  31% 0.31475019549927574/1 [00:34<00:02,  4.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  96% 0.9592440171588358/1 [00:34<00:01, 27.82s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.47908385831375/1 [00:34<00:37, 71.42s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  34% 0.33907180151512883/1 [00:34<00:02,  4.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  96% 0.9632049025436719/1 [00:34<00:01, 29.70s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.48058355166646805/1 [00:34<00:37, 72.63s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  36% 0.36307547804057866/1 [00:34<00:03,  4.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  97% 0.9668452538511224/1 [00:34<00:01, 31.19s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.4825263362370346/1 [00:34<00:33, 65.65s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  39% 0.38628433084002023/1 [00:34<00:02,  4.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  97% 0.9715616838469389/1 [00:34<00:00, 27.83s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.4846849857598864/1 [00:34<00:30, 59.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  42% 0.42411794019801397/1 [00:34<00:02,  3.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  98% 0.9770565537449774/1 [00:34<00:00, 24.60s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.4869231644756853/1 [00:34<00:27, 54.39s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  46% 0.4614746553204027/1 [00:34<00:01,  3.66s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  44% 0.4375636875537293/1 [00:34<00:02,  3.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.48920678844459686/1 [00:34<00:25, 50.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  49% 0.48929348573069226/1 [00:34<00:01,  3.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.4912291022081106/1 [00:34<00:26, 52.32s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  47% 0.46626883748349496/1 [00:34<00:02,  4.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.4931718867786772/1 [00:35<00:26, 52.47s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.9896489639279823/1 [00:35<00:00, 27.88s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  49% 0.4917845263099533/1 [00:35<00:02,  4.32s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.4953532589280853/1 [00:35<00:25, 50.88s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.9944111845062824/1 [00:35<00:00, 25.94s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  52% 0.5247422910441287/1 [00:35<00:01,  3.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.49746646319782434/1 [00:35<00:25, 50.95s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | : 100% 0.9986010228035368/1 [00:35<00:00, 25.55s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  61% 0.6102656568291512/1 [00:35<00:01,  3.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.5004090433368696/1 [00:35<00:22, 45.38s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  64% 0.6431713590858937/1 [00:35<00:01,  3.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.5035334044883656/1 [00:35<00:20, 40.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  68% 0.6845021928383239/1 [00:35<00:00,  3.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5059988094697279/1 [00:35<00:20, 41.42s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  72% 0.7178847893306713/1 [00:35<00:00,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5087255246564879/1 [00:35<00:19, 39.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  76% 0.7641435301843528/1 [00:35<00:00,  2.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5121680025797726/1 [00:35<00:18, 37.30s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  81% 0.8051564344463795/1 [00:35<00:00,  2.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.51484927251342/1 [00:35<00:19, 39.44s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  85% 0.8450565854919948/1 [00:35<00:00,  2.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5179963562914723/1 [00:36<00:17, 37.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  88% 0.8841619128116018/1 [00:36<00:00,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5207230714782324/1 [00:36<00:21, 44.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  92% 0.9218365574243939/1 [00:36<00:00,  3.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5231657538330383/1 [00:36<00:20, 43.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  96% 0.9576036250947662/1 [00:36<00:00,  3.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5255743522480097/1 [00:36<00:21, 44.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  99% 0.9905093273515087/1 [00:36<00:00,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5279147827833122/1 [00:36<00:21, 45.44s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5301756841256674/1 [00:36<00:21, 46.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5862551264667002/1 [00:38<00:15, 37.54s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5890727321596856/1 [00:38<00:15, 37.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :   0% 0.00030184652548561843/1 [00:38<35:30:01, 127840.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5918676152261148/1 [00:38<00:15, 38.50s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.5984798995540079/1 [00:38<00:13, 33.71s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  19% 0.1931817763107958/1 [00:38<01:16, 94.56s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | : 100% 1.0/1 [00:39<00:00,  3.21s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6015247315125568/1 [00:39<00:13, 34.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6046263700374964/1 [00:39<00:13, 33.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  36% 0.3598010583788572/1 [00:39<00:20, 32.59s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6076143954296543/1 [00:39<00:13, 34.46s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  44% 0.44371439246385913/1 [00:39<00:11, 21.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  17% 0.1696274487452306/1 [00:39<01:51, 134.05s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6105456142554214/1 [00:39<00:14, 37.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  25% 0.2517962544783673/1 [00:39<00:55, 74.53s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6132950520687379/1 [00:39<00:14, 37.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  33% 0.32796991129535236/1 [00:39<00:31, 47.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.616089935135167/1 [00:39<00:14, 36.79s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  44% 0.4411724290650385/1 [00:39<00:14, 26.80s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6188393729484835/1 [00:39<00:14, 39.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  53% 0.5261624813469523/1 [00:39<00:08, 18.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6217024238945815/1 [00:39<00:14, 38.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6243268872618382/1 [00:39<00:14, 38.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  93% 0.9254614471389061/1 [00:39<00:00,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6269172666892602/1 [00:40<00:16, 42.93s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  99% 0.9939806084241415/1 [00:40<00:00,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6293031424776753/1 [00:40<00:17, 47.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6323934196893367/1 [00:40<00:15, 42.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.663148494733335/1 [00:41<00:11, 34.24s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | : 100% 1.0/1 [00:41<00:00,  3.10s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :   0% 0.0006420630790921862/1 [00:41<17:53:16, 64437.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | : 100% 1.0/1 [00:41<00:00,  3.94s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :   0% 0.0007921420514148734/1 [00:41<14:31:09, 52310.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6660797135591022/1 [00:41<00:13, 41.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :  12% 0.11723702360940125/1 [00:41<03:39, 248.96s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :  21% 0.21308621183060092/1 [00:41<01:30, 115.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  33% 0.32616804417883055/1 [00:41<00:50, 74.61s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6686473703599679/1 [00:41<00:20, 60.98s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  45% 0.4526544707599912/1 [00:41<00:24, 45.44s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6710446074616612/1 [00:41<00:18, 56.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  57% 0.5695099511547691/1 [00:41<00:12, 30.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6731918956712348/1 [00:42<00:18, 56.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  68% 0.6780186115213486/1 [00:42<00:06, 21.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6752255707480267/1 [00:42<00:19, 60.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  78% 0.7801066410970061/1 [00:42<00:03, 15.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6770547421858116/1 [00:42<00:19, 60.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6792701982750542/1 [00:42<00:17, 55.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6935968143188229/1 [00:43<00:13, 44.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | : 100% 1.0/1 [00:43<00:00,  9.27s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.6958917996010127/1 [00:43<00:13, 45.25s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.6981413396300897/1 [00:43<00:13, 46.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.8         | 17.0 MB   | :  39% 0.38793618302031185/1 [00:43<00:39, 64.49s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | : 100% 1.0/1 [00:43<00:00,  7.82s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :   0% 0.0009221176422649559/1 [00:43<13:03:24, 47047.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.7003227117794978/1 [00:43<00:17, 57.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :  23% 0.2323736458507689/1 [00:43<01:40, 131.28s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.7027994780741382/1 [00:43<00:15, 53.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :  46% 0.46382517405927287/1 [00:43<00:29, 54.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7051853538625533/1 [00:43<00:15, 51.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7080029595555387/1 [00:43<00:13, 47.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7175691853357554/1 [00:44<00:12, 44.25s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7198641706179452/1 [00:44<00:12, 44.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :   0% 0.000997983748775134/1 [00:44<12:19:33, 44417.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7221250719603005/1 [00:44<00:15, 57.14s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  29% 0.28741931964723855/1 [00:44<01:02, 88.38s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7240905791574234/1 [00:44<00:15, 56.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :   0% 0.001016089426288399/1 [00:44<12:11:23, 43928.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7266355133317328/1 [00:44<00:13, 50.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  22% 0.2225235843571594/1 [00:44<01:49, 141.06s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7294190350848837/1 [00:44<00:12, 45.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  44% 0.443014989861742/1 [00:44<00:32, 58.63s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7322025568380347/1 [00:44<00:11, 43.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  91% 0.9141531138780227/1 [00:45<00:01, 12.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  74% 0.7391329579377166/1 [00:45<00:12, 46.93s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  74% 0.74208689939004/1 [00:45<00:10, 42.40s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | : 100% 1.0/1 [00:45<00:00, 16.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :   0% 0.0015713236502815128/1 [00:45<8:00:36, 28882.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [00:45<00:00, 12.23s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  74% 0.7444954978050115/1 [00:45<00:10, 42.47s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :  43% 0.43054268017713454/1 [00:45<00:42, 74.10s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7468813735934265/1 [00:45<00:10, 42.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :  87% 0.8705133022559581/1 [00:45<00:03, 30.24s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7560385920956293/1 [00:45<00:09, 37.06s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  91% 0.9121316752243669/1 [00:50<00:01, 18.34s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 0.9973528861238983/1 [00:53<00:00, 23.16s/it]\n",
            "\n",
            "dgl-2.1.0.cu118      | 577.9 MB  | : 100% 1/1 [01:03<00:00, 63.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [01:10<00:00, 23.16s/it]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | : 100% 1.0/1 [01:24<00:00,  3.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.2.0    | 177.1 MB  | : 100% 1.0/1 [01:29<00:00,  4.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | : 100% 1.0/1 [01:36<00:00,  6.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | : 100% 1.0/1 [02:04<00:00,  7.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcublas-12.1.0.26  | 329.0 MB  | : 100% 1.0/1 [02:33<00:00, 16.30s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [02:34<00:00,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | : 100% 1.0/1 [02:44<00:00,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | : 100% 1.0/1 [02:45<00:00,  3.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | : 100% 1.0/1 [02:49<00:00,  9.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | : 100% 1.0/1 [02:51<00:00,  7.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.8         | 17.0 MB   | : 100% 1.0/1 [02:52<00:00, 13.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | : 100% 1.0/1 [02:53<00:00,  3.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | : 100% 1.0/1 [02:57<00:00, 21.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | : 100% 1.0/1 [02:58<00:00, 16.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [02:58<00:00, 12.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [03:01<00:00, 30.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | : 100% 1.0/1 [03:43<00:00, 25.55s/it]\u001b[A\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [08:06<00:00, 23.16s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Installing pip dependencies: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ Ran pip subprocess with arguments:\n",
            "['/usr/local/miniconda/envs/graphany/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/GraphAny/condaenv.iv1voggq.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting ogb (from -r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1))\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting rootutils (from -r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 2))\n",
            "  Downloading rootutils-1.0.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting hydra_colorlog (from -r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 3))\n",
            "  Downloading hydra_colorlog-1.2.0-py3-none-any.whl.metadata (949 bytes)\n",
            "Collecting codetiming (from -r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 4))\n",
            "  Downloading codetiming-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting humanfriendly (from -r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting torch_frame (from -r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading torch_frame-1.7.5-py3-none-any.whl.metadata (763 bytes)\n",
            "Collecting pytorch-frame[full] (from -r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading pytorch_frame-0.2.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (1.6.1)\n",
            "Collecting pandas>=0.24.0 (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1))\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2.3.0)\n",
            "Collecting outdated>=0.2.0 (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1))\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting python-dotenv>=0.20.0 (from rootutils->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 2))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting colorlog (from hydra_colorlog->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 3))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra_colorlog->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 3)) (1.3.2)\n",
            "Collecting termcolor (from torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opencv-python (from torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tabulate (from torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting transformers>=4.25.1 (from torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting accelerate>=0.16.0 (from torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diffusers (from torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6)) (6.0.2)\n",
            "Collecting pyarrow (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (9.4.0)\n",
            "Collecting xgboost<2.0.0,>=1.7.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting optuna>=3.0.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting optuna-integration (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading optuna_integration-4.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (1.3.0)\n",
            "Collecting catboost (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting lightgbm (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting datasets (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (1.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6)) (7.0.0)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 3)) (4.9.3)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (75.8.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1))\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2025.1)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1))\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2025.2.0)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting graphviz (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting matplotlib (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy>=1.16.0 (from ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting plotly (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from diffusers->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6)) (8.6.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torchmetrics->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (0.13.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (2.4.8)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (1.18.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (2025.1.31)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from importlib-metadata->diffusers->torch_frame->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 6)) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 1)) (3.0.2)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7)) (3.2.1)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.iv1voggq.requirements.txt (line 7))\n",
            "  Downloading narwhals-1.29.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "Downloading rootutils-1.0.7-py3-none-any.whl (6.4 kB)\n",
            "Downloading hydra_colorlog-1.2.0-py3-none-any.whl (3.6 kB)\n",
            "Downloading codetiming-1.4.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading torch_frame-1.7.5-py3-none-any.whl (46 kB)\n",
            "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "    13.1/13.1 MB 145.2 MB/s eta 0:00:00\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "    10.0/10.0 MB 145.4 MB/s eta 0:00:00\n",
            "Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "    200.3/200.3 MB 70.2 MB/s eta 0:00:00\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "    98.7/98.7 MB 62.9 MB/s eta 0:00:00\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "    18.2/18.2 MB 128.3 MB/s eta 0:00:00\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "    42.1/42.1 MB 43.9 MB/s eta 0:00:00\n",
            "Downloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "    3.2/3.2 MB 82.8 MB/s eta 0:00:00\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "    3.6/3.6 MB 98.1 MB/s eta 0:00:00\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "    63.0/63.0 MB 49.8 MB/s eta 0:00:00\n",
            "Downloading optuna_integration-4.2.1-py3-none-any.whl (97 kB)\n",
            "Downloading pytorch_frame-0.2.5-py3-none-any.whl (144 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "    781.7/781.7 kB 29.2 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "    3.1/3.1 MB 85.0 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "    3.0/3.0 MB 80.5 MB/s eta 0:00:00\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "    8.6/8.6 MB 145.0 MB/s eta 0:00:00\n",
            "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
            "    14.8/14.8 MB 151.1 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "    4.6/4.6 MB 113.8 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
            "    599.5/599.5 kB 26.1 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "    1.6/1.6 MB 75.5 MB/s eta 0:00:00\n",
            "Downloading narwhals-1.29.0-py3-none-any.whl (305 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: xxhash, tzdata, termcolor, tabulate, safetensors, regex, python-dotenv, pyarrow, numpy, narwhals, Mako, littleutils, kiwisolver, humanfriendly, greenlet, graphviz, fsspec, fonttools, dill, cycler, colorlog, codetiming, sqlalchemy, rootutils, plotly, pandas, outdated, opencv-python, multiprocess, huggingface-hub, contourpy, xgboost, tokenizers, pytorch-frame, matplotlib, lightgbm, hydra_colorlog, diffusers, alembic, accelerate, transformers, optuna, ogb, catboost, torch_frame, optuna-integration, datasets\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.3\n",
            "    Uninstalling numpy-2.2.3:\n",
            "      Successfully uninstalled numpy-2.2.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.2.0\n",
            "    Uninstalling fsspec-2025.2.0:\n",
            "      Successfully uninstalled fsspec-2025.2.0\n",
            "Successfully installed Mako-1.3.9 accelerate-1.4.0 alembic-1.15.1 catboost-1.2.7 codetiming-1.4.0 colorlog-6.9.0 contourpy-1.3.1 cycler-0.12.1 datasets-3.3.2 diffusers-0.32.2 dill-0.3.8 fonttools-4.56.0 fsspec-2024.12.0 graphviz-0.20.3 greenlet-3.1.1 huggingface-hub-0.29.2 humanfriendly-10.0 hydra_colorlog-1.2.0 kiwisolver-1.4.8 lightgbm-4.6.0 littleutils-0.2.4 matplotlib-3.10.1 multiprocess-0.70.16 narwhals-1.29.0 numpy-1.26.4 ogb-1.3.6 opencv-python-4.11.0.86 optuna-4.2.1 optuna-integration-4.2.1 outdated-0.2.2 pandas-2.2.3 plotly-6.0.0 pyarrow-19.0.1 python-dotenv-1.0.1 pytorch-frame-0.2.5 regex-2024.11.6 rootutils-1.0.7 safetensors-0.5.3 sqlalchemy-2.0.38 tabulate-0.9.0 termcolor-2.5.0 tokenizers-0.21.0 torch_frame-1.7.5 transformers-4.49.0 tzdata-2025.1 xgboost-1.7.6 xxhash-3.5.0\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate graphany\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'name': 'graphany',\n",
        "    'channels': [\n",
        "        'pytorch',\n",
        "        'pyg',\n",
        "        'nvidia',\n",
        "        'conda-forge',\n",
        "        'defaults',\n",
        "        'dglteam/label/cu118'\n",
        "    ],\n",
        "    'dependencies': [\n",
        "        'python=3.10',\n",
        "        'cudatoolkit=11.8',\n",
        "        'pyg',\n",
        "        'pytorch=2.2.1',\n",
        "        'torchvision',\n",
        "        'torchaudio',\n",
        "        'torchdata=0.7.1',\n",
        "        'dgl',\n",
        "        'lightning=2.*',\n",
        "        'pydantic',\n",
        "        'wandb',\n",
        "        'rich',\n",
        "        'hydra-core',\n",
        "        'jupyter',\n",
        "        'einops',\n",
        "        'tensorboard',\n",
        "        'pip',\n",
        "        {\n",
        "            'pip': [\n",
        "                'ogb',\n",
        "                'rootutils',\n",
        "                'hydra_colorlog',\n",
        "                # For time logging\n",
        "                'codetiming',\n",
        "                'humanfriendly',\n",
        "                'torch_frame',\n",
        "                'pytorch-frame[full]'\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "sys.path.insert(0,'/content/GraphAny')\n",
        "\n",
        "\n",
        "with open('GraphAny/environment.yaml', 'w') as file:\n",
        "    yaml.dump(data, file)\n",
        "\n",
        "\n",
        "\n",
        "!wget -O Miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda.sh -b -p /usr/local/miniconda\n",
        "\n",
        "os.environ['PATH'] = '/usr/local/miniconda/bin:' + os.environ['PATH']\n",
        "\n",
        "!conda update conda -y -q\n",
        "!source /usr/local/etc/profile.d/conda.sh\n",
        "!conda init\n",
        "!conda install -n root _license -y -q\n",
        "\n",
        "!conda env create -f GraphAny/environment.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwHPwzzJfr1y",
        "outputId": "a9d40e89-0e54-4e63-908f-582b4ae5562c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '/env/python', '/usr/local/miniconda/envs/graphany/lib/python310.zip', '/usr/local/miniconda/envs/graphany/lib/python3.10', '/usr/local/miniconda/envs/graphany/lib/python3.10/lib-dynload', '/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages', '/usr/local/lib/python3.10/site-packages']\n",
            "Python version\n",
            "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate graphany\n",
        "\n",
        "python\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "# some simple python commands\n",
        "sys.path.append('/usr/local/lib/python3.10/site-packages')\n",
        "print(sys.path)\n",
        "\n",
        "print(\"Python version\")\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda config --add channels pytorch\n",
        "!source activate graphany && conda config --add channels pyg\n",
        "!source activate graphany && conda config --add channels nvidia\n",
        "!source activate graphany && conda config --add channels conda-forge\n",
        "!source activate graphany && conda config --add channels dglteam/label/cu118"
      ],
      "metadata": {
        "id": "ENRRADzupiU6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda list torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBhCyXx32AXi",
        "outputId": "92024225-0f4f-479a-e355-5951927aa206"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# packages in environment at /usr/local/miniconda/envs/graphany:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "pytorch                   2.2.1           py3.10_cuda12.1_cudnn8.9.2_0    pytorch\n",
            "pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n",
            "pytorch-frame             0.2.5                    pypi_0    pypi\n",
            "pytorch-lightning         2.5.0.post0        pyh101cb37_0    conda-forge\n",
            "pytorch-mutex             1.0                        cuda    pytorch\n",
            "torch-frame               1.7.5                    pypi_0    pypi\n",
            "torchaudio                2.2.1               py310_cu121    pytorch\n",
            "torchdata                 0.7.1                     py310    pytorch\n",
            "torchmetrics              1.6.2              pyhd8ed1ab_0    conda-forge\n",
            "torchtriton               2.2.0                     py310    pytorch\n",
            "torchvision               0.17.1              py310_cu121    pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wg0WnaJhM3f"
      },
      "source": [
        "# F1 and H&M Datasets Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKbBdLDuhaLT"
      },
      "source": [
        "## Update `configs/data.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VIuYTpWCjgcK"
      },
      "outputs": [],
      "source": [
        "# leggiamo tutto il file yaml\n",
        "file_path = 'GraphAny/configs/data.yaml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# aggiungo i metadati del dataset F1 al file yaml\n",
        "data['_ds_meta_data']['F1'] = 'relbench, f1_3_classes_remastered'\n",
        "# aggiungo i metadati del dataset H&M al file yaml\n",
        "data['_ds_meta_data']['HM'] = 'relbench, hm_3_classes'\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "453-Ir-Okjtc"
      },
      "outputs": [],
      "source": [
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "# Aggiungo il nuovo elemento _dataset_lookup\n",
        "data['_dataset_lookup']['F1Debug'] = {\n",
        "    'train': ['Wisconsin'],\n",
        "    'eval': ['F1']\n",
        "}\n",
        "data['_dataset_lookup']['HMDebug'] = {\n",
        "    'train': ['Wisconsin'],\n",
        "    'eval': ['HM']\n",
        "}\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCjvqIMLmVON"
      },
      "source": [
        "## Implement the dataset interface and update `GraphDataset` class in `data.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l5Y0yWWBowc-"
      },
      "outputs": [],
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import os.path\n",
        "import os.path as osp\n",
        "import re\n",
        "import ssl\n",
        "import sys\n",
        "import urllib\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "#from torch_frame import TensorFrame\n",
        "import requests\n",
        "\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import OmegaConf\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.manifold._utils import (\n",
        "    _binary_search_perplexity as sklearn_binary_search_perplexity,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from graphany.utils import logger, timer\n",
        "\n",
        "\n",
        "def get_entropy_normed_cond_gaussian_prob(X, entropy, metric=\"euclidean\"):\n",
        "\n",
        "    #Parameters\n",
        "    #----------\n",
        "    #X:              The matrix for pairwise similarity\n",
        "    #entropy:     Perplexity of the conditional prob distribution\n",
        "    #Returns the entropy-normalized conditional gaussian probability based on distances.\n",
        "    #-------\n",
        "\n",
        "\n",
        "    # Compute pairwise distances\n",
        "    perplexity = np.exp2(entropy)\n",
        "    distances = pdist(X, metric=metric)\n",
        "    distances = squareform(distances)\n",
        "\n",
        "    # Compute the squared distances\n",
        "    distances **= 2\n",
        "    distances = distances.astype(np.float32)\n",
        "    return sklearn_binary_search_perplexity(distances, perplexity, verbose=0)\n",
        "\n",
        "\n",
        "def sample_k_nodes_per_label(label, visible_nodes, k, num_class):\n",
        "    ref_node_idx = [\n",
        "        (label[visible_nodes] == lbl).nonzero().view(-1) for lbl in range(num_class)\n",
        "    ]\n",
        "    sampled_indices = [\n",
        "        label_indices[torch.randperm(len(label_indices))[:k]]\n",
        "        for label_indices in ref_node_idx\n",
        "    ]\n",
        "    return visible_nodes[torch.cat(sampled_indices)]\n",
        "\n",
        "\n",
        "def get_data_split_masks(n_nodes, labels, num_train_nodes, label_idx=None, seed=42):\n",
        "    label_idx = np.arange(n_nodes)\n",
        "    test_rate_in_labeled_nodes = (len(labels) - num_train_nodes) / len(labels)\n",
        "    train_idx, test_and_valid_idx = train_test_split(\n",
        "        label_idx,\n",
        "        test_size=test_rate_in_labeled_nodes,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels,\n",
        "    )\n",
        "    valid_idx, test_idx = train_test_split(\n",
        "        test_and_valid_idx,\n",
        "        test_size=0.5,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels[test_and_valid_idx],\n",
        "    )\n",
        "    train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[train_idx] = True\n",
        "    val_mask[valid_idx] = True\n",
        "    test_mask[test_idx] = True\n",
        "\n",
        "    return train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def download_url(url: str, folder: str, log: bool = True, filename=None):\n",
        "    #Modified from torch_geometric.data.download_url\n",
        "\n",
        "    #Downloads the content of an URL to a specific folder.\n",
        "\n",
        "    #Args:\n",
        "        #url (str): The URL.\n",
        "        #folder (str): The folder.\n",
        "        #log (bool, optional): If :obj:`False`, will not print anything to the\n",
        "            #console. (default: :obj:`True`)\n",
        "\n",
        "\n",
        "    if filename is None:\n",
        "        filename = url.rpartition(\"/\")[2]\n",
        "        filename = filename if filename[0] == \"?\" else filename.split(\"?\")[0]\n",
        "\n",
        "    path = osp.join(folder, filename)\n",
        "\n",
        "    if osp.exists(path):  # pragma: no cover\n",
        "        if log and \"pytest\" not in sys.modules:\n",
        "            print(f\"Using existing file {filename}\", file=sys.stderr)\n",
        "        return path\n",
        "\n",
        "    if log and \"pytest\" not in sys.modules:\n",
        "        print(f\"Downloading {url}\", file=sys.stderr)\n",
        "\n",
        "    os.makedirs(osp.expanduser(osp.normpath(folder)), exist_ok=True)\n",
        "\n",
        "    context = ssl._create_unverified_context()\n",
        "    data = urllib.request.urlopen(url, context=context)\n",
        "\n",
        "    with open(path, \"wb\") as f:\n",
        "        # workaround for https://bugs.python.org/issue42853\n",
        "        while True:\n",
        "            chunk = data.read(10 * 1024 * 1024)\n",
        "            if not chunk:\n",
        "                break\n",
        "            f.write(chunk)\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "def download_file_from_google_drive(url, destination, filename=\"data.pkl\"):\n",
        "    path = osp.join(destination, filename)\n",
        "    os.makedirs(osp.expanduser(osp.normpath(destination)), exist_ok=True)\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(url, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {'confirm' : token }\n",
        "        response = session.get(url, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, path)\n",
        "    return path\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 10 * 1024 * 1024\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "'''\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url, raw_dir)\n",
        "    download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "'''\n",
        "\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url[0], raw_dir)\n",
        "    # download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(raw_dir, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def load_heterophilous_dataset(url, raw_dir):\n",
        "    # Wrap Heterophilous to DGL Graph Dataset format https://arxiv.org/pdf/2302.11640.pdf\n",
        "    download_path = download_url(url, raw_dir)\n",
        "    data = np.load(download_path)\n",
        "    node_features = torch.tensor(data[\"node_features\"])\n",
        "    labels = torch.tensor(data[\"node_labels\"])\n",
        "    edges = torch.tensor(data[\"edges\"])\n",
        "\n",
        "    #\n",
        "    '''\n",
        "    print(f\"node_features  un: {type(data['node_features'])} con size: {data['node_features'].shape}\")\n",
        "    print(data['node_features'][0])\n",
        "    print(f\"node_labels  un: {type(data['node_labels'])} con size: {data['node_labels'].shape}\")\n",
        "    print(data['node_labels'][0])\n",
        "    print(f\"edges  un: {type(data['edges'])} con size: {data['edges'].shape}\")\n",
        "    print(data['edges'][0])\n",
        "    '''\n",
        "    #\n",
        "\n",
        "    graph = dgl.graph(\n",
        "        (edges[:, 0], edges[:, 1]), num_nodes=len(node_features), idtype=torch.int\n",
        "    )\n",
        "    num_classes = len(labels.unique())\n",
        "    num_targets = 1 if num_classes == 2 else num_classes\n",
        "    if num_targets == 1:\n",
        "        labels = labels.float()\n",
        "    train_masks = torch.tensor(data[\"train_masks\"]).T\n",
        "    val_masks = torch.tensor(data[\"val_masks\"]).T\n",
        "    test_masks = torch.tensor(data[\"test_masks\"]).T\n",
        "\n",
        "    '''\n",
        "    print(f\"la size della train mask : {data['train_masks'].shape}\")\n",
        "    print(data['train_masks'][0])\n",
        "    print(data['train_masks'][1])\n",
        "    print(data['train_masks'][2])\n",
        "    '''\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_masks, val_masks, test_masks\n",
        "\n",
        "\n",
        "class CombinedDataset(pl.LightningDataModule):\n",
        "    def __init__(self, train_ds_dict, eval_ds_dict, cfg):\n",
        "        super().__init__()\n",
        "        self.train_ds_dict = train_ds_dict\n",
        "        self.eval_ds_dict = eval_ds_dict\n",
        "        self.all_ds = list(self.train_ds_dict.values()) + list(\n",
        "            self.eval_ds_dict.values()\n",
        "        )\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def to(self, device):\n",
        "        for ds in self.all_ds:\n",
        "            ds.to(device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.train_dataloader() for name, ds in self.train_ds_dict.items()\n",
        "        }\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"min_size\")\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.val_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.test_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "\n",
        "class GraphDataset(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            cfg,\n",
        "            ds_name,\n",
        "            cache_dir,\n",
        "            train_batch_size=256,\n",
        "            val_test_batch_size=256,\n",
        "            n_hops=1,\n",
        "            preprocess_device=torch.device(\"cpu\"),\n",
        "            permute_label=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.name = ds_name\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.permute_label = permute_label  # For checking label equivariance\n",
        "        self.val_test_batch_size = val_test_batch_size\n",
        "        self.preprocess_device = preprocess_device\n",
        "\n",
        "        self.n_hops = n_hops\n",
        "\n",
        "        self.data_source, ds_alias = cfg[\"_ds_meta_data\"][ds_name].split(\", \")\n",
        "        self.gidtype = None\n",
        "        self.dist = None\n",
        "        self.unmasked_pred = None\n",
        "        if self.data_source == \"pyg\":\n",
        "            components = ds_alias.split(\".\")\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"torch_geometric.datasets.{ds_alias}\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}/\",\n",
        "            }\n",
        "            if len(components) == 2:  # If sub-dataset\n",
        "                ds_init_args[\"_target_\"] = f\"torch_geometric.datasets.{components[0]}\"\n",
        "                ds_init_args[\"name\"] = components[1]\n",
        "        elif self.data_source == \"dgl\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"dgl.data.{ds_alias}\",\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "            }\n",
        "        elif self.data_source == \"ogb\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"ogb.nodeproppred.DglNodePropPredDataset\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"name\": ds_alias,\n",
        "            }\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            target = \"graphany.data.load_heterophilous_dataset\"\n",
        "            url = f\"https://raw.githubusercontent.com/yandex-research/heterophilous-graphs/main/data/{ds_alias}.npz\"\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"url\": url,\n",
        "            }\n",
        "        elif self.data_source == \"relbench\":\n",
        "            target = \"graphany.data.load_relbench_dataset\"\n",
        "            # url = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}.pkl\"\n",
        "            '''\n",
        "            if ds_alias == \"f1_3_classes\":\n",
        "                url = \"https://drive.google.com/file/d/16pyMEgYqX-5hnctXVSa0oB1YCOxFsSa_/view?usp=sharing\"\n",
        "            else:\n",
        "                url1 = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}3.pkl\"\n",
        "                url2 = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}3.pkl\"\n",
        "            '''\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}.pkl\",\n",
        "                # \"url\": url,\n",
        "                \"url\" : \"\",\n",
        "            }\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        self.data_init_args = OmegaConf.create(ds_init_args)\n",
        "        # self.cache_f_name = osp.join(\n",
        "        #     cache_dir, f'{self.name}_{n_hops}')\n",
        "        if cfg.get(\"feat_chn\"):\n",
        "            all_channels = \"+\".join([cfg.feat_chn, cfg.pred_chn])\n",
        "            all_hops = re.findall(r\"\\d+\", all_channels)\n",
        "            n_hops = max(max([int(_) for _ in all_hops]), n_hops)\n",
        "\n",
        "        self.split_index = 0\n",
        "        (\n",
        "            self.g,\n",
        "            self.label,\n",
        "            self.feat,\n",
        "            self.train_mask,\n",
        "            self.val_mask,\n",
        "            self.test_mask,\n",
        "            self.num_class,\n",
        "        ) = self.load_dataset(self.data_init_args)\n",
        "        self.n_nodes, self.n_edges = self.g.num_nodes(), self.g.num_edges()\n",
        "        self.cache_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}.pt\",\n",
        "        )\n",
        "\n",
        "        self.dist_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}_{cfg.feat_chn}_entropy={cfg.entropy}_dist.pt\",\n",
        "        )\n",
        "\n",
        "        self.gidtype = self.g.idtype\n",
        "        self.train_indices = self.train_mask.nonzero().view(-1)\n",
        "\n",
        "        (\n",
        "            self.features,\n",
        "            self.unmasked_pred,\n",
        "            self.dist,\n",
        "        ) = self.prepare_prop_features_logits_and_dist_features(\n",
        "            self.g, self.feat, n_hops=cfg.n_hops\n",
        "        )\n",
        "        # Remove the graph, as GraphAny doesn't use it in training\n",
        "        del self.g\n",
        "        del self.feat\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def to(self, device):  # Supports nested dictionary\n",
        "        def to_device(input):\n",
        "            if input is None:\n",
        "                return None\n",
        "            elif isinstance(input, dict):\n",
        "                return {key: to_device(value) for key, value in input.items()}\n",
        "            elif isinstance(input, list):\n",
        "                return [to_device(item) for item in input]\n",
        "            elif hasattr(input, \"to\"):\n",
        "                return input.to(device)\n",
        "            else:\n",
        "                return (\n",
        "                    input  # Return as is if it's not a tensor or any nested structure\n",
        "                )\n",
        "\n",
        "        # Apply to_device to all attributes that may contain tensors\n",
        "        attrs = [\n",
        "            \"label\",\n",
        "            \"feat\",\n",
        "            \"train_mask\",\n",
        "            \"val_mask\",\n",
        "            \"test_mask\",\n",
        "            \"train_indices\",\n",
        "            \"unmasked_pred\",\n",
        "        ]\n",
        "        for attr in attrs:\n",
        "            if hasattr(self, attr):\n",
        "                setattr(self, attr, to_device(getattr(self, attr)))\n",
        "\n",
        "    def load_dataset(self, data_init_args):\n",
        "        dataset = instantiate(data_init_args)\n",
        "\n",
        "        if self.data_source == \"ogb\":\n",
        "            split_idx = dataset.get_idx_split()\n",
        "            train_indices, valid_indices, test_indices = (\n",
        "                split_idx[\"train\"],\n",
        "                split_idx[\"valid\"],\n",
        "                split_idx[\"test\"],\n",
        "            )\n",
        "            # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)\n",
        "            g, label = dataset[0]\n",
        "            label = label.view(-1)\n",
        "\n",
        "            def to_mask(indices):\n",
        "                mask = torch.BoolTensor(g.number_of_nodes()).fill_(False)\n",
        "                mask[indices] = 1\n",
        "                return mask\n",
        "\n",
        "            train_mask, val_mask, test_mask = map(\n",
        "                to_mask, (train_indices, valid_indices, test_indices)\n",
        "            )\n",
        "\n",
        "            num_class = label.max().item() + 1\n",
        "\n",
        "            feat = g.ndata[\"feat\"]\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"relbench\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"dgl\":\n",
        "            g = dataset[0]\n",
        "            num_class = dataset.num_classes\n",
        "\n",
        "            # get node feature\n",
        "            feat = g.ndata[\"feat\"]\n",
        "\n",
        "            # get data split\n",
        "            train_mask = g.ndata[\"train_mask\"]\n",
        "            val_mask = g.ndata[\"val_mask\"]\n",
        "            test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "            label = g.ndata[\"label\"]\n",
        "        elif self.data_source == \"pyg\":\n",
        "            g = dgl.graph((dataset.edge_index[0], dataset.edge_index[1]))\n",
        "            n_nodes = dataset.x.shape[0]\n",
        "            num_class = dataset.num_classes\n",
        "            # get node feature\n",
        "            feat = dataset.x\n",
        "            label = dataset.y\n",
        "\n",
        "            if (\n",
        "                    hasattr(dataset, \"train_mask\")\n",
        "                    and hasattr(dataset, \"val_mask\")\n",
        "                    and hasattr(dataset, \"test_mask\")\n",
        "            ):\n",
        "                train_mask, val_mask, test_mask = (\n",
        "                    dataset.train_mask,\n",
        "                    dataset.val_mask,\n",
        "                    dataset.test_mask,\n",
        "                )\n",
        "            else:\n",
        "                if label.ndim > 1:\n",
        "                    raise NotImplementedError(\n",
        "                        \"Multi-Label classification currently unsupported.\"\n",
        "                    )\n",
        "                logging.warning(\n",
        "                    f\"No dataset split found for {self.name}, splitting with semi-supervised settings!!\"\n",
        "                )\n",
        "                train_mask, val_mask, test_mask = get_data_split_masks(\n",
        "                    n_nodes, label, 20 * num_class, seed=self.cfg.seed\n",
        "                )\n",
        "\n",
        "                self.split_index = self.cfg.seed\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        if train_mask.ndim == 1:\n",
        "            pass  # only one train/val/test split\n",
        "        elif train_mask.ndim == 2:\n",
        "            # ! Multiple splits\n",
        "            # Modified: Use the ${seed} split if not specified!\n",
        "            split_index = self.data_init_args.get(\"split\", self.cfg.seed)\n",
        "            # Avoid invalid split index\n",
        "            self.split_index = split_index = (split_index % train_mask.ndim)\n",
        "            train_mask = train_mask[:, split_index].squeeze()\n",
        "            val_mask = val_mask[:, split_index].squeeze()\n",
        "            if test_mask.ndim == 2:\n",
        "                test_mask = test_mask[:, split_index].squeeze()\n",
        "        else:\n",
        "            raise ValueError(\"train/val/test masks have more than 2 dimensions\")\n",
        "        print(\n",
        "            f\"{self.name} {g.num_nodes()} {g.num_edges()} {feat.shape[1]} {num_class} {len(train_mask.nonzero())}\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.add_self_loop:\n",
        "            g = dgl.add_self_loop(g)\n",
        "        else:\n",
        "            g = dgl.remove_self_loop(g)\n",
        "        if self.cfg.to_bidirected:\n",
        "            g = dgl.to_bidirected(g)\n",
        "        g = dgl.to_simple(g)  # Remove duplicate edges.\n",
        "        return g, label, feat, train_mask, val_mask, test_mask, num_class\n",
        "\n",
        "    def compute_linear_gnn_logits(\n",
        "            self, features, n_per_label_examples, visible_nodes, bootstrap=False\n",
        "    ):\n",
        "        # Compute and save LinearGNN logits into a dict. Note the computation is on CPU as torch does not support\n",
        "        # the gelss driver on GPU currently.\n",
        "        preds = {}\n",
        "        label, num_class, device = self.label, self.num_class, torch.device(\"cpu\")\n",
        "        label = label.to(device)\n",
        "        visible_nodes = visible_nodes.to(device)\n",
        "        for channel, F in features.items():\n",
        "            F = F.to(device)\n",
        "            if bootstrap:\n",
        "                ref_nodes = sample_k_nodes_per_label(\n",
        "                    label, visible_nodes, n_per_label_examples, num_class\n",
        "                )\n",
        "            else:\n",
        "                ref_nodes = visible_nodes\n",
        "            Y_L = torch.nn.functional.one_hot(label[ref_nodes], num_class).float()\n",
        "            with timer(\n",
        "                    f\"Solving with CPU driver (N={len(ref_nodes)}, d={F.shape[1]}, k={num_class})\",\n",
        "                    logger.debug,\n",
        "            ):\n",
        "                W = torch.linalg.lstsq(\n",
        "                    F[ref_nodes.cpu()].cpu(), Y_L.cpu(), driver=\"gelss\"\n",
        "                )[0]\n",
        "            preds[channel] = F @ W\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def compute_channel_logits(self, features, visible_nodes, sample, device):\n",
        "        pred_logits = self.compute_linear_gnn_logits(\n",
        "            {\n",
        "                c: features[c]\n",
        "                for c in set(self.cfg.feat_channels + self.cfg.pred_channels)\n",
        "            },\n",
        "            self.cfg.n_per_label_examples,\n",
        "            visible_nodes,\n",
        "            bootstrap=sample,\n",
        "        )\n",
        "        return {c: logits.to(device) for c, logits in pred_logits.items()}\n",
        "\n",
        "    def prepare_prop_features_logits_and_dist_features(self, g, input_feats, n_hops):\n",
        "        # Calculate Low-pass features containing AX, A^2X and High-pass features\n",
        "        # (I-A)X, and (I-A)^2X\n",
        "        if not os.path.exists(self.cache_f_name):\n",
        "            g = g.to(self.preprocess_device)\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} message passing and normalized predictions to file {self.cache_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                dim = input_feats.size(1)\n",
        "                LP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "                HP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "\n",
        "                g.ndata[\"LP\"] = input_feats.to(self.preprocess_device)\n",
        "                g.ndata[\"HP\"] = input_feats.to(self.preprocess_device)\n",
        "                for hop_idx in range(n_hops):\n",
        "                    # D^-1 A filter\n",
        "                    g.update_all(fn.copy_u(\"LP\", \"temp\"), fn.mean(\"temp\", \"LP\"))\n",
        "\n",
        "                    # (I - D^-1A) filter\n",
        "                    g.update_all(fn.copy_u(\"HP\", \"temp\"), fn.mean(\"temp\", \"HP_out\"))\n",
        "                    g.ndata[\"HP\"] = g.ndata[\"HP\"] - g.ndata[\"HP_out\"]\n",
        "\n",
        "                    LP[hop_idx] = g.ndata[\"LP\"].clone()\n",
        "                    HP[hop_idx] = g.ndata[\"HP\"].clone()\n",
        "                lp_feat_dict = {f\"L{l + 1}\": x for l, x in enumerate(LP)}\n",
        "                hp_feat_dict = {f\"H{l + 1}\": x for l, x in enumerate(HP)}\n",
        "\n",
        "                features = {\"X\": input_feats, **lp_feat_dict, **hp_feat_dict}\n",
        "                unmasked_pred = self.compute_channel_logits(\n",
        "                    features,\n",
        "                    self.train_indices,\n",
        "                    sample=False,\n",
        "                    device=self.preprocess_device,\n",
        "                )\n",
        "                torch.save((features, unmasked_pred), self.cache_f_name)\n",
        "        else:\n",
        "            features, unmasked_pred = torch.load(self.cache_f_name, map_location=\"cpu\")\n",
        "        if not os.path.exists(self.dist_f_name):\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} conditional gaussian distances \"\n",
        "                    f\"and save to {self.dist_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                # y_feat: n_nodes, n_channels, n_labels\n",
        "                y_feat = np.stack(\n",
        "                    [unmasked_pred[c].cpu().numpy() for c in self.cfg.feat_channels],\n",
        "                    axis=1,\n",
        "                )\n",
        "                # Conditional gaussian probability\n",
        "                bsz, n_channel, n_class = y_feat.shape\n",
        "                dist_feat_dim = n_channel * (n_channel - 1)\n",
        "                # Conditional gaussian probability\n",
        "                cond_gaussian_prob = np.zeros((bsz, n_channel, n_channel))\n",
        "                for i in range(bsz):\n",
        "                    cond_gaussian_prob[i, :, :] = get_entropy_normed_cond_gaussian_prob(\n",
        "                        y_feat[i, :, :], self.cfg.entropy\n",
        "                    )\n",
        "                dist = np.zeros((bsz, dist_feat_dim), dtype=np.float32)\n",
        "\n",
        "                # Compute pairwise distances between channels n_channels(n_channels-1)/2 total features\n",
        "                pair_index = 0\n",
        "                for c in range(n_channel):\n",
        "                    for c_prime in range(n_channel):\n",
        "                        if c != c_prime:  # Diagonal distances are useless\n",
        "                            dist[:, pair_index] = cond_gaussian_prob[:, c, c_prime]\n",
        "                            pair_index += 1\n",
        "\n",
        "                dist = torch.from_numpy(dist)\n",
        "                torch.save(dist, self.dist_f_name)\n",
        "        else:\n",
        "            dist = torch.load(self.dist_f_name, map_location=\"cpu\")\n",
        "        return features, unmasked_pred, dist\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_mask.nonzero().view(-1),\n",
        "            batch_size=self.train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "riTRCN1OnR2k"
      },
      "outputs": [],
      "source": [
        "path_name = 'GraphAny/graphany/data.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFSPf9jrIEfg"
      },
      "source": [
        "# Testing GraphAny on F1 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XMxpGG22Lc10"
      },
      "outputs": [],
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqd5y77pmiyI",
        "outputId": "404db92f-988a-4ed6-f941-f38f2e03331a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[15:28:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mMar4-15\u001b[0m:\u001b[1;36m28\u001b[0m-\u001b[1;36m2e114737\u001b[0m/                                                         \u001b[2mexperiment.py:56\u001b[0m\n",
            "Done loading data from cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "F1 97605 455432 300 3 66303\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 message passing and normalized predictions to file                                                            \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:17\u001b[0m                                            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:28:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 message passing and normalized predictions to file                                                           \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:23\u001b[0m, running time = \u001b[1;36m6.27\u001b[0m seconds.              \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 conditional gaussian distances and save to                                                                    \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:23\u001b[0m               \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:28:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 conditional gaussian distances and save to                                                                   \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:28\u001b[0m, running time \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         = \u001b[1;36m4.95\u001b[0m seconds.                                                                                                                    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:28\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.30it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m[15:28:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                                \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.16it/s]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 205.56it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 71.38it/s] \n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:289\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                                   \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                               \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m15:28:29\u001b[0m, running time = \u001b[1;36m12.97\u001b[0m seconds.                                                                     \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing GraphAny on F1 Dataset prediction files"
      ],
      "metadata": {
        "id": "j_34PmXAZ3_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import rootutils\n",
        "\n",
        "root = rootutils.setup_root(__file__, dotenv=True, pythonpath=True, cwd=False)\n",
        "from graphany.utils import logger, timer\n",
        "from graphany.utils.experiment import init_experiment\n",
        "from graphany.data import GraphDataset, CombinedDataset\n",
        "from graphany.model import GraphAny\n",
        "\n",
        "import torch\n",
        "import hydra\n",
        "from omegaconf import DictConfig\n",
        "import wandb\n",
        "import numpy as np\n",
        "import torchmetrics\n",
        "from rich.pretty import pretty_repr\n",
        "\n",
        "import os\n",
        "\n",
        "mean = lambda input: np.round(np.mean(input).item(), 2)\n",
        "\n",
        "\n",
        "class InductiveNodeClassification(pl.LightningModule):\n",
        "    def __init__(self, cfg, combined_dataset, checkpoint=None):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if checkpoint:\n",
        "            # Initialize from previous checkpoint using previous graphany config\n",
        "            ckpt = torch.load(checkpoint, map_location=\"cpu\")\n",
        "            logger.critical(f\"Loaded checkpoint at {checkpoint}\")\n",
        "            self.gnn_model = GraphAny(**ckpt[\"graph_any_config\"])\n",
        "            self.load_state_dict(ckpt[\"state_dict\"])\n",
        "        else:\n",
        "            self.gnn_model = GraphAny(**cfg.graph_any)\n",
        "        self.combined_dataset = combined_dataset\n",
        "        self.attn_dict, self.loss_dict, self.res_dict = {}, {}, {}\n",
        "        # Initialize accuracy metrics for validation and testing\n",
        "        self.metrics = {}\n",
        "        held_out_datasets = list(\n",
        "            set(self.cfg._all_datasets) - set(self.cfg._trans_datasets)\n",
        "        )  # 27 datasets in total\n",
        "        self.heldout_metrics = [\n",
        "            f\"{setting}/{d.lower()[:4]}_{split}_acc\"\n",
        "            for split in [\"val\", \"test\"]\n",
        "            for d in held_out_datasets\n",
        "            for setting in [\"trans\", \"ind\"]\n",
        "        ]\n",
        "        for split in (\"val\", \"test\"):\n",
        "            self.metrics[split] = {\n",
        "                k: torchmetrics.Accuracy(task=\"multiclass\", num_classes=v.num_class)\n",
        "                for k, v in combined_dataset.eval_ds_dict.items()\n",
        "            }\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def on_train_end(self):\n",
        "        checkpoint_path = f\"{self.cfg.dirs.output}{self.cfg.dataset}_val_acc={self.res_dict['val_acc']}.pt\"\n",
        "        self.save_checkpoint(checkpoint_path)\n",
        "\n",
        "    def save_checkpoint(self, file_path):\n",
        "        checkpoint = {\n",
        "            \"state_dict\": self.state_dict(),\n",
        "            \"optimizer_state_dict\": [\n",
        "                opt.state_dict() for opt in self.trainer.optimizers\n",
        "            ],\n",
        "            \"graph_any_config\": self.cfg.graph_any,\n",
        "        }\n",
        "        torch.save(checkpoint, file_path)\n",
        "        logger.critical(f\"Checkpoint saved to {file_path}\")\n",
        "\n",
        "    def get_metric_name(self, ds_name, split):\n",
        "        if ds_name in self.cfg.train_datasets:\n",
        "            return f\"trans/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "        else:\n",
        "            return f\"ind/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # start with all the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {\"params\": decay_params, \"weight_decay\": self.cfg.weight_decay},\n",
        "            {\"params\": nodecay_params, \"weight_decay\": 0.0},\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        logger.info(\n",
        "            f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\"\n",
        "        )\n",
        "        logger.info(\n",
        "            f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.optimizer == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=self.cfg.lr)\n",
        "        else:  # AdamW\n",
        "            optimizer = torch.optim.AdamW(\n",
        "                optim_groups,\n",
        "                lr=self.cfg.lr,\n",
        "                weight_decay=self.cfg.weight_decay,\n",
        "            )\n",
        "        return optimizer\n",
        "\n",
        "    def on_fit_start(self):\n",
        "        super().on_fit_start()\n",
        "        # move all datasets to the correct GPU device\n",
        "        print(f\"moving train and eval datasets to {self.device}\")\n",
        "        self.combined_dataset.to(self.device)\n",
        "        self.move_metrics_to_device()\n",
        "\n",
        "    def move_metrics_to_device(self):\n",
        "        for metrics_dict in self.metrics.values():\n",
        "            for metric in metrics_dict.values():\n",
        "                metric.to(self.device)\n",
        "\n",
        "    def predict(self, ds, nodes, input, is_training=False):\n",
        "        # Use preprocessed distance during evaluation\n",
        "        dist = ds.dist if not is_training else None\n",
        "        dist = dist.to(nodes.device)[nodes] if dist is not None else dist\n",
        "\n",
        "        preds, attn = self.gnn_model(\n",
        "            {c: chn_pred[nodes] for c, chn_pred in input.items()}, dist=dist\n",
        "        )\n",
        "\n",
        "        self.attn_dict.update(\n",
        "            {\n",
        "                f\"Attention/{ds.name}-{c}\": v\n",
        "                for c, v in zip(self.cfg.feat_channels, attn)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        def softmax(logits):\n",
        "          exp_logits = np.exp(logits - np.max(logits))\n",
        "          return exp_logits / exp_logits.sum(axis=0)\n",
        "\n",
        "        # Scrittura delle predizioni in un file\n",
        "        with open(\"predictions.txt\", \"a\") as file:  # Modalit append\n",
        "            for node, pred in zip(nodes.cpu().numpy(), preds.cpu().numpy()):\n",
        "                line = f\"Node:{node}\\tPrediction:{pred}\\tClass:{np.argmax(softmax(pred))}\"\n",
        "                file.write(line + os.linesep)  # Scrive il nodo e la predizione\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        loss = {}\n",
        "        for ds_name, batch_nodes in batch.items():\n",
        "            ds = self.combined_dataset.train_ds_dict[ds_name]\n",
        "            train_target_idx = batch_nodes\n",
        "            # Batch nodes are not visible to avoid trivial solution and overfitting\n",
        "            visible_nodes = list(\n",
        "                set(ds.train_indices.tolist()) - set(batch_nodes.tolist())\n",
        "            )\n",
        "            ref_nodes = torch.tensor(visible_nodes, dtype=torch.long).to(self.device)\n",
        "            ds_too_small = len(visible_nodes) < len(batch_nodes)\n",
        "            if ds_too_small:\n",
        "                # Visible nodes are too few, add first half of the batch to visible nodes\n",
        "                ref_nodes = torch.cat((ref_nodes, batch_nodes[: len(batch_nodes) // 2]))\n",
        "\n",
        "            input = ds.compute_channel_logits(\n",
        "                ds.features, ref_nodes, sample=True, device=self.device\n",
        "            )\n",
        "\n",
        "            preds = self.predict(ds, train_target_idx, input, is_training=True)\n",
        "            loss[f\"loss/{ds_name}_loss\"] = self.criterion(\n",
        "                preds, ds.label[train_target_idx]\n",
        "            )\n",
        "\n",
        "        detached_loss = {k: v.detach().cpu() for k, v in loss.items()}\n",
        "        avg_loss = mean(list(detached_loss.values()))\n",
        "        self.loss_dict.update({\"loss/avg_loss\": avg_loss, **detached_loss})\n",
        "        return sum(loss.values())\n",
        "\n",
        "    def evaluation_step(self, split, batch, batch_idx):\n",
        "        self.move_metrics_to_device()\n",
        "        for ds_name, eval_idx in batch.items():\n",
        "            if eval_idx is None:  # Skip if dataset is already evaluated (empty batch)\n",
        "                continue\n",
        "            ds = self.combined_dataset.eval_ds_dict[ds_name]\n",
        "            ds.to(self.device)\n",
        "            eval_idx.to(self.device)\n",
        "            # Use unmasked feature for evaluation\n",
        "            processed_feat = ds.unmasked_pred\n",
        "            preds = self.predict(\n",
        "                ds, eval_idx, processed_feat, is_training=False\n",
        "            ).argmax(-1)\n",
        "            self.metrics[split][ds_name].update(preds, ds.label[eval_idx])\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"val\", batch, batch_idx)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"test\", batch, batch_idx)\n",
        "\n",
        "    def compute_and_log_metrics(self, split):\n",
        "        # Compute metrics from collected outputs\n",
        "        res = {}\n",
        "        for ds_name, metric in self.metrics[split].items():\n",
        "            metric_name = self.get_metric_name(ds_name, split)\n",
        "            accuracy = metric.compute().cpu().numpy()\n",
        "            res[metric_name] = np.round(accuracy * 100, 2)\n",
        "            metric.reset()  # Reset metrics for the next epoch\n",
        "\n",
        "        combined_res = {f\"{split}_acc\": np.round(sum(res.values()) / len(res), 2)}\n",
        "        combined_res[f\"trans_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"trans\")]\n",
        "        )\n",
        "        combined_res[f\"ind_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"ind\")]\n",
        "        )\n",
        "\n",
        "        combined_res[f\"heldout_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k in self.heldout_metrics]\n",
        "        )\n",
        "        self.log_dict(res, prog_bar=False, logger=True, add_dataloader_idx=False)\n",
        "        self.log_dict(\n",
        "            combined_res, prog_bar=True, logger=True, add_dataloader_idx=False\n",
        "        )\n",
        "        self.res_dict.update({**res, **combined_res})\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log_dict(self.loss_dict, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if len(self.attn_dict):\n",
        "            self.log_dict(self.attn_dict, on_epoch=True, prog_bar=False, logger=True)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"val\")\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"test\")\n",
        "\n",
        "\n",
        "@timer()\n",
        "@hydra.main(config_path=f\"{root}/configs\", config_name=\"main\", version_base=None)\n",
        "def main(cfg: DictConfig):\n",
        "    cfg, logger = init_experiment(cfg)\n",
        "    # Define the default step metric for all metrics\n",
        "    wandb.define_metric(\"*\", step_metric=\"epoch\")\n",
        "    if torch.cuda.is_available() and cfg.preprocess_device == \"gpu\":\n",
        "        preprocess_device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        preprocess_device = torch.device(\"cpu\")\n",
        "\n",
        "    def construct_ds_dict(datasets):\n",
        "        datasets = [datasets] if isinstance(datasets, str) else datasets\n",
        "        ds_dict = {\n",
        "            dataset: GraphDataset(\n",
        "                cfg,\n",
        "                dataset,\n",
        "                cfg.dirs.data_cache,\n",
        "                cfg.train_batch_size,\n",
        "                cfg.val_test_batch_size,\n",
        "                cfg.n_hops,\n",
        "                preprocess_device,\n",
        "            )\n",
        "            for dataset in datasets\n",
        "        }\n",
        "        return ds_dict\n",
        "\n",
        "    train_ds_dict = construct_ds_dict(cfg.train_datasets)\n",
        "    eval_ds_dict = construct_ds_dict(cfg.eval_datasets)\n",
        "\n",
        "    combined_dataset = CombinedDataset(train_ds_dict, eval_ds_dict, cfg)\n",
        "\n",
        "    model = InductiveNodeClassification(cfg, combined_dataset, cfg.get(\"prev_ckpt\"))\n",
        "    # Set up the checkpoint callback to save only at the end of training\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=cfg.dirs.output,  # specify where to save\n",
        "        filename=\"final_checkpoint.pt\",  # set a filename\n",
        "        save_top_k=0,  # do not save based on metric, just save last\n",
        "        save_last=True,  # ensures only the last checkpoint is kept\n",
        "        save_on_train_epoch_end=True,  # save at the end of training epoch\n",
        "    )\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=cfg.total_steps,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        limit_train_batches=cfg.limit_train_batches,\n",
        "        check_val_every_n_epoch=cfg.eval_freq,\n",
        "        logger=logger,\n",
        "        accelerator=\"gpu\" if torch.cuda.is_available() and cfg.gpus > 0 else \"cpu\",\n",
        "        default_root_dir=cfg.dirs.lightning_root,\n",
        "    )\n",
        "    dataloaders = {\n",
        "        \"train\": combined_dataset.train_dataloader(),\n",
        "        \"val\": combined_dataset.val_dataloader(),\n",
        "        \"test\": combined_dataset.test_dataloader(),\n",
        "    }\n",
        "    if cfg.total_steps > 0:\n",
        "        trainer.fit(\n",
        "            model,\n",
        "            train_dataloaders=dataloaders[\"train\"],\n",
        "            val_dataloaders=dataloaders[\"val\"],\n",
        "        )\n",
        "    trainer.validate(model, dataloaders=dataloaders[\"val\"])\n",
        "    trainer.test(model, dataloaders=dataloaders[\"test\"])\n",
        "    final_results = model.res_dict\n",
        "    logger.critical(pretty_repr(final_results))\n",
        "    logger.wandb_summary_update(final_results, finish_wandb=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AVs-Ye68aWpF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_name = 'GraphAny/graphany/run.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ],
      "metadata": {
        "id": "mXAnRZB-becd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ],
      "metadata": {
        "id": "PsPPVWujbv5p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulyl08LlbwbJ",
        "outputId": "8f180f36-062d-43ef-dc9c-164412df4c6c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[07:30:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mMar6-7\u001b[0m:\u001b[1;36m30\u001b[0m-d1b51443/                                                          \u001b[2mexperiment.py:56\u001b[0m\n",
            "Done loading data from cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "F1 97605 455432 300 3 66303\n",
            "\u001b[2;36m[07:30:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 message passing and normalized predictions to file                                                            \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m07:30:53\u001b[0m                                            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[07:31:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 message passing and normalized predictions to file                                                           \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m07:31:00\u001b[0m, running time = \u001b[1;36m7.43\u001b[0m seconds.              \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 conditional gaussian distances and save to                                                                    \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m07:31:00\u001b[0m               \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[07:31:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 conditional gaussian distances and save to                                                                   \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m07:31:06\u001b[0m, running time \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         = \u001b[1;36m5.53\u001b[0m seconds.                                                                                                                    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:32\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.91it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                                \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.82it/s]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          90.0           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 111.30it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.4800033569336\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 49.76it/s] \n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    90.4800033569336     \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:304\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                                   \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m90.0\u001b[0m,                                                                                                               \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.48\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m07:31:06\u001b[0m, running time = \u001b[1;36m15.37\u001b[0m seconds.                                                                     \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "def build_comparison_file(download_path, output_file):\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    val_nodes = []\n",
        "    test_nodes = []\n",
        "\n",
        "    # Scrittura dei nodi e delle rispettive classi nel test set\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"Node,Class\\n\")  # Header del file\n",
        "        for node in range(len(test_mask)):\n",
        "            if val_mask[node]:\n",
        "                val_nodes.append(node)\n",
        "                f.write(f\"{node},{labels[node].item()}\\n\")  # Scrivo nodo e classe\n",
        "            if test_mask[node]:\n",
        "                test_nodes.append(node)\n",
        "                f.write(f\"{node},{labels[node].item()}\\n\")  # Scrivo nodo e classe\n",
        "\n",
        "    return labels, node_features, train_mask, val_mask, test_mask, val_nodes, test_nodes"
      ],
      "metadata": {
        "id": "qr4Mo4bMatiL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_data_path = \"data/relbench/f1_3_classes_remastered.pkl\"\n",
        "f1_labels = \"true_labels.txt\"\n",
        "labels, node_features, train_mask, val_mask, test_mask, val_nodes, test_nodes = build_comparison_file(f1_data_path, f1_labels)"
      ],
      "metadata": {
        "id": "RNtwne-b_2bG"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_AUROC(file_path, true_labels, val_nodes, test_nodes, auroc_labels):\n",
        "    val_scores = []\n",
        "    test_scores = []\n",
        "\n",
        "    # Leggi il file e estrai le probabilit\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Split della linea per ottenere il nodo e le probabilit\n",
        "            parts = line.split(\"\\t\")\n",
        "            node = int(parts[0].split(':')[1])  # Estrai il nodo\n",
        "            prediction = [float(x) for x in parts[1].strip('Prediction:[]').split()]\n",
        "            #print(prediction)\n",
        "\n",
        "            # Controlla se la somma delle probabilit  1.0\n",
        "            total = sum(prediction)\n",
        "            if not np.isclose(total, 1.0):\n",
        "                delta_error = 1.0 - total\n",
        "                prediction[np.argmax(prediction)] += delta_error  # Aggiusta la probabilit massima\n",
        "                # Ricalcola la somma per confermare\n",
        "                adjusted_total = sum(prediction)\n",
        "\n",
        "\n",
        "            # Controlla se il nodo  in val_nodes o test_nodes\n",
        "            if node in val_nodes:\n",
        "                val_scores.append(prediction)  # Probabilit della classe 1 per validazione\n",
        "            elif node in test_nodes:\n",
        "                test_scores.append(prediction)  # Probabilit della classe 1 per test\n",
        "\n",
        "    # Estrai le etichette vere per validazione e test\n",
        "    val_labels = [true_labels[node] for node in val_nodes]\n",
        "    test_labels = [true_labels[node] for node in test_nodes]\n",
        "\n",
        "\n",
        "    # Calcola l'AUROC per validazione e test\n",
        "    auroc_val = roc_auc_score(val_labels, val_scores, multi_class='ovo', labels= auroc_labels, average='macro')\n",
        "    auroc_test = roc_auc_score(test_labels, test_scores, multi_class='ovo', labels= auroc_labels, average='macro')\n",
        "\n",
        "    return auroc_val, auroc_test"
      ],
      "metadata": {
        "id": "dBXkGdfgD1HN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_path = \"predictions.txt\"\n",
        "auroc_labels = [0, 1, 2]\n",
        "auroc_val, auroc_test = compute_AUROC(predictions_path, labels, val_nodes, test_nodes, auroc_labels)\n",
        "print(f\"ROC AUC Val: {auroc_val*100:.2f}\")\n",
        "print(f\"ROC AUC Test: {auroc_test*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wfBebJPEtCK",
        "outputId": "b5fc63c0-5005-44ce-ba56-a6d3cdf563cb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Val: 58.33\n",
            "ROC AUC Test: 50.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}