{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcNraNGefTp8"
      },
      "source": [
        "# Downloading GraphAny"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing to do is to download the git repository of GraphAny, so, we are going to clone it."
      ],
      "metadata": {
        "id": "mXDTxpRSL7DD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC3-4ki8fWY3",
        "outputId": "1d8d2f7d-b87b-4cea-e9e7-48365b019529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GraphAny'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 76 (delta 24), reused 40 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (76/76), 576.89 KiB | 4.65 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DeepGraphLearning/GraphAny.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHVlit_sfoks"
      },
      "source": [
        "# Imports and Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we need to setup our environment manually using the `environment.yaml` file.\n",
        "\n",
        "GraphAny relies on the usage of Conda, but not all the dependencies are avaiable on it, so we are going also to use pip.\n",
        "\n",
        "Note that this process may take a while in colab."
      ],
      "metadata": {
        "id": "k9oYudlWMDxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MKSI8hbjDr2",
        "outputId": "5221c6a2-28a5-4e6e-9192-29617be2b518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  39% 0.3934081948830919/1 [00:23<00:31, 52.34s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  79% 0.7861098247881382/1 [00:23<00:05, 26.41s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.3958735998644542/1 [00:24<00:29, 48.47s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  79% 0.789979129008007/1 [00:24<00:05, 26.66s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.39796408150763696/1 [00:24<00:29, 48.36s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  79% 0.7944666060914052/1 [00:24<00:05, 25.29s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.4000545631508197/1 [00:24<00:29, 49.27s/it] \n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.40209959954088975/1 [00:24<01:16, 128.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  63% 0.6309946664126983/1 [00:24<00:04, 13.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  40% 0.4036220155201642/1 [00:25<01:08, 114.04s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  65% 0.6497769314653796/1 [00:25<00:03, 11.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.4052239606923857/1 [00:25<01:00, 100.92s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  67% 0.6694535900919981/1 [00:25<00:03,  9.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.4067577379849383/1 [00:25<00:55, 93.48s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  69% 0.6859998712098365/1 [00:25<00:02,  8.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.40841648972355066/1 [00:25<00:50, 85.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  71% 0.7060119274266814/1 [00:25<00:02,  7.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.41010932540199757/1 [00:25<00:46, 78.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  73% 0.725017790872847/1 [00:25<00:01,  7.25s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.4122566136115712/1 [00:25<00:41, 70.33s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  75% 0.7453652446799185/1 [00:25<00:01,  6.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  83% 0.8257873645102248/1 [00:25<00:06, 34.89s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  41% 0.4142221208086941/1 [00:25<00:41, 70.12s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  83% 0.8293132393614662/1 [00:25<00:05, 33.59s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.4165171060908838/1 [00:25<00:36, 62.49s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  83% 0.8336862399886552/1 [00:25<00:05, 31.29s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.4182440257091652/1 [00:25<00:38, 66.46s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  84% 0.8374868583347985/1 [00:25<00:04, 29.90s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  82% 0.819935308906933/1 [00:26<00:01,  5.97s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.42044812048512964/1 [00:26<00:36, 62.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  84% 0.8373759835987085/1 [00:26<00:00,  5.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.42233409848930537/1 [00:26<00:35, 62.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  86% 0.8563818470448741/1 [00:26<00:00,  5.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  42% 0.42476541953083313/1 [00:26<00:31, 54.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.426662758848287/1 [00:26<00:31, 54.80s/it]  \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  85% 0.8546125361836853/1 [00:26<00:03, 26.45s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  90% 0.9006543289547657/1 [00:26<00:00,  5.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.42893502150392043/1 [00:26<00:29, 51.33s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  86% 0.8594434426357108/1 [00:26<00:03, 25.25s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  92% 0.9226787707129694/1 [00:26<00:00,  5.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.43124136809938834/1 [00:26<00:28, 49.98s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  86% 0.8638164432628999/1 [00:26<00:03, 24.60s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  95% 0.9460448028320789/1 [00:26<00:00,  5.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :   3% 0.025413900204195632/1 [00:26<11:58, 737.42s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  43% 0.4335249920683/1 [00:26<00:28, 49.54s/it]    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  97% 0.9657214614586974/1 [00:26<00:00,  5.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.43557002845837/1 [00:26<00:32, 57.58s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  87% 0.8719671669449903/1 [00:26<00:04, 32.01s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  98% 0.9841683289211522/1 [00:26<00:00,  5.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :   6% 0.06491986829413007/1 [00:26<03:14, 208.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4373878385828768/1 [00:27<00:36, 64.40s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4391374808277145/1 [00:27<00:35, 63.15s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  88% 0.8791104978124404/1 [00:27<00:03, 31.15s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  10% 0.10165560081678253/1 [00:27<01:21, 90.30s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4407848712530487/1 [00:27<00:35, 63.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  12% 0.12285392515772296/1 [00:27<00:52, 59.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4428299076431188/1 [00:27<00:33, 59.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  14% 0.14116156890671697/1 [00:27<00:36, 42.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  44% 0.4445568272614002/1 [00:27<00:35, 63.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  16% 0.16043277285302646/1 [00:27<00:25, 30.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.44640872132574144/1 [00:27<00:33, 60.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  18% 0.18175154221863132/1 [00:27<00:18, 22.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.44840831246269885/1 [00:27<00:32, 58.84s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  20% 0.20126363621426968/1 [00:27<00:13, 17.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.4504647101660471/1 [00:27<00:31, 57.36s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  23% 0.22679798144312974/1 [00:27<00:09, 12.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.4523734107967792/1 [00:27<00:30, 56.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  25% 0.24751452568541243/1 [00:27<00:07, 10.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  45% 0.45416849829472955/1 [00:27<00:31, 57.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  27% 0.26726750973037966/1 [00:28<00:06,  8.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.45620217337152147/1 [00:28<00:30, 56.46s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  29% 0.28665915870135356/1 [00:28<00:05,  8.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.45798589955619373/1 [00:28<00:32, 60.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  31% 0.314241069349509/1 [00:28<00:04,  6.44s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.46132612565997483/1 [00:28<00:26, 48.27s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  34% 0.3430274302443088/1 [00:28<00:03,  5.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4640642021600131/1 [00:28<00:24, 45.18s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  37% 0.37169334611444416/1 [00:28<00:03,  4.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4672340085646217/1 [00:28<00:21, 40.54s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  41% 0.4061406231684724/1 [00:28<00:02,  4.15s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4697334974858185/1 [00:28<00:21, 41.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  44% 0.44203324051847376/1 [00:28<00:02,  3.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4721989024671807/1 [00:28<00:22, 42.25s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  47% 0.4716627165859246/1 [00:28<00:02,  3.86s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.47482336583443735/1 [00:28<00:21, 41.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  50% 0.49948551728340895/1 [00:28<00:01,  3.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.4772887708157996/1 [00:29<00:24, 46.45s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  53% 0.5263447577835778/1 [00:29<00:01,  4.15s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.47951558821832035/1 [00:29<00:24, 46.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  56% 0.5559742338510286/1 [00:29<00:01,  3.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.48171968299428475/1 [00:29<00:24, 46.40s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  58% 0.5828334743511975/1 [00:29<00:01,  4.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.48391241645697103/1 [00:29<00:24, 48.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  61% 0.612101615344655/1 [00:29<00:01,  3.97s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.48655960245078395/1 [00:29<00:23, 45.23s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  64% 0.6425742065847568/1 [00:29<00:01,  3.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.4889909234923117/1 [00:29<00:22, 44.29s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  67% 0.6696743371342545/1 [00:29<00:01,  3.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.49155858029317745/1 [00:29<00:22, 43.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.49428529547993755/1 [00:29<00:20, 41.32s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.988756047569551/1 [00:29<00:00, 21.65s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.49677342308785616/1 [00:29<00:20, 41.06s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.9944340797975243/1 [00:29<00:00, 20.41s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | :  76% 0.7601285506572447/1 [00:29<00:00,  3.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.49922746675594026/1 [00:29<00:21, 42.74s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.501590619917799/1 [00:30<00:21, 42.84s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.5039424117663795/1 [00:30<00:23, 46.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5061237839157877/1 [00:30<00:24, 49.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5083960465714211/1 [00:30<00:24, 49.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5106910318536109/1 [00:30<00:23, 47.59s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5128155974366281/1 [00:30<00:25, 53.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5155877578765009/1 [00:30<00:22, 47.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5177804913391871/1 [00:30<00:24, 50.15s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.528039757229372/1 [00:31<00:20, 42.74s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5305846914036815/1 [00:31<00:19, 41.73s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5334704649763359/1 [00:31<00:18, 39.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.5367538845137262/1 [00:31<00:17, 36.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.5403213368830706/1 [00:31<00:15, 34.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.543479781974401/1 [00:31<00:15, 33.76s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5464564460532809/1 [00:31<00:15, 34.27s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.549387664879048/1 [00:32<00:15, 34.97s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5523984128977623/1 [00:32<00:15, 34.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5552841864704167/1 [00:32<00:16, 37.06s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5580109016571768/1 [00:32<00:18, 40.82s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  29% 0.29084847680159376/1 [00:32<00:11, 16.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5628735437402324/1 [00:32<00:18, 43.30s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5652139742755348/1 [00:32<00:21, 49.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  37% 0.3736225863874259/1 [00:32<00:05,  9.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5673158172319956/1 [00:32<00:25, 58.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5692017952361714/1 [00:33<00:25, 60.11s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.571280915566076/1 [00:33<00:24, 57.50s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5730987256905827/1 [00:33<00:25, 59.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5748370066221422/1 [00:33<00:25, 59.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  58% 0.5768365977590997/1 [00:33<00:24, 57.42s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  58% 0.5786089626304938/1 [00:33<00:24, 57.98s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  58% 0.5807676121533455/1 [00:33<00:23, 56.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  58% 0.5828353711699719/1 [00:33<00:22, 54.92s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5850735498857708/1 [00:33<00:21, 52.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5870049731430592/1 [00:34<00:22, 54.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5895499073173687/1 [00:34<00:20, 50.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5923675130103541/1 [00:34<00:18, 45.70s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5947761114253255/1 [00:34<00:18, 46.11s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.5969574835747335/1 [00:34<00:20, 51.88s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.5989457133984128/1 [00:34<00:20, 51.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6009112205955357/1 [00:34<00:20, 52.41s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6031380379980565/1 [00:34<00:19, 50.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6051489904482921/1 [00:34<00:21, 53.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | : 100% 1.0/1 [00:35<00:00,  4.47s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6070576910790242/1 [00:35<00:22, 56.42s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   0% 0.00015896474520165442/1 [00:35<61:24:34, 221109.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6091140887823724/1 [00:35<00:22, 56.42s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   1% 0.005722730827259558/1 [00:35<1:12:09, 4354.84s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6123407017533719/1 [00:35<00:17, 46.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  99% 0.9888848211254188/1 [00:35<00:00,  3.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6145561578426144/1 [00:35<00:18, 48.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :   4% 0.037674644612792095/1 [00:35<05:56, 370.55s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6166807234256316/1 [00:35<00:22, 58.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6185212561766947/1 [00:35<00:23, 61.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6203617889277578/1 [00:35<00:23, 61.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6227363034028948/1 [00:35<00:20, 55.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6248267850460775/1 [00:36<00:20, 53.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6267582083033659/1 [00:36<00:20, 53.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6288259673199923/1 [00:36<00:19, 52.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6311777591685729/1 [00:36<00:18, 50.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6331659889922521/1 [00:36<00:18, 50.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6357109231665615/1 [00:36<00:17, 48.71s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6384717222931562/1 [00:36<00:16, 44.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6415619995048176/1 [00:36<00:14, 40.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6444023278243594/1 [00:36<00:13, 38.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6470154298783378/1 [00:37<00:14, 42.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6498898421377141/1 [00:37<00:14, 40.05s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6524347763120235/1 [00:37<00:14, 40.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6552751046315652/1 [00:37<00:13, 39.15s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6578654840589874/1 [00:37<00:13, 40.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6613988524884974/1 [00:37<00:12, 36.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6641937355549264/1 [00:37<00:12, 37.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6669090894284084/1 [00:37<00:13, 40.02s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6699198374471227/1 [00:37<00:12, 38.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6731691730446785/1 [00:38<00:11, 36.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  90% 0.8973559866633392/1 [00:38<00:00,  2.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6759754174243857/1 [00:38<00:12, 37.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :   0% 0.00030184652548561843/1 [00:38<35:04:55, 126333.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6787021326111459/1 [00:38<00:12, 37.64s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :   7% 0.06821731475974976/1 [00:38<06:06, 393.29s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6813834025447932/1 [00:38<00:12, 40.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.68388289146599/1 [00:38<00:14, 47.19s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6860983475552326/1 [00:38<00:16, 52.47s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6882001905116936/1 [00:38<00:16, 51.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6904951757938833/1 [00:38<00:15, 49.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6927674384495167/1 [00:38<00:14, 47.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6949147266590903/1 [00:39<00:15, 49.64s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.6969711243624385/1 [00:39<00:15, 52.31s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.6989252702462833/1 [00:39<00:15, 52.44s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.7008566935035717/1 [00:39<00:16, 54.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.7030835109060924/1 [00:39<00:15, 53.76s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.70495812759699/1 [00:39<00:15, 53.78s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7068668282277221/1 [00:39<00:16, 55.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7090709230036865/1 [00:39<00:15, 54.14s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7111954885867037/1 [00:39<00:15, 53.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7136268096282314/1 [00:40<00:14, 51.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7485855705851516/1 [00:41<00:09, 39.37s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | : 100% 1.0/1 [00:41<00:00,  2.42s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7511645886992956/1 [00:41<00:12, 48.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7536186323673797/1 [00:42<00:11, 46.54s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [00:42<00:00,  2.95s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7585153583902696/1 [00:42<00:08, 34.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7615942742886529/1 [00:42<00:08, 34.24s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  15% 0.15269996945256728/1 [00:42<02:16, 160.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  30% 0.30369583641060405/1 [00:42<00:56, 80.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7646731901870363/1 [00:42<00:09, 39.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  44% 0.4410973353363319/1 [00:42<00:25, 46.23s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  77% 0.7674112666870745/1 [00:42<00:09, 41.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  38% 0.37698907008035665/1 [00:42<00:22, 35.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  77% 0.7702515950066162/1 [00:42<00:09, 39.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  72% 0.7248892162950782/1 [00:42<00:05, 18.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  77% 0.7728646970605947/1 [00:42<00:09, 40.88s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  88% 0.8751319768026496/1 [00:42<00:01, 12.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  78% 0.7754209925481823/1 [00:42<00:09, 40.42s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  78% 0.7790566127971957/1 [00:42<00:08, 36.56s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  78% 0.7818401345503467/1 [00:43<00:08, 37.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  78% 0.7845668497371068/1 [00:43<00:09, 44.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  79% 0.7873730941168141/1 [00:43<00:08, 41.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  79% 0.7906792362807608/1 [00:43<00:07, 38.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  79% 0.7945761667351721/1 [00:43<00:06, 33.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  80% 0.7976664439468335/1 [00:43<00:06, 33.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :  27% 0.2732890077381313/1 [00:43<01:21, 111.91s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "dgl-2.1.0.cu118      | 577.9 MB  | : 100% 1/1 [00:43<00:00, 43.65s/it]\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  80% 0.8007112759053823/1 [00:43<00:06, 34.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.8         | 17.0 MB   | :   0% 0.0009214636176254438/1 [00:43<13:10:13, 47456.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  80% 0.8038924436232691/1 [00:43<00:06, 33.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.8         | 17.0 MB   | :  25% 0.25432395846462247/1 [00:43<01:30, 120.89s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  81% 0.8069145529552615/1 [00:43<00:06, 36.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  81% 0.809743519961525/1 [00:44<00:07, 39.08s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :  97% 0.9703740129832198/1 [00:44<00:00, 18.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  81% 0.8123679833287817/1 [00:44<00:07, 40.56s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  82% 0.8175373808703477/1 [00:44<00:07, 39.92s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  82% 0.8206049354554529/1 [00:44<00:06, 37.68s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :   0% 0.0009221176422649559/1 [00:44<13:23:18, 48242.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | : 100% 1.0/1 [00:44<00:00, 18.60s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  82% 0.8232862053891002/1 [00:44<00:06, 39.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :   0% 0.000997983748775134/1 [00:44<12:24:23, 44707.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  83% 0.825853862189966/1 [00:44<00:06, 39.72s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  20% 0.20159271725257705/1 [00:44<02:04, 155.66s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.8         | 17.0 MB   | : 100% 1.0/1 [00:44<00:00, 21.33s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :   0% 0.001016089426288399/1 [00:44<12:14:12, 44097.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  83% 0.8283874350509973/1 [00:44<00:07, 42.57s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  40% 0.4001914832588287/1 [00:44<00:38, 64.96s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  22% 0.2204914055045826/1 [00:44<01:51, 142.92s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :  75% 0.7469152902346143/1 [00:44<00:06, 23.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  83% 0.8307733108394124/1 [00:44<00:07, 46.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  43% 0.4348862744514348/1 [00:45<00:33, 60.07s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :  91% 0.9073637599887167/1 [00:45<00:01, 16.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  83% 0.8335000260261725/1 [00:45<00:07, 44.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  84% 0.8368402521299536/1 [00:45<00:06, 40.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  84% 0.8428731094806603/1 [00:45<00:05, 37.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  85% 0.8456225472939768/1 [00:45<00:05, 37.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [00:45<00:00, 18.89s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  85% 0.8485196821799094/1 [00:45<00:05, 36.63s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | : 100% 1.0/1 [00:45<00:00, 21.28s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  85% 0.8512691199932259/1 [00:45<00:05, 36.88s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  86% 0.8601763896033088/1 [00:46<00:04, 34.99s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  86% 0.8636756740929843/1 [00:46<00:04, 33.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [00:46<00:00, 21.63s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  96% 0.9558613700320321/1 [00:49<00:01, 30.75s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [01:07<00:00, 21.99s/it]               \n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.2.0    | 177.1 MB  | : 100% 1.0/1 [01:30<00:00,  4.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcublas-12.1.0.26  | 329.0 MB  | : 100% 1.0/1 [02:04<00:00, 55.21s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | : 100% 1.0/1 [02:04<00:00,  8.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mkl-2022.1.0         | 129.7 MB  | : 100% 1.0/1 [02:10<00:00,  4.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | : 100% 1.0/1 [02:33<00:00,  3.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | : 100% 1.0/1 [02:35<00:00,  5.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | : 100% 1.0/1 [02:44<00:00,  2.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | : 100% 1.0/1 [02:46<00:00, 12.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [03:15<00:00,  2.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | : 100% 1.0/1 [03:16<00:00,  3.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | : 100% 1.0/1 [03:23<00:00, 18.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.8         | 17.0 MB   | : 100% 1.0/1 [03:25<00:00, 21.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | : 100% 1.0/1 [03:29<00:00, 16.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [03:30<00:00, 18.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | : 100% 1.0/1 [03:35<00:00, 21.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [03:39<00:00, 21.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | : 100% 1.0/1 [04:30<00:00, 20.56s/it]\u001b[A\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [08:42<00:00, 21.99s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Installing pip dependencies: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n",
            "['/usr/local/miniconda/envs/graphany/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/GraphAny/condaenv.vdfhqhra.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting ogb (from -r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1))\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting rootutils (from -r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 2))\n",
            "  Downloading rootutils-1.0.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting hydra_colorlog (from -r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 3))\n",
            "  Downloading hydra_colorlog-1.2.0-py3-none-any.whl.metadata (949 bytes)\n",
            "Collecting codetiming (from -r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 4))\n",
            "  Downloading codetiming-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting humanfriendly (from -r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting torch_frame (from -r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading torch_frame-1.7.5-py3-none-any.whl.metadata (763 bytes)\n",
            "Collecting pytorch-frame[full] (from -r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading pytorch_frame-0.2.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (1.6.1)\n",
            "Collecting pandas>=0.24.0 (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1))\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2.3.0)\n",
            "Collecting outdated>=0.2.0 (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1))\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting python-dotenv>=0.20.0 (from rootutils->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 2))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting colorlog (from hydra_colorlog->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 3))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra_colorlog->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 3)) (1.3.2)\n",
            "Collecting termcolor (from torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opencv-python (from torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tabulate (from torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting transformers>=4.25.1 (from torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting accelerate>=0.16.0 (from torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diffusers (from torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6)) (6.0.2)\n",
            "Collecting pyarrow (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (9.4.0)\n",
            "Collecting xgboost<2.0.0,>=1.7.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting optuna>=3.0.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting optuna-integration (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading optuna_integration-4.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (1.3.0)\n",
            "Collecting catboost (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting lightgbm (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting datasets (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (1.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6)) (7.0.0)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 3)) (4.9.3)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (75.8.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1))\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2025.1)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1))\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2025.3.0)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting graphviz (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting matplotlib (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy>=1.16.0 (from ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting plotly (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from diffusers->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6)) (8.6.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torchmetrics->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (0.14.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (1.18.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (2025.1.31)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from importlib-metadata->diffusers->torch_frame->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 6)) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 1)) (3.0.2)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7)) (3.2.1)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.vdfhqhra.requirements.txt (line 7))\n",
            "  Downloading narwhals-1.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "Downloading rootutils-1.0.7-py3-none-any.whl (6.4 kB)\n",
            "Downloading hydra_colorlog-1.2.0-py3-none-any.whl (3.6 kB)\n",
            "Downloading codetiming-1.4.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading torch_frame-1.7.5-py3-none-any.whl (46 kB)\n",
            "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 145.0 MB/s eta 0:00:00\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.0/10.0 MB 141.4 MB/s eta 0:00:00\n",
            "Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.3/200.3 MB 65.4 MB/s eta 0:00:00\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.7/98.7 MB 58.8 MB/s eta 0:00:00\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 178.9 MB/s eta 0:00:00\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 53.1 MB/s eta 0:00:00\n",
            "Downloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 97.9 MB/s eta 0:00:00\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 109.8 MB/s eta 0:00:00\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.0/63.0 MB 56.7 MB/s eta 0:00:00\n",
            "Downloading optuna_integration-4.2.1-py3-none-any.whl (97 kB)\n",
            "Downloading pytorch_frame-0.2.5-py3-none-any.whl (144 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 kB 34.9 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 97.9 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 100.2 MB/s eta 0:00:00\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 144.1 MB/s eta 0:00:00\n",
            "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.8/14.8 MB 138.4 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 118.4 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 599.5/599.5 kB 27.2 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 71.8 MB/s eta 0:00:00\n",
            "Downloading narwhals-1.29.1-py3-none-any.whl (308 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: xxhash, tzdata, termcolor, tabulate, safetensors, regex, python-dotenv, pyarrow, numpy, narwhals, Mako, littleutils, kiwisolver, humanfriendly, greenlet, graphviz, fsspec, fonttools, dill, cycler, colorlog, codetiming, sqlalchemy, rootutils, plotly, pandas, outdated, opencv-python, multiprocess, huggingface-hub, contourpy, xgboost, tokenizers, pytorch-frame, matplotlib, lightgbm, hydra_colorlog, diffusers, alembic, accelerate, transformers, optuna, ogb, catboost, torch_frame, optuna-integration, datasets\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.3\n",
            "    Uninstalling numpy-2.2.3:\n",
            "      Successfully uninstalled numpy-2.2.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "Successfully installed Mako-1.3.9 accelerate-1.4.0 alembic-1.15.1 catboost-1.2.7 codetiming-1.4.0 colorlog-6.9.0 contourpy-1.3.1 cycler-0.12.1 datasets-3.3.2 diffusers-0.32.2 dill-0.3.8 fonttools-4.56.0 fsspec-2024.12.0 graphviz-0.20.3 greenlet-3.1.1 huggingface-hub-0.29.2 humanfriendly-10.0 hydra_colorlog-1.2.0 kiwisolver-1.4.8 lightgbm-4.6.0 littleutils-0.2.4 matplotlib-3.10.1 multiprocess-0.70.16 narwhals-1.29.1 numpy-1.26.4 ogb-1.3.6 opencv-python-4.11.0.86 optuna-4.2.1 optuna-integration-4.2.1 outdated-0.2.2 pandas-2.2.3 plotly-6.0.0 pyarrow-19.0.1 python-dotenv-1.0.1 pytorch-frame-0.2.5 regex-2024.11.6 rootutils-1.0.7 safetensors-0.5.3 sqlalchemy-2.0.38 tabulate-0.9.0 termcolor-2.5.0 tokenizers-0.21.0 torch_frame-1.7.5 transformers-4.49.0 tzdata-2025.1 xgboost-1.7.6 xxhash-3.5.0\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate graphany\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'name': 'graphany',\n",
        "    'channels': [\n",
        "        'pytorch',\n",
        "        'pyg',\n",
        "        'nvidia',\n",
        "        'conda-forge',\n",
        "        'defaults',\n",
        "        'dglteam/label/cu118'\n",
        "    ],\n",
        "    'dependencies': [\n",
        "        'python=3.10',\n",
        "        'cudatoolkit=11.8',\n",
        "        'pyg',\n",
        "        'pytorch=2.2.1',\n",
        "        'torchvision',\n",
        "        'torchaudio',\n",
        "        'torchdata=0.7.1',\n",
        "        'dgl',\n",
        "        'lightning=2.*',\n",
        "        'pydantic',\n",
        "        'wandb',\n",
        "        'rich',\n",
        "        'hydra-core',\n",
        "        'jupyter',\n",
        "        'einops',\n",
        "        'tensorboard',\n",
        "        'pip',\n",
        "        {\n",
        "            'pip': [\n",
        "                'ogb',\n",
        "                'rootutils',\n",
        "                'hydra_colorlog',\n",
        "                # For time logging\n",
        "                'codetiming',\n",
        "                'humanfriendly',\n",
        "                'torch_frame',\n",
        "                'pytorch-frame[full]'\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "sys.path.insert(0,'/content/GraphAny')\n",
        "\n",
        "\n",
        "with open('GraphAny/environment.yaml', 'w') as file:\n",
        "    yaml.dump(data, file)\n",
        "\n",
        "\n",
        "\n",
        "!wget -O Miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda.sh -b -p /usr/local/miniconda\n",
        "\n",
        "os.environ['PATH'] = '/usr/local/miniconda/bin:' + os.environ['PATH']\n",
        "\n",
        "!conda update conda -y -q\n",
        "!source /usr/local/etc/profile.d/conda.sh\n",
        "!conda init\n",
        "!conda install -n root _license -y -q\n",
        "\n",
        "!conda env create -f GraphAny/environment.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwHPwzzJfr1y",
        "outputId": "651eba11-bebf-4768-d771-e780f84ac967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '/env/python', '/usr/local/miniconda/envs/graphany/lib/python310.zip', '/usr/local/miniconda/envs/graphany/lib/python3.10', '/usr/local/miniconda/envs/graphany/lib/python3.10/lib-dynload', '/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages', '/usr/local/lib/python3.10/site-packages']\n",
            "Python version\n",
            "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate graphany\n",
        "\n",
        "python\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "# some simple python commands\n",
        "sys.path.append('/usr/local/lib/python3.10/site-packages')\n",
        "print(sys.path)\n",
        "# we chekc the python version and system paths\n",
        "print(\"Python version\")\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes colab needs to upload again the channels, so we need to do that manually one more time using bash command lines."
      ],
      "metadata": {
        "id": "O3evmNNMMkdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda config --add channels pytorch\n",
        "!source activate graphany && conda config --add channels pyg\n",
        "!source activate graphany && conda config --add channels nvidia\n",
        "!source activate graphany && conda config --add channels conda-forge\n",
        "!source activate graphany && conda config --add channels dglteam/label/cu118"
      ],
      "metadata": {
        "id": "ENRRADzupiU6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can check all the dependencies of torch inside conda. This is important because there are some conflicts between dgl, torchdata, torchaudio and torchtriton most recent versions.\n",
        "\n",
        "Thus make sure to have the correct versions of the following dependencies."
      ],
      "metadata": {
        "id": "4xnaE-DnMwo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda list torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBhCyXx32AXi",
        "outputId": "c7473e07-8639-4755-fa0f-f960aed42d55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# packages in environment at /usr/local/miniconda/envs/graphany:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "pytorch                   2.2.1           py3.10_cuda12.1_cudnn8.9.2_0    pytorch\n",
            "pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n",
            "pytorch-frame             0.2.5                    pypi_0    pypi\n",
            "pytorch-lightning         2.5.0.post0        pyh101cb37_0    conda-forge\n",
            "pytorch-mutex             1.0                        cuda    pytorch\n",
            "torch-frame               1.7.5                    pypi_0    pypi\n",
            "torchaudio                2.2.1               py310_cu121    pytorch\n",
            "torchdata                 0.7.1                     py310    pytorch\n",
            "torchmetrics              1.6.2              pyhd8ed1ab_0    conda-forge\n",
            "torchtriton               2.2.0                     py310    pytorch\n",
            "torchvision               0.17.1              py310_cu121    pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Usefull functions"
      ],
      "metadata": {
        "id": "4EGxwH6Yg2Cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we are going to define some functions that we will use in the following."
      ],
      "metadata": {
        "id": "kIuRTmM9NdrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch"
      ],
      "metadata": {
        "id": "vZfe0jcFg2bA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_comparison_file(download_path, output_file):\n",
        "    \"\"\"\n",
        "    Build a comparison file from the data loaded from a pickle file.\n",
        "\n",
        "    Parameters:\n",
        "    - download_path (str): Path to the input pickle file containing the data.\n",
        "    - output_file (str): Path to the output CSV file where node information will be saved.\n",
        "\n",
        "    Returns:\n",
        "    - labels (torch.Tensor): Tensor containing the labels for the nodes.\n",
        "    - node_features (torch.Tensor): Tensor containing the features for the nodes.\n",
        "    - train_mask (torch.Tensor): Tensor indicating the training nodes.\n",
        "    - val_mask (torch.Tensor): Tensor indicating the validation nodes.\n",
        "    - test_mask (torch.Tensor): Tensor indicating the test nodes.\n",
        "    - val_nodes (list): List of nodes in the validation set.\n",
        "    - test_nodes (list): List of nodes in the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    train_mask = torch.tensor(data['train_mask'])\n",
        "    val_mask = torch.tensor(data['val_mask'])\n",
        "    test_mask = torch.tensor(data['test_mask'])\n",
        "\n",
        "    val_nodes = []\n",
        "    test_nodes = []\n",
        "\n",
        "    # Writing nodes and their respective classes in the test set\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"Node,Class,Split\\n\")  # Header of the file\n",
        "        for node in range(len(test_mask)):\n",
        "            if val_mask[node]:\n",
        "                val_nodes.append(node)\n",
        "                f.write(f\"{node},{labels[node].item()},val\\n\")  # Write node and class\n",
        "            if test_mask[node]:\n",
        "                test_nodes.append(node)\n",
        "                f.write(f\"{node},{labels[node].item()},test\\n\")  # Write node and class\n",
        "\n",
        "    return labels, node_features, train_mask, val_mask, test_mask, val_nodes, test_nodes\n"
      ],
      "metadata": {
        "id": "_8vY40Ysg7p9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_AUROC(file_path, true_labels, val_nodes, test_nodes, auroc_labels):\n",
        "    \"\"\"\n",
        "    Compute the AUROC for validation and test predictions.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): Path to the input file containing prediction scores.\n",
        "    - true_labels (list): List of true labels for all nodes.\n",
        "    - val_nodes (list): List of nodes in the validation set.\n",
        "    - test_nodes (list): List of nodes in the test set.\n",
        "    - auroc_labels (list): List of class labels for which to compute AUROC.\n",
        "\n",
        "    Returns:\n",
        "    - average_val_auroc (float): Average One-vs-Rest AUROC for the validation set.\n",
        "    - average_test_auroc (float): Average One-vs-Rest AUROC for the test set.\n",
        "    - binary_val_auroc (float): AUROC for the binary classification (0 vs 1) in the validation set.\n",
        "    - binary_test_auroc (float): AUROC for the binary classification (0 vs 1) in the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    val_scores = {}\n",
        "    test_scores = {}\n",
        "\n",
        "    n_val_nodes = len(val_nodes)\n",
        "    n_test_nodes = len(test_nodes)\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for index, line in enumerate(file):\n",
        "            parts = line.split(\"\\t\")\n",
        "            node = int(parts[0].split(':')[1])\n",
        "            prediction = [float(x) for x in parts[1].strip('Prediction:[]').split()]\n",
        "\n",
        "            if index < n_val_nodes:\n",
        "                val_scores[node] = prediction\n",
        "            elif index >= n_val_nodes and index < n_val_nodes + n_test_nodes:\n",
        "                test_scores[node] = prediction\n",
        "\n",
        "    # Select the validation and test true labels\n",
        "    true_val_labels = []\n",
        "    true_test_labels = []\n",
        "    for node in val_nodes:\n",
        "        true_val_labels.append(true_labels[node])\n",
        "    for node in test_nodes:\n",
        "        true_test_labels.append(true_labels[node])\n",
        "\n",
        "    ### COMPUTING One-vs-rest AUROC ###\n",
        "    # Validation AUROC\n",
        "    val_aurocs = []\n",
        "    for class_idx in auroc_labels:\n",
        "        true_binary = [1 if label == class_idx else 0 for label in true_val_labels]\n",
        "        pred_binary = [val_scores[node][class_idx] for node in val_nodes]\n",
        "        val_aurocs.append(roc_auc_score(true_binary, pred_binary))\n",
        "\n",
        "    # Test AUROC\n",
        "    test_aurocs = []\n",
        "    for class_idx in auroc_labels:\n",
        "        true_binary = [1 if label == class_idx else 0 for label in true_test_labels]\n",
        "        pred_binary = [test_scores[node][class_idx] for node in test_nodes]\n",
        "        test_aurocs.append(roc_auc_score(true_binary, pred_binary))\n",
        "\n",
        "    # One-vs-rest AUROC\n",
        "    average_val_auroc = sum(val_aurocs) / len(val_aurocs) if val_aurocs else 0\n",
        "    average_test_auroc = sum(test_aurocs) / len(test_aurocs) if test_aurocs else 0\n",
        "\n",
        "    ### COMPUTING binary AUROC ####\n",
        "    b_true_val_labels = []\n",
        "    b_true_test_labels = []\n",
        "    b_val_pred = []\n",
        "    b_test_pred = []\n",
        "\n",
        "    # Validation AUROC\n",
        "    for node in val_nodes:  # Only consider nodes that should be classified as 0 or 1\n",
        "        if true_labels[node] in [0, 1]:\n",
        "            b_true_val_labels.append(true_labels[node])\n",
        "            # Take only the probabilities for class 0 and 1, and normalize them\n",
        "            prob_0_1 = val_scores[node][:2]\n",
        "            prob_sum = sum(prob_0_1)\n",
        "            b_val_pred.append(prob_0_1[1] / prob_sum)  # Probability for class 1\n",
        "\n",
        "    # Test AUROC\n",
        "    for node in test_nodes:  # Only consider nodes that should be classified as 0 or 1\n",
        "        if true_labels[node] in [0, 1]:\n",
        "            b_true_test_labels.append(true_labels[node])\n",
        "            # Take only the probabilities for class 0 and 1, and normalize them\n",
        "            prob_0_1 = test_scores[node][:2]\n",
        "            prob_sum = sum(prob_0_1)\n",
        "            b_test_pred.append(prob_0_1[1] / prob_sum)  # Probability for class 1\n",
        "\n",
        "    # Binary AUROC\n",
        "    binary_val_auroc = roc_auc_score(b_true_val_labels, b_val_pred) if b_val_pred else 0\n",
        "    binary_test_auroc = roc_auc_score(b_true_test_labels, b_test_pred) if b_test_pred else 0\n",
        "\n",
        "    return average_val_auroc, average_test_auroc, binary_val_auroc, binary_test_auroc\n"
      ],
      "metadata": {
        "id": "zrrmrIKhhAVa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_file_content(file_path):\n",
        "    \"\"\"\n",
        "    Check if the file exists and clear its content if it does.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): Path to the file to be checked and cleared.\n",
        "    \"\"\"\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.truncate()  # Clear the file content\n",
        "        print(f\"The content of the file '{file_path}' has been cleared.\")"
      ],
      "metadata": {
        "id": "CpShFg-9IcZk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing code in `run.py`"
      ],
      "metadata": {
        "id": "m7PB7ToSD9mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we want to obtain also the predictions performed by GraphAny on validation and test sets, we are going to change the code inside the `run.py` script.\n",
        "\n",
        "In particular, we are going to append the predictions on a specific file which is going to be built inside our workspace."
      ],
      "metadata": {
        "id": "XF3jxLQ2GnjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import rootutils\n",
        "\n",
        "root = rootutils.setup_root(__file__, dotenv=True, pythonpath=True, cwd=False)\n",
        "from graphany.utils import logger, timer\n",
        "from graphany.utils.experiment import init_experiment\n",
        "from graphany.data import GraphDataset, CombinedDataset\n",
        "from graphany.model import GraphAny\n",
        "\n",
        "import torch\n",
        "import hydra\n",
        "from omegaconf import DictConfig\n",
        "import wandb\n",
        "import numpy as np\n",
        "import torchmetrics\n",
        "from rich.pretty import pretty_repr\n",
        "\n",
        "import os\n",
        "\n",
        "mean = lambda input: np.round(np.mean(input).item(), 2)\n",
        "\n",
        "\n",
        "class InductiveNodeClassification(pl.LightningModule):\n",
        "    def __init__(self, cfg, combined_dataset, checkpoint=None):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if checkpoint:\n",
        "            # Initialize from previous checkpoint using previous graphany config\n",
        "            ckpt = torch.load(checkpoint, map_location=\"cpu\")\n",
        "            logger.critical(f\"Loaded checkpoint at {checkpoint}\")\n",
        "            self.gnn_model = GraphAny(**ckpt[\"graph_any_config\"])\n",
        "            self.load_state_dict(ckpt[\"state_dict\"])\n",
        "        else:\n",
        "            self.gnn_model = GraphAny(**cfg.graph_any)\n",
        "        self.combined_dataset = combined_dataset\n",
        "        self.attn_dict, self.loss_dict, self.res_dict = {}, {}, {}\n",
        "        # Initialize accuracy metrics for validation and testing\n",
        "        self.metrics = {}\n",
        "        held_out_datasets = list(\n",
        "            set(self.cfg._all_datasets) - set(self.cfg._trans_datasets)\n",
        "        )  # 27 datasets in total\n",
        "        self.heldout_metrics = [\n",
        "            f\"{setting}/{d.lower()[:4]}_{split}_acc\"\n",
        "            for split in [\"val\", \"test\"]\n",
        "            for d in held_out_datasets\n",
        "            for setting in [\"trans\", \"ind\"]\n",
        "        ]\n",
        "        for split in (\"val\", \"test\"):\n",
        "            self.metrics[split] = {\n",
        "                k: torchmetrics.Accuracy(task=\"multiclass\", num_classes=v.num_class)\n",
        "                for k, v in combined_dataset.eval_ds_dict.items()\n",
        "            }\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def on_train_end(self):\n",
        "        checkpoint_path = f\"{self.cfg.dirs.output}{self.cfg.dataset}_val_acc={self.res_dict['val_acc']}.pt\"\n",
        "        self.save_checkpoint(checkpoint_path)\n",
        "\n",
        "    def save_checkpoint(self, file_path):\n",
        "        checkpoint = {\n",
        "            \"state_dict\": self.state_dict(),\n",
        "            \"optimizer_state_dict\": [\n",
        "                opt.state_dict() for opt in self.trainer.optimizers\n",
        "            ],\n",
        "            \"graph_any_config\": self.cfg.graph_any,\n",
        "        }\n",
        "        torch.save(checkpoint, file_path)\n",
        "        logger.critical(f\"Checkpoint saved to {file_path}\")\n",
        "\n",
        "    def get_metric_name(self, ds_name, split):\n",
        "        if ds_name in self.cfg.train_datasets:\n",
        "            return f\"trans/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "        else:\n",
        "            return f\"ind/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # start with all the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {\"params\": decay_params, \"weight_decay\": self.cfg.weight_decay},\n",
        "            {\"params\": nodecay_params, \"weight_decay\": 0.0},\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        logger.info(\n",
        "            f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\"\n",
        "        )\n",
        "        logger.info(\n",
        "            f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.optimizer == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=self.cfg.lr)\n",
        "        else:  # AdamW\n",
        "            optimizer = torch.optim.AdamW(\n",
        "                optim_groups,\n",
        "                lr=self.cfg.lr,\n",
        "                weight_decay=self.cfg.weight_decay,\n",
        "            )\n",
        "        return optimizer\n",
        "\n",
        "    def on_fit_start(self):\n",
        "        super().on_fit_start()\n",
        "        # move all datasets to the correct GPU device\n",
        "        print(f\"moving train and eval datasets to {self.device}\")\n",
        "        self.combined_dataset.to(self.device)\n",
        "        self.move_metrics_to_device()\n",
        "\n",
        "    def move_metrics_to_device(self):\n",
        "        for metrics_dict in self.metrics.values():\n",
        "            for metric in metrics_dict.values():\n",
        "                metric.to(self.device)\n",
        "\n",
        "    def predict(self, ds, nodes, input, is_training=False):\n",
        "        # Use preprocessed distance during evaluation\n",
        "        dist = ds.dist if not is_training else None\n",
        "        dist = dist.to(nodes.device)[nodes] if dist is not None else dist\n",
        "\n",
        "        preds, attn = self.gnn_model(\n",
        "            {c: chn_pred[nodes] for c, chn_pred in input.items()}, dist=dist\n",
        "        )\n",
        "\n",
        "        self.attn_dict.update(\n",
        "            {\n",
        "                f\"Attention/{ds.name}-{c}\": v\n",
        "                for c, v in zip(self.cfg.feat_channels, attn)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        def softmax(logits):\n",
        "          exp_logits = np.exp(logits - np.max(logits))\n",
        "          return exp_logits / exp_logits.sum(axis=0)\n",
        "\n",
        "        # Scrittura delle predizioni in un file\n",
        "        with open(\"predictions.txt\", \"a\") as file:  # Modalità append\n",
        "            for node, pred in zip(nodes.cpu().numpy(), preds.cpu().numpy()):\n",
        "                line = f\"Node:{node}\\tPrediction:{pred}\\tClass:{np.argmax(softmax(pred))}\"\n",
        "                file.write(line + os.linesep)  # Scrive il nodo e la predizione\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        loss = {}\n",
        "        for ds_name, batch_nodes in batch.items():\n",
        "            ds = self.combined_dataset.train_ds_dict[ds_name]\n",
        "            train_target_idx = batch_nodes\n",
        "            # Batch nodes are not visible to avoid trivial solution and overfitting\n",
        "            visible_nodes = list(\n",
        "                set(ds.train_indices.tolist()) - set(batch_nodes.tolist())\n",
        "            )\n",
        "            ref_nodes = torch.tensor(visible_nodes, dtype=torch.long).to(self.device)\n",
        "            ds_too_small = len(visible_nodes) < len(batch_nodes)\n",
        "            if ds_too_small:\n",
        "                # Visible nodes are too few, add first half of the batch to visible nodes\n",
        "                ref_nodes = torch.cat((ref_nodes, batch_nodes[: len(batch_nodes) // 2]))\n",
        "\n",
        "            input = ds.compute_channel_logits(\n",
        "                ds.features, ref_nodes, sample=True, device=self.device\n",
        "            )\n",
        "\n",
        "            preds = self.predict(ds, train_target_idx, input, is_training=True)\n",
        "            loss[f\"loss/{ds_name}_loss\"] = self.criterion(\n",
        "                preds, ds.label[train_target_idx]\n",
        "            )\n",
        "\n",
        "        detached_loss = {k: v.detach().cpu() for k, v in loss.items()}\n",
        "        avg_loss = mean(list(detached_loss.values()))\n",
        "        self.loss_dict.update({\"loss/avg_loss\": avg_loss, **detached_loss})\n",
        "        return sum(loss.values())\n",
        "\n",
        "    def evaluation_step(self, split, batch, batch_idx):\n",
        "        self.move_metrics_to_device()\n",
        "        for ds_name, eval_idx in batch.items():\n",
        "            if eval_idx is None:  # Skip if dataset is already evaluated (empty batch)\n",
        "                continue\n",
        "            ds = self.combined_dataset.eval_ds_dict[ds_name]\n",
        "            ds.to(self.device)\n",
        "            eval_idx.to(self.device)\n",
        "            # Use unmasked feature for evaluation\n",
        "            processed_feat = ds.unmasked_pred\n",
        "            preds = self.predict(\n",
        "                ds, eval_idx, processed_feat, is_training=False\n",
        "            ).argmax(-1)\n",
        "            self.metrics[split][ds_name].update(preds, ds.label[eval_idx])\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"val\", batch, batch_idx)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"test\", batch, batch_idx)\n",
        "\n",
        "    def compute_and_log_metrics(self, split):\n",
        "        # Compute metrics from collected outputs\n",
        "        res = {}\n",
        "        for ds_name, metric in self.metrics[split].items():\n",
        "            metric_name = self.get_metric_name(ds_name, split)\n",
        "            accuracy = metric.compute().cpu().numpy()\n",
        "            res[metric_name] = np.round(accuracy * 100, 2)\n",
        "            metric.reset()  # Reset metrics for the next epoch\n",
        "\n",
        "        combined_res = {f\"{split}_acc\": np.round(sum(res.values()) / len(res), 2)}\n",
        "        combined_res[f\"trans_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"trans\")]\n",
        "        )\n",
        "        combined_res[f\"ind_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"ind\")]\n",
        "        )\n",
        "\n",
        "        combined_res[f\"heldout_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k in self.heldout_metrics]\n",
        "        )\n",
        "        self.log_dict(res, prog_bar=False, logger=True, add_dataloader_idx=False)\n",
        "        self.log_dict(\n",
        "            combined_res, prog_bar=True, logger=True, add_dataloader_idx=False\n",
        "        )\n",
        "        self.res_dict.update({**res, **combined_res})\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log_dict(self.loss_dict, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if len(self.attn_dict):\n",
        "            self.log_dict(self.attn_dict, on_epoch=True, prog_bar=False, logger=True)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"val\")\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"test\")\n",
        "\n",
        "\n",
        "@timer()\n",
        "@hydra.main(config_path=f\"{root}/configs\", config_name=\"main\", version_base=None)\n",
        "def main(cfg: DictConfig):\n",
        "    cfg, logger = init_experiment(cfg)\n",
        "    # Define the default step metric for all metrics\n",
        "    wandb.define_metric(\"*\", step_metric=\"epoch\")\n",
        "    if torch.cuda.is_available() and cfg.preprocess_device == \"gpu\":\n",
        "        preprocess_device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        preprocess_device = torch.device(\"cpu\")\n",
        "\n",
        "    def construct_ds_dict(datasets):\n",
        "        datasets = [datasets] if isinstance(datasets, str) else datasets\n",
        "        ds_dict = {\n",
        "            dataset: GraphDataset(\n",
        "                cfg,\n",
        "                dataset,\n",
        "                cfg.dirs.data_cache,\n",
        "                cfg.train_batch_size,\n",
        "                cfg.val_test_batch_size,\n",
        "                cfg.n_hops,\n",
        "                preprocess_device,\n",
        "            )\n",
        "            for dataset in datasets\n",
        "        }\n",
        "        return ds_dict\n",
        "\n",
        "    train_ds_dict = construct_ds_dict(cfg.train_datasets)\n",
        "    eval_ds_dict = construct_ds_dict(cfg.eval_datasets)\n",
        "\n",
        "    combined_dataset = CombinedDataset(train_ds_dict, eval_ds_dict, cfg)\n",
        "\n",
        "    model = InductiveNodeClassification(cfg, combined_dataset, cfg.get(\"prev_ckpt\"))\n",
        "    # Set up the checkpoint callback to save only at the end of training\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=cfg.dirs.output,  # specify where to save\n",
        "        filename=\"final_checkpoint.pt\",  # set a filename\n",
        "        save_top_k=0,  # do not save based on metric, just save last\n",
        "        save_last=True,  # ensures only the last checkpoint is kept\n",
        "        save_on_train_epoch_end=True,  # save at the end of training epoch\n",
        "    )\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=cfg.total_steps,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        limit_train_batches=cfg.limit_train_batches,\n",
        "        check_val_every_n_epoch=cfg.eval_freq,\n",
        "        logger=logger,\n",
        "        accelerator=\"gpu\" if torch.cuda.is_available() and cfg.gpus > 0 else \"cpu\",\n",
        "        default_root_dir=cfg.dirs.lightning_root,\n",
        "    )\n",
        "    dataloaders = {\n",
        "        \"train\": combined_dataset.train_dataloader(),\n",
        "        \"val\": combined_dataset.val_dataloader(),\n",
        "        \"test\": combined_dataset.test_dataloader(),\n",
        "    }\n",
        "    if cfg.total_steps > 0:\n",
        "        trainer.fit(\n",
        "            model,\n",
        "            train_dataloaders=dataloaders[\"train\"],\n",
        "            val_dataloaders=dataloaders[\"val\"],\n",
        "        )\n",
        "    trainer.validate(model, dataloaders=dataloaders[\"val\"])\n",
        "    trainer.test(model, dataloaders=dataloaders[\"test\"])\n",
        "    final_results = model.res_dict\n",
        "    logger.critical(pretty_repr(final_results))\n",
        "    logger.wandb_summary_update(final_results, finish_wandb=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ykTF4_rsELVw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_name = 'GraphAny/graphany/run.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ],
      "metadata": {
        "id": "F4mQkL2LEMCQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement the dataset interface and update `GraphDataset` class in `data.py`"
      ],
      "metadata": {
        "id": "EvOgmqmhPx5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we are going to implement the function `load_relbench_dataset`. Note that this function will not download the data from an online repository, instead we are going to use our current workspace.\n",
        "\n",
        "So, make sure to insert the `data.pkl` file inside the directory `\\data\\relbench`."
      ],
      "metadata": {
        "id": "NcXBb3MtTGFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import os.path\n",
        "import os.path as osp\n",
        "import re\n",
        "import ssl\n",
        "import sys\n",
        "import urllib\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "#from torch_frame import TensorFrame\n",
        "import requests\n",
        "\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import OmegaConf\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.manifold._utils import (\n",
        "    _binary_search_perplexity as sklearn_binary_search_perplexity,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from graphany.utils import logger, timer\n",
        "\n",
        "\n",
        "def get_entropy_normed_cond_gaussian_prob(X, entropy, metric=\"euclidean\"):\n",
        "\n",
        "    #Parameters\n",
        "    #----------\n",
        "    #X:              The matrix for pairwise similarity\n",
        "    #entropy:     Perplexity of the conditional prob distribution\n",
        "    #Returns the entropy-normalized conditional gaussian probability based on distances.\n",
        "    #-------\n",
        "\n",
        "\n",
        "    # Compute pairwise distances\n",
        "    perplexity = np.exp2(entropy)\n",
        "    distances = pdist(X, metric=metric)\n",
        "    distances = squareform(distances)\n",
        "\n",
        "    # Compute the squared distances\n",
        "    distances **= 2\n",
        "    distances = distances.astype(np.float32)\n",
        "    return sklearn_binary_search_perplexity(distances, perplexity, verbose=0)\n",
        "\n",
        "\n",
        "def sample_k_nodes_per_label(label, visible_nodes, k, num_class):\n",
        "    ref_node_idx = [\n",
        "        (label[visible_nodes] == lbl).nonzero().view(-1) for lbl in range(num_class)\n",
        "    ]\n",
        "    sampled_indices = [\n",
        "        label_indices[torch.randperm(len(label_indices))[:k]]\n",
        "        for label_indices in ref_node_idx\n",
        "    ]\n",
        "    return visible_nodes[torch.cat(sampled_indices)]\n",
        "\n",
        "\n",
        "def get_data_split_masks(n_nodes, labels, num_train_nodes, label_idx=None, seed=42):\n",
        "    label_idx = np.arange(n_nodes)\n",
        "    test_rate_in_labeled_nodes = (len(labels) - num_train_nodes) / len(labels)\n",
        "    train_idx, test_and_valid_idx = train_test_split(\n",
        "        label_idx,\n",
        "        test_size=test_rate_in_labeled_nodes,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels,\n",
        "    )\n",
        "    valid_idx, test_idx = train_test_split(\n",
        "        test_and_valid_idx,\n",
        "        test_size=0.5,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels[test_and_valid_idx],\n",
        "    )\n",
        "    train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[train_idx] = True\n",
        "    val_mask[valid_idx] = True\n",
        "    test_mask[test_idx] = True\n",
        "\n",
        "    return train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def download_url(url: str, folder: str, log: bool = True, filename=None):\n",
        "    #Modified from torch_geometric.data.download_url\n",
        "\n",
        "    #Downloads the content of an URL to a specific folder.\n",
        "\n",
        "    #Args:\n",
        "        #url (str): The URL.\n",
        "        #folder (str): The folder.\n",
        "        #log (bool, optional): If :obj:`False`, will not print anything to the\n",
        "            #console. (default: :obj:`True`)\n",
        "\n",
        "\n",
        "    if filename is None:\n",
        "        filename = url.rpartition(\"/\")[2]\n",
        "        filename = filename if filename[0] == \"?\" else filename.split(\"?\")[0]\n",
        "\n",
        "    path = osp.join(folder, filename)\n",
        "\n",
        "    if osp.exists(path):  # pragma: no cover\n",
        "        if log and \"pytest\" not in sys.modules:\n",
        "            print(f\"Using existing file {filename}\", file=sys.stderr)\n",
        "        return path\n",
        "\n",
        "    if log and \"pytest\" not in sys.modules:\n",
        "        print(f\"Downloading {url}\", file=sys.stderr)\n",
        "\n",
        "    os.makedirs(osp.expanduser(osp.normpath(folder)), exist_ok=True)\n",
        "\n",
        "    context = ssl._create_unverified_context()\n",
        "    data = urllib.request.urlopen(url, context=context)\n",
        "\n",
        "    with open(path, \"wb\") as f:\n",
        "        # workaround for https://bugs.python.org/issue42853\n",
        "        while True:\n",
        "            chunk = data.read(10 * 1024 * 1024)\n",
        "            if not chunk:\n",
        "                break\n",
        "            f.write(chunk)\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "'''\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url, raw_dir)\n",
        "    download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "'''\n",
        "\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url[0], raw_dir)\n",
        "    # download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(raw_dir, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def load_heterophilous_dataset(url, raw_dir):\n",
        "    # Wrap Heterophilous to DGL Graph Dataset format https://arxiv.org/pdf/2302.11640.pdf\n",
        "    download_path = download_url(url, raw_dir)\n",
        "    data = np.load(download_path)\n",
        "    node_features = torch.tensor(data[\"node_features\"])\n",
        "    labels = torch.tensor(data[\"node_labels\"])\n",
        "    edges = torch.tensor(data[\"edges\"])\n",
        "\n",
        "    graph = dgl.graph(\n",
        "        (edges[:, 0], edges[:, 1]), num_nodes=len(node_features), idtype=torch.int\n",
        "    )\n",
        "    num_classes = len(labels.unique())\n",
        "    num_targets = 1 if num_classes == 2 else num_classes\n",
        "    if num_targets == 1:\n",
        "        labels = labels.float()\n",
        "    train_masks = torch.tensor(data[\"train_masks\"]).T\n",
        "    val_masks = torch.tensor(data[\"val_masks\"]).T\n",
        "    test_masks = torch.tensor(data[\"test_masks\"]).T\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_masks, val_masks, test_masks\n",
        "\n",
        "\n",
        "class CombinedDataset(pl.LightningDataModule):\n",
        "    def __init__(self, train_ds_dict, eval_ds_dict, cfg):\n",
        "        super().__init__()\n",
        "        self.train_ds_dict = train_ds_dict\n",
        "        self.eval_ds_dict = eval_ds_dict\n",
        "        self.all_ds = list(self.train_ds_dict.values()) + list(\n",
        "            self.eval_ds_dict.values()\n",
        "        )\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def to(self, device):\n",
        "        for ds in self.all_ds:\n",
        "            ds.to(device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.train_dataloader() for name, ds in self.train_ds_dict.items()\n",
        "        }\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"min_size\")\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.val_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.test_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "\n",
        "class GraphDataset(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            cfg,\n",
        "            ds_name,\n",
        "            cache_dir,\n",
        "            train_batch_size=256,\n",
        "            val_test_batch_size=256,\n",
        "            n_hops=1,\n",
        "            preprocess_device=torch.device(\"cpu\"),\n",
        "            permute_label=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.name = ds_name\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.permute_label = permute_label  # For checking label equivariance\n",
        "        self.val_test_batch_size = val_test_batch_size\n",
        "        self.preprocess_device = preprocess_device\n",
        "\n",
        "        self.n_hops = n_hops\n",
        "\n",
        "        self.data_source, ds_alias = cfg[\"_ds_meta_data\"][ds_name].split(\", \")\n",
        "        self.gidtype = None\n",
        "        self.dist = None\n",
        "        self.unmasked_pred = None\n",
        "        if self.data_source == \"pyg\":\n",
        "            components = ds_alias.split(\".\")\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"torch_geometric.datasets.{ds_alias}\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}/\",\n",
        "            }\n",
        "            if len(components) == 2:  # If sub-dataset\n",
        "                ds_init_args[\"_target_\"] = f\"torch_geometric.datasets.{components[0]}\"\n",
        "                ds_init_args[\"name\"] = components[1]\n",
        "        elif self.data_source == \"dgl\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"dgl.data.{ds_alias}\",\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "            }\n",
        "        elif self.data_source == \"ogb\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"ogb.nodeproppred.DglNodePropPredDataset\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"name\": ds_alias,\n",
        "            }\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            target = \"graphany.data.load_heterophilous_dataset\"\n",
        "            url = f\"https://raw.githubusercontent.com/yandex-research/heterophilous-graphs/main/data/{ds_alias}.npz\"\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"url\": url,\n",
        "            }\n",
        "        elif self.data_source == \"relbench\":\n",
        "            target = \"graphany.data.load_relbench_dataset\"\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}.pkl\",\n",
        "                \"url\" : \"\",\n",
        "            }\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        self.data_init_args = OmegaConf.create(ds_init_args)\n",
        "        # self.cache_f_name = osp.join(\n",
        "        #     cache_dir, f'{self.name}_{n_hops}')\n",
        "        if cfg.get(\"feat_chn\"):\n",
        "            all_channels = \"+\".join([cfg.feat_chn, cfg.pred_chn])\n",
        "            all_hops = re.findall(r\"\\d+\", all_channels)\n",
        "            n_hops = max(max([int(_) for _ in all_hops]), n_hops)\n",
        "\n",
        "        self.split_index = 0\n",
        "        (\n",
        "            self.g,\n",
        "            self.label,\n",
        "            self.feat,\n",
        "            self.train_mask,\n",
        "            self.val_mask,\n",
        "            self.test_mask,\n",
        "            self.num_class,\n",
        "        ) = self.load_dataset(self.data_init_args)\n",
        "        self.n_nodes, self.n_edges = self.g.num_nodes(), self.g.num_edges()\n",
        "        self.cache_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}.pt\",\n",
        "        )\n",
        "\n",
        "        self.dist_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}_{cfg.feat_chn}_entropy={cfg.entropy}_dist.pt\",\n",
        "        )\n",
        "\n",
        "        self.gidtype = self.g.idtype\n",
        "        self.train_indices = self.train_mask.nonzero().view(-1)\n",
        "\n",
        "        (\n",
        "            self.features,\n",
        "            self.unmasked_pred,\n",
        "            self.dist,\n",
        "        ) = self.prepare_prop_features_logits_and_dist_features(\n",
        "            self.g, self.feat, n_hops=cfg.n_hops\n",
        "        )\n",
        "        # Remove the graph, as GraphAny doesn't use it in training\n",
        "        del self.g\n",
        "        del self.feat\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def to(self, device):  # Supports nested dictionary\n",
        "        def to_device(input):\n",
        "            if input is None:\n",
        "                return None\n",
        "            elif isinstance(input, dict):\n",
        "                return {key: to_device(value) for key, value in input.items()}\n",
        "            elif isinstance(input, list):\n",
        "                return [to_device(item) for item in input]\n",
        "            elif hasattr(input, \"to\"):\n",
        "                return input.to(device)\n",
        "            else:\n",
        "                return (\n",
        "                    input  # Return as is if it's not a tensor or any nested structure\n",
        "                )\n",
        "\n",
        "        # Apply to_device to all attributes that may contain tensors\n",
        "        attrs = [\n",
        "            \"label\",\n",
        "            \"feat\",\n",
        "            \"train_mask\",\n",
        "            \"val_mask\",\n",
        "            \"test_mask\",\n",
        "            \"train_indices\",\n",
        "            \"unmasked_pred\",\n",
        "        ]\n",
        "        for attr in attrs:\n",
        "            if hasattr(self, attr):\n",
        "                setattr(self, attr, to_device(getattr(self, attr)))\n",
        "\n",
        "    def load_dataset(self, data_init_args):\n",
        "        dataset = instantiate(data_init_args)\n",
        "\n",
        "        if self.data_source == \"ogb\":\n",
        "            split_idx = dataset.get_idx_split()\n",
        "            train_indices, valid_indices, test_indices = (\n",
        "                split_idx[\"train\"],\n",
        "                split_idx[\"valid\"],\n",
        "                split_idx[\"test\"],\n",
        "            )\n",
        "            # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)\n",
        "            g, label = dataset[0]\n",
        "            label = label.view(-1)\n",
        "\n",
        "            def to_mask(indices):\n",
        "                mask = torch.BoolTensor(g.number_of_nodes()).fill_(False)\n",
        "                mask[indices] = 1\n",
        "                return mask\n",
        "\n",
        "            train_mask, val_mask, test_mask = map(\n",
        "                to_mask, (train_indices, valid_indices, test_indices)\n",
        "            )\n",
        "\n",
        "            num_class = label.max().item() + 1\n",
        "\n",
        "            feat = g.ndata[\"feat\"]\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"relbench\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"dgl\":\n",
        "            g = dataset[0]\n",
        "            num_class = dataset.num_classes\n",
        "\n",
        "            # get node feature\n",
        "            feat = g.ndata[\"feat\"]\n",
        "\n",
        "            # get data split\n",
        "            train_mask = g.ndata[\"train_mask\"]\n",
        "            val_mask = g.ndata[\"val_mask\"]\n",
        "            test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "            label = g.ndata[\"label\"]\n",
        "        elif self.data_source == \"pyg\":\n",
        "            g = dgl.graph((dataset.edge_index[0], dataset.edge_index[1]))\n",
        "            n_nodes = dataset.x.shape[0]\n",
        "            num_class = dataset.num_classes\n",
        "            # get node feature\n",
        "            feat = dataset.x\n",
        "            label = dataset.y\n",
        "\n",
        "            if (\n",
        "                    hasattr(dataset, \"train_mask\")\n",
        "                    and hasattr(dataset, \"val_mask\")\n",
        "                    and hasattr(dataset, \"test_mask\")\n",
        "            ):\n",
        "                train_mask, val_mask, test_mask = (\n",
        "                    dataset.train_mask,\n",
        "                    dataset.val_mask,\n",
        "                    dataset.test_mask,\n",
        "                )\n",
        "            else:\n",
        "                if label.ndim > 1:\n",
        "                    raise NotImplementedError(\n",
        "                        \"Multi-Label classification currently unsupported.\"\n",
        "                    )\n",
        "                logging.warning(\n",
        "                    f\"No dataset split found for {self.name}, splitting with semi-supervised settings!!\"\n",
        "                )\n",
        "                train_mask, val_mask, test_mask = get_data_split_masks(\n",
        "                    n_nodes, label, 20 * num_class, seed=self.cfg.seed\n",
        "                )\n",
        "\n",
        "                self.split_index = self.cfg.seed\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        if train_mask.ndim == 1:\n",
        "            pass  # only one train/val/test split\n",
        "        elif train_mask.ndim == 2:\n",
        "            # ! Multiple splits\n",
        "            # Modified: Use the ${seed} split if not specified!\n",
        "            split_index = self.data_init_args.get(\"split\", self.cfg.seed)\n",
        "            # Avoid invalid split index\n",
        "            self.split_index = split_index = (split_index % train_mask.ndim)\n",
        "            train_mask = train_mask[:, split_index].squeeze()\n",
        "            val_mask = val_mask[:, split_index].squeeze()\n",
        "            if test_mask.ndim == 2:\n",
        "                test_mask = test_mask[:, split_index].squeeze()\n",
        "        else:\n",
        "            raise ValueError(\"train/val/test masks have more than 2 dimensions\")\n",
        "        print(\n",
        "            f\"{self.name} {g.num_nodes()} {g.num_edges()} {feat.shape[1]} {num_class} {len(train_mask.nonzero())}\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.add_self_loop:\n",
        "            g = dgl.add_self_loop(g)\n",
        "        else:\n",
        "            g = dgl.remove_self_loop(g)\n",
        "        if self.cfg.to_bidirected:\n",
        "            g = dgl.to_bidirected(g)\n",
        "        g = dgl.to_simple(g)  # Remove duplicate edges.\n",
        "        return g, label, feat, train_mask, val_mask, test_mask, num_class\n",
        "\n",
        "    def compute_linear_gnn_logits(\n",
        "            self, features, n_per_label_examples, visible_nodes, bootstrap=False\n",
        "    ):\n",
        "        # Compute and save LinearGNN logits into a dict. Note the computation is on CPU as torch does not support\n",
        "        # the gelss driver on GPU currently.\n",
        "        preds = {}\n",
        "        label, num_class, device = self.label, self.num_class, torch.device(\"cpu\")\n",
        "        label = label.to(device)\n",
        "        visible_nodes = visible_nodes.to(device)\n",
        "        for channel, F in features.items():\n",
        "            F = F.to(device)\n",
        "            if bootstrap:\n",
        "                ref_nodes = sample_k_nodes_per_label(\n",
        "                    label, visible_nodes, n_per_label_examples, num_class\n",
        "                )\n",
        "            else:\n",
        "                ref_nodes = visible_nodes\n",
        "            Y_L = torch.nn.functional.one_hot(label[ref_nodes], num_class).float()\n",
        "            with timer(\n",
        "                    f\"Solving with CPU driver (N={len(ref_nodes)}, d={F.shape[1]}, k={num_class})\",\n",
        "                    logger.debug,\n",
        "            ):\n",
        "                W = torch.linalg.lstsq(\n",
        "                    F[ref_nodes.cpu()].cpu(), Y_L.cpu(), driver=\"gelss\"\n",
        "                )[0]\n",
        "            preds[channel] = F @ W\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def compute_channel_logits(self, features, visible_nodes, sample, device):\n",
        "        pred_logits = self.compute_linear_gnn_logits(\n",
        "            {\n",
        "                c: features[c]\n",
        "                for c in set(self.cfg.feat_channels + self.cfg.pred_channels)\n",
        "            },\n",
        "            self.cfg.n_per_label_examples,\n",
        "            visible_nodes,\n",
        "            bootstrap=sample,\n",
        "        )\n",
        "        return {c: logits.to(device) for c, logits in pred_logits.items()}\n",
        "\n",
        "    def prepare_prop_features_logits_and_dist_features(self, g, input_feats, n_hops):\n",
        "        # Calculate Low-pass features containing AX, A^2X and High-pass features\n",
        "        # (I-A)X, and (I-A)^2X\n",
        "        if not os.path.exists(self.cache_f_name):\n",
        "            g = g.to(self.preprocess_device)\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} message passing and normalized predictions to file {self.cache_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                dim = input_feats.size(1)\n",
        "                LP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "                HP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "\n",
        "                g.ndata[\"LP\"] = input_feats.to(self.preprocess_device)\n",
        "                g.ndata[\"HP\"] = input_feats.to(self.preprocess_device)\n",
        "                for hop_idx in range(n_hops):\n",
        "                    # D^-1 A filter\n",
        "                    g.update_all(fn.copy_u(\"LP\", \"temp\"), fn.mean(\"temp\", \"LP\"))\n",
        "\n",
        "                    # (I - D^-1A) filter\n",
        "                    g.update_all(fn.copy_u(\"HP\", \"temp\"), fn.mean(\"temp\", \"HP_out\"))\n",
        "                    g.ndata[\"HP\"] = g.ndata[\"HP\"] - g.ndata[\"HP_out\"]\n",
        "\n",
        "                    LP[hop_idx] = g.ndata[\"LP\"].clone()\n",
        "                    HP[hop_idx] = g.ndata[\"HP\"].clone()\n",
        "                lp_feat_dict = {f\"L{l + 1}\": x for l, x in enumerate(LP)}\n",
        "                hp_feat_dict = {f\"H{l + 1}\": x for l, x in enumerate(HP)}\n",
        "\n",
        "                features = {\"X\": input_feats, **lp_feat_dict, **hp_feat_dict}\n",
        "                unmasked_pred = self.compute_channel_logits(\n",
        "                    features,\n",
        "                    self.train_indices,\n",
        "                    sample=False,\n",
        "                    device=self.preprocess_device,\n",
        "                )\n",
        "                torch.save((features, unmasked_pred), self.cache_f_name)\n",
        "        else:\n",
        "            features, unmasked_pred = torch.load(self.cache_f_name, map_location=\"cpu\")\n",
        "        if not os.path.exists(self.dist_f_name):\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} conditional gaussian distances \"\n",
        "                    f\"and save to {self.dist_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                # y_feat: n_nodes, n_channels, n_labels\n",
        "                y_feat = np.stack(\n",
        "                    [unmasked_pred[c].cpu().numpy() for c in self.cfg.feat_channels],\n",
        "                    axis=1,\n",
        "                )\n",
        "                # Conditional gaussian probability\n",
        "                bsz, n_channel, n_class = y_feat.shape\n",
        "                dist_feat_dim = n_channel * (n_channel - 1)\n",
        "                # Conditional gaussian probability\n",
        "                cond_gaussian_prob = np.zeros((bsz, n_channel, n_channel))\n",
        "                for i in range(bsz):\n",
        "                    cond_gaussian_prob[i, :, :] = get_entropy_normed_cond_gaussian_prob(\n",
        "                        y_feat[i, :, :], self.cfg.entropy\n",
        "                    )\n",
        "                dist = np.zeros((bsz, dist_feat_dim), dtype=np.float32)\n",
        "\n",
        "                # Compute pairwise distances between channels n_channels(n_channels-1)/2 total features\n",
        "                pair_index = 0\n",
        "                for c in range(n_channel):\n",
        "                    for c_prime in range(n_channel):\n",
        "                        if c != c_prime:  # Diagonal distances are useless\n",
        "                            dist[:, pair_index] = cond_gaussian_prob[:, c, c_prime]\n",
        "                            pair_index += 1\n",
        "\n",
        "                dist = torch.from_numpy(dist)\n",
        "                torch.save(dist, self.dist_f_name)\n",
        "        else:\n",
        "            dist = torch.load(self.dist_f_name, map_location=\"cpu\")\n",
        "        return features, unmasked_pred, dist\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_mask.nonzero().view(-1),\n",
        "            batch_size=self.train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZTYCcF6nP38O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_name = 'GraphAny/graphany/data.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ],
      "metadata": {
        "id": "pey3hRrtP4bp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wg0WnaJhM3f"
      },
      "source": [
        "# F1 Dataset Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKbBdLDuhaLT"
      },
      "source": [
        "## Update `configs/data.yaml` metadata section"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we build the yaml interface of our dataset. For this dataset we are going to use a file named `f1_3_classes.pkl`, which has inside the Formula 1 imported dataset from Relbench."
      ],
      "metadata": {
        "id": "pXSe3tu2N9z8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VIuYTpWCjgcK"
      },
      "outputs": [],
      "source": [
        "# we read the data.yaml file\n",
        "file_path = 'GraphAny/configs/data.yaml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# We add the F1 dataset metadata to the yaml file\n",
        "data['_ds_meta_data']['F1'] = 'relbench, f1_3_classes'\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing GraphAny on F1 Dataset"
      ],
      "metadata": {
        "id": "j_34PmXAZ3_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can successfully test GraphAny on our Formula 1 Dataset. Note that we can choose between four different checkpoints of GraphAny. In particular, we are going to test the model using three of these checkpoints.\n",
        "\n",
        "We can see the checkpoints in the directory `GraphAny/checkpoints/`\n",
        "\n",
        "We will see that the performances in terms of F1-score are the same, but the ROC AUC changes a little in depending on what checkpoint we are using."
      ],
      "metadata": {
        "id": "7T5QjDqkWh6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on Wisconsin checkpoint"
      ],
      "metadata": {
        "id": "MYiSS0MFPd6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clearing output files"
      ],
      "metadata": {
        "id": "W_fJ13Z3Ohz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First of all we clear our output files\n",
        "file_path = '/content/predictions.txt'\n",
        "clear_file_content(file_path)\n",
        "file_path = '/content/true_labels.txt'\n",
        "clear_file_content(file_path)"
      ],
      "metadata": {
        "id": "McunbPKKImqU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update `configs/data.yaml` dataset section"
      ],
      "metadata": {
        "id": "GyvNoTjDOmjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'GraphAny/configs/data.yaml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "# We add the new element to _dataset_lookup\n",
        "data['_dataset_lookup']['F1Debug'] = {\n",
        "    'train': ['Wisconsin'],\n",
        "    'eval': ['F1']\n",
        "}\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ],
      "metadata": {
        "id": "38TfgdxzOqFu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the model"
      ],
      "metadata": {
        "id": "gjFeIuIMQGxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ],
      "metadata": {
        "id": "PsPPVWujbv5p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulyl08LlbwbJ",
        "outputId": "97a746a7-70bc-4f75-ec0e-1381985c90a8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[15:33:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mMar8-15\u001b[0m:\u001b[1;36m33\u001b[0m-f0b9f928/                                                         \u001b[2mexperiment.py:56\u001b[0m\n",
            "Done loading data from cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "F1 97605 455432 300 3 66303\n",
            "\u001b[2;36m[15:33:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 message passing and normalized predictions to file                                                            \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:33:13\u001b[0m                                            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:33:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 message passing and normalized predictions to file                                                           \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:33:21\u001b[0m, running time = \u001b[1;36m7.96\u001b[0m seconds.              \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 conditional gaussian distances and save to                                                                    \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:33:21\u001b[0m               \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:33:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 conditional gaussian distances and save to                                                                   \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:33:26\u001b[0m, running time \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         = \u001b[1;36m4.83\u001b[0m seconds.                                                                                                                    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:32\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.09it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m[15:33:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.95it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 37.77it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 23.41it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:304\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:33:27\u001b[0m, running time = \u001b[1;36m15.33\u001b[0m seconds.                                                                     \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_data_path = \"data/relbench/f1_3_classes.pkl\"\n",
        "f1_labels = \"true_labels.txt\"\n",
        "labels, node_features, train_mask, val_mask, test_mask, val_nodes, test_nodes = build_comparison_file(f1_data_path, f1_labels)"
      ],
      "metadata": {
        "id": "RNtwne-b_2bG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_path = \"predictions.txt\"\n",
        "auroc_labels = [0, 1]\n",
        "ovr_auroc_val, ovr_auroc_test, b_auroc_val, b_auroc_test = compute_AUROC(predictions_path, labels, val_nodes, test_nodes, auroc_labels)\n",
        "\n",
        "print(f\"One-vs-Rest ROC AUC Val: {ovr_auroc_val*100:.2f}\")\n",
        "print(f\"One-vs-Rest ROC AUC Test: {ovr_auroc_test*100:.2f}\")\n",
        "print(f\"Binary ROC AUC Val: {b_auroc_val*100:.2f}\")\n",
        "print(f\"Binary ROC AUC Test: {b_auroc_test*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wfBebJPEtCK",
        "outputId": "74a79d05-2772-41db-a75d-cb0f67b8ae3d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-Rest ROC AUC Val: 51.16\n",
            "One-vs-Rest ROC AUC Test: 53.70\n",
            "Binary ROC AUC Val: 53.70\n",
            "Binary ROC AUC Test: 58.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on Cora checkpoint"
      ],
      "metadata": {
        "id": "EghoEDfKQSFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clearing output files"
      ],
      "metadata": {
        "id": "JwtsXZwTQbJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First of all we clear our output files\n",
        "file_path = '/content/predictions.txt'\n",
        "clear_file_content(file_path)\n",
        "file_path = '/content/true_labels.txt'\n",
        "clear_file_content(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxEJfTc8Qbp9",
        "outputId": "0df8bdc8-b481-4dd3-b64d-eb47edeb16fe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The content of the file '/content/predictions.txt' has been cleared.\n",
            "The content of the file '/content/true_labels.txt' has been cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update `configs/data.yaml` dataset section"
      ],
      "metadata": {
        "id": "2A1taOEbQdP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'GraphAny/configs/data.yaml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "# We add the new element to _dataset_lookup\n",
        "data['_dataset_lookup']['F1Debug'] = {\n",
        "    'train': ['Cora'],\n",
        "    'eval': ['F1']\n",
        "}\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ],
      "metadata": {
        "id": "KSZEyKquQhfD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the model"
      ],
      "metadata": {
        "id": "6_fgbt87QpMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_cora.pt\""
      ],
      "metadata": {
        "id": "iFgEbKYlQpiS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijtqfxRYQrV5",
        "outputId": "746fb84e-9b6e-4393-dff5-34e693aa8cf8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[15:34:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mMar8-15\u001b[0m:\u001b[1;36m34\u001b[0m-f2cf3d44/                                                         \u001b[2mexperiment.py:56\u001b[0m\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Cora 2708 10556 1433 7 140\n",
            "\u001b[2;36m[15:34:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Cora message passing and normalized predictions to file                                                          \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mCora_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:10\u001b[0m                                          \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Cora message passing and normalized predictions to file                                                         \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mCora_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:10\u001b[0m, running time = \u001b[1;36m0.45\u001b[0m seconds.            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Cora conditional gaussian distances and save to                                                                  \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mCora_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:10\u001b[0m             \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Cora conditional gaussian distances and save to                                                                 \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mCora_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:10\u001b[0m, running    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         time = \u001b[1;36m0.12\u001b[0m seconds.                                                                                                               \u001b[2m              \u001b[0m\n",
            "F1 97605 455432 300 3 66303\n",
            "\u001b[2;36m[15:34:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_cora.pt                                                                             \u001b[2mrun.py:32\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  8.03it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  6.64it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 92.28it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 38.91it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:304\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:11\u001b[0m, running time = \u001b[1;36m7.27\u001b[0m seconds.                                                                      \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_data_path = \"data/relbench/f1_3_classes.pkl\"\n",
        "f1_labels = \"true_labels.txt\"\n",
        "labels, node_features, train_mask, val_mask, test_mask, val_nodes, test_nodes = build_comparison_file(f1_data_path, f1_labels)"
      ],
      "metadata": {
        "id": "9rx0GCqhQ1mf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_path = \"predictions.txt\"\n",
        "auroc_labels = [0, 1]\n",
        "ovr_auroc_val, ovr_auroc_test, b_auroc_val, b_auroc_test = compute_AUROC(predictions_path, labels, val_nodes, test_nodes, auroc_labels)\n",
        "\n",
        "print(f\"One-vs-Rest ROC AUC Val: {ovr_auroc_val*100:.2f}\")\n",
        "print(f\"One-vs-Rest ROC AUC Test: {ovr_auroc_test*100:.2f}\")\n",
        "print(f\"Binary ROC AUC Val: {b_auroc_val*100:.2f}\")\n",
        "print(f\"Binary ROC AUC Test: {b_auroc_test*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoqMLYvHQ4gq",
        "outputId": "8309f59b-3af9-4596-a73c-827197f0ee39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-Rest ROC AUC Val: 53.24\n",
            "One-vs-Rest ROC AUC Test: 56.25\n",
            "Binary ROC AUC Val: 56.94\n",
            "Binary ROC AUC Test: 60.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on Arxiv checkpoint"
      ],
      "metadata": {
        "id": "gfPi12TYRD1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clearing output files"
      ],
      "metadata": {
        "id": "rQ2xwjkcRLFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First of all we clear our output files\n",
        "file_path = '/content/predictions.txt'\n",
        "clear_file_content(file_path)\n",
        "file_path = '/content/true_labels.txt'\n",
        "clear_file_content(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUDj-QVqRDeU",
        "outputId": "2ace54b0-a92b-40a8-a025-5156a995bc02"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The content of the file '/content/predictions.txt' has been cleared.\n",
            "The content of the file '/content/true_labels.txt' has been cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update `configs/data.yaml` dataset section"
      ],
      "metadata": {
        "id": "N_AUXDqkRN4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'GraphAny/configs/data.yaml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "# We add the new element to _dataset_lookup\n",
        "data['_dataset_lookup']['F1Debug'] = {\n",
        "    'train': ['Arxiv'],\n",
        "    'eval': ['F1']\n",
        "}\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ],
      "metadata": {
        "id": "uB48orLxRQY7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the model"
      ],
      "metadata": {
        "id": "N74uyoYaRZF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_arxiv.pt\""
      ],
      "metadata": {
        "id": "PjyqzqlCRZwf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEsvBkxmRbo9",
        "outputId": "70f2bb7f-a5f3-474c-fcb3-eddb9fc48de7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[15:34:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mMar8-15\u001b[0m:\u001b[1;36m34\u001b[0m-a1f37a8a/                                                         \u001b[2mexperiment.py:56\u001b[0m\n",
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n",
            "Downloaded 0.08 GB: 100% 81/81 [00:01<00:00, 69.82it/s]\n",
            "Extracting /content/data/ogb/arxiv.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n",
            "100% 1/1 [00:00<00:00, 16844.59it/s]\n",
            "Converting graphs into DGL objects...\n",
            "100% 1/1 [00:00<00:00, 198.10it/s]\n",
            "Saving...\n",
            "Arxiv 169343 1166243 128 40 90941\n",
            "\u001b[2;36m[15:34:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Arxiv message passing and normalized predictions to file                                                         \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mArxiv_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:47\u001b[0m                                         \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:34:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Arxiv message passing and normalized predictions to file                                                        \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mArxiv_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:53\u001b[0m, running time = \u001b[1;36m5.13\u001b[0m seconds.           \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Arxiv conditional gaussian distances and save to                                                                 \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mArxiv_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:34:53\u001b[0m            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[15:35:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Arxiv conditional gaussian distances and save to                                                                \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mArxiv_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:35:03\u001b[0m, running   \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         time = \u001b[1;36m10.71\u001b[0m seconds.                                                                                                              \u001b[2m              \u001b[0m\n",
            "F1 97605 455432 300 3 66303\n",
            "\u001b[2;36m[15:35:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_arxiv.pt                                                                            \u001b[2mrun.py:32\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00, 11.22it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  8.65it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 102.40it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m85.70999908447266\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 48.96it/s] \n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    85.70999908447266    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:304\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m85.71\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m03\u001b[0m-\u001b[1;36m08\u001b[0m \u001b[1;92m15:35:04\u001b[0m, running time = \u001b[1;36m27.13\u001b[0m seconds.                                                                     \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_data_path = \"data/relbench/f1_3_classes.pkl\"\n",
        "f1_labels = \"true_labels.txt\"\n",
        "labels, node_features, train_mask, val_mask, test_mask, val_nodes, test_nodes = build_comparison_file(f1_data_path, f1_labels)"
      ],
      "metadata": {
        "id": "OID_o6_3RifE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_path = \"predictions.txt\"\n",
        "auroc_labels = [0, 1]\n",
        "ovr_auroc_val, ovr_auroc_test, b_auroc_val, b_auroc_test = compute_AUROC(predictions_path, labels, val_nodes, test_nodes, auroc_labels)\n",
        "\n",
        "print(f\"One-vs-Rest ROC AUC Val: {ovr_auroc_val*100:.2f}\")\n",
        "print(f\"One-vs-Rest ROC AUC Test: {ovr_auroc_test*100:.2f}\")\n",
        "print(f\"Binary ROC AUC Val: {b_auroc_val*100:.2f}\")\n",
        "print(f\"Binary ROC AUC Test: {b_auroc_test*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m92f5ryYRi2g",
        "outputId": "c4835971-f2d2-4db7-ab6c-736f427c6132"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-Rest ROC AUC Val: 49.54\n",
            "One-vs-Rest ROC AUC Test: 53.47\n",
            "Binary ROC AUC Val: 55.56\n",
            "Binary ROC AUC Test: 56.94\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}