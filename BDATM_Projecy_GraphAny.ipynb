{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcNraNGefTp8"
      },
      "source": [
        "# Downloading GraphAny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC3-4ki8fWY3",
        "outputId": "6e411baa-ba0f-4e8a-eb04-2c3bfc82e3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GraphAny'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 76 (delta 24), reused 40 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (76/76), 576.89 KiB | 2.07 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DeepGraphLearning/GraphAny.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHVlit_sfoks"
      },
      "source": [
        "# Imports and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MKSI8hbjDr2",
        "outputId": "fb7c1743-d573-4b9a-a2b3-b81c92074ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4618941913238832/1 [00:26<00:22, 41.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  75% 0.7536448984577492/1 [00:26<00:01,  6.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  90% 0.9031047630338754/1 [00:26<00:02, 25.54s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  46% 0.4643368736786891/1 [00:26<00:22, 41.55s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  77% 0.7735886820301681/1 [00:26<00:01,  6.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  91% 0.9088972717180577/1 [00:26<00:02, 22.52s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  47% 0.4700038231040014/1 [00:26<00:03,  5.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4667568334069387/1 [00:26<00:24, 46.03s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  91% 0.9134076440926976/1 [00:26<00:01, 23.01s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  49% 0.49247546164917366/1 [00:26<00:02,  5.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.4689836508094595/1 [00:27<00:25, 47.29s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  92% 0.9184217128746578/1 [00:27<00:01, 22.05s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  52% 0.5150588993910881/1 [00:27<00:02,  5.11s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.47142633316426535/1 [00:27<00:24, 45.53s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  92% 0.923573153404069/1 [00:27<00:01, 21.22s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  54% 0.5364125459688389/1 [00:27<00:02,  4.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  47% 0.47430074542364165/1 [00:27<00:22, 43.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  56% 0.5583251885303004/1 [00:27<00:02,  4.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  87% 0.8666916332264116/1 [00:27<00:00,  5.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.4777318620336481/1 [00:27<00:19, 38.20s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  58% 0.5828092126168314/1 [00:27<00:01,  4.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  89% 0.8890325061705153/1 [00:27<00:00,  5.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.48039040934073923/1 [00:27<00:19, 38.41s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  60% 0.6047218551782929/1 [00:27<00:01,  4.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  91% 0.9082092211439949/1 [00:27<00:00,  5.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  48% 0.48371927413124216/1 [00:27<00:18, 35.80s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  63% 0.6331188511507992/1 [00:27<00:01,  4.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  93% 0.9269065182431376/1 [00:27<00:00,  5.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.4865368798242276/1 [00:27<00:23, 46.37s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  66% 0.6568202808601351/1 [00:27<00:01,  5.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | :  95% 0.9453161646176781/1 [00:27<00:00,  6.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.48893411692592087/1 [00:27<00:24, 47.82s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  95% 0.9485977067313861/1 [00:27<00:01, 30.57s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  68% 0.6768323370769801/1 [00:27<00:01,  6.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.49118365695499794/1 [00:28<00:25, 49.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  70% 0.6950556061459506/1 [00:28<00:01,  6.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  95% 0.9523754297862876/1 [00:28<00:01, 30.09s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  49% 0.49329686122473704/1 [00:28<00:25, 50.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  71% 0.7130552768214369/1 [00:28<00:01,  6.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  96% 0.9557868281813199/1 [00:28<00:01, 30.90s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.4953418976148071/1 [00:28<00:26, 52.82s/it] \n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  96% 0.9593813889062868/1 [00:28<00:01, 30.02s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  73% 0.7304959515132124/1 [00:28<00:01,  6.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.4972846821853737/1 [00:28<00:27, 55.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.49912521493643675/1 [00:28<00:27, 55.28s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  97% 0.9676465890445863/1 [00:28<00:00, 28.07s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  77% 0.7690666743892544/1 [00:28<00:01,  5.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.5017155943638588/1 [00:28<00:25, 51.81s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  79% 0.7936624976725276/1 [00:28<00:01,  5.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  98% 0.9765528573376572/1 [00:28<00:00, 26.28s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  50% 0.5038174373203198/1 [00:28<00:25, 51.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  83% 0.8323450197453117/1 [00:29<00:03, 18.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5057602218908863/1 [00:30<02:11, 265.19s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | : 100% 1.0/1 [00:30<00:00,  7.51s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   0% 0.0001518791001574902/1 [00:30<55:53:18, 201229.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   1% 0.010175899710551843/1 [00:30<35:00, 2122.24s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  85% 0.8463199193380805/1 [00:31<00:05, 36.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   2% 0.019744283020473728/1 [00:31<15:17, 935.49s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5071576634241008/1 [00:31<02:52, 349.47s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | :  86% 0.8563818470448741/1 [00:31<00:04, 32.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.9888018381520347/1 [00:31<00:01, 118.25s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   6% 0.05832157446047624/1 [00:31<03:26, 219.25s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5096571523452976/1 [00:31<01:57, 239.77s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | :  99% 0.9936327446040603/1 [00:31<00:00, 86.50s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :   9% 0.09127933919465162/1 [00:31<01:44, 114.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5118271631814275/1 [00:31<01:28, 180.34s/it]\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | : 100% 0.998440755764844/1 [00:31<00:00, 65.72s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  12% 0.12226267562677962/1 [00:31<01:02, 70.78s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  51% 0.5138608382582195/1 [00:31<01:09, 143.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  17% 0.1719271413782789/1 [00:31<00:31, 38.23s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5157468162623952/1 [00:31<00:57, 118.50s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5176896008329618/1 [00:31<00:47, 99.24s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  21% 0.20579618071339922/1 [00:31<00:21, 27.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5203140642002184/1 [00:31<00:37, 77.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5223477392770103/1 [00:31<00:35, 75.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  52% 0.5243814143538023/1 [00:32<00:32, 67.98s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5273921623725165/1 [00:32<00:26, 55.25s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | :  32% 0.3239581206359266/1 [00:32<00:06,  9.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.5319026037439488/1 [00:32<00:24, 52.44s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  53% 0.534027169326966/1 [00:32<00:23, 51.17s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.5370265560324021/1 [00:32<00:20, 45.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.5398555230386658/1 [00:32<00:19, 41.88s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  54% 0.5427867418644329/1 [00:32<00:18, 39.56s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5453998439184113/1 [00:32<00:18, 40.93s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5480015846591116/1 [00:33<00:18, 40.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5506601319662027/1 [00:33<00:17, 39.82s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  55% 0.5534550150326318/1 [00:33<00:17, 39.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5560340331467757/1 [00:33<00:18, 42.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.558499438128138/1 [00:33<00:18, 41.97s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.561351127760958/1 [00:33<00:17, 39.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  56% 0.5638960619352673/1 [00:33<00:18, 41.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5664409961095768/1 [00:33<00:17, 41.11s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5688950397776609/1 [00:33<00:18, 42.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5712922768793541/1 [00:34<00:18, 42.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  57% 0.5736440687279347/1 [00:34<00:19, 44.80s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  58% 0.5798814297176484/1 [00:34<00:15, 37.88s/it]\n",
            "\n",
            "dgl-2.1.0.cu118      | 577.9 MB  | : 100% 1/1 [00:34<00:00, 34.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "dgl-2.1.0.cu118      | 577.9 MB  | : 100% 1/1 [00:34<00:00, 34.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  58% 0.5825513383380178/1 [00:34<00:16, 39.63s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5851076338256053/1 [00:34<00:16, 39.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5876639293131929/1 [00:34<00:16, 39.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5904247284397875/1 [00:34<00:15, 38.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  59% 0.5930264691804877/1 [00:34<00:15, 38.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | : 100% 1.0/1 [00:35<00:00,  3.06s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | : 100% 1.0/1 [00:35<00:00,  6.57s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.595628209921188/1 [00:35<00:36, 90.63s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :   0% 0.00030184652548561843/1 [00:35<32:36:32, 117427.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :   0% 0.00035265581859715307/1 [00:35<27:56:14, 100610.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.597934556516656/1 [00:35<00:31, 77.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :   6% 0.06248223077552302/1 [00:35<06:14, 399.29s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :   7% 0.06559398225907047/1 [00:35<05:55, 380.79s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.5999909542200043/1 [00:35<00:29, 73.64s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  13% 0.1308353086995438/1 [00:35<02:17, 158.33s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6019791840436834/1 [00:35<00:27, 68.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  32% 0.31570398397048566/1 [00:35<00:14, 21.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  60% 0.6047854284233907/1 [00:35<00:22, 56.93s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  19% 0.18690758385649112/1 [00:35<01:15, 93.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  35% 0.3476558977560182/1 [00:35<00:10, 16.10s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  21% 0.21249995394187537/1 [00:35<00:55, 69.87s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6069668005727988/1 [00:36<00:24, 61.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  38% 0.37833609357993747/1 [00:36<00:08, 13.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  25% 0.25415477445889073/1 [00:36<00:36, 48.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6088982238300872/1 [00:36<00:23, 60.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  40% 0.4048832060286138/1 [00:36<00:06, 11.01s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  30% 0.29550774845042044/1 [00:36<00:23, 33.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.610784201834263/1 [00:36<00:26, 69.17s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  43% 0.4303175652608785/1 [00:36<00:05,  9.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  34% 0.33655887591646455/1 [00:36<00:16, 24.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6124315922595972/1 [00:36<00:26, 67.66s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  38% 0.37549707770410934/1 [00:36<00:11, 18.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  45% 0.4528905590795134/1 [00:36<00:04,  8.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  61% 0.6142039571309913/1 [00:36<00:25, 65.47s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  42% 0.4228869822053514/1 [00:36<00:07, 12.86s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  48% 0.4826169664322228/1 [00:36<00:03,  7.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6159876833156634/1 [00:36<00:24, 63.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  46% 0.4618251839929962/1 [00:36<00:05, 10.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  50% 0.5048720307604544/1 [00:36<00:03,  6.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6179304678862301/1 [00:36<00:23, 60.28s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  50% 0.49895230662772727/1 [00:36<00:04,  8.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  64% 0.6414809340282214/1 [00:36<00:02,  5.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6196687488177897/1 [00:36<00:22, 59.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  56% 0.5563031464699948/1 [00:36<00:02,  5.63s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | :  72% 0.7176545908452064/1 [00:36<00:01,  4.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6218273983406414/1 [00:36<00:21, 57.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  60% 0.5994671996144382/1 [00:36<00:01,  4.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  59% 0.5870568040297097/1 [00:37<00:02,  4.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  62% 0.6239519639236586/1 [00:37<00:20, 53.90s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  64% 0.6414238666569392/1 [00:37<00:01,  4.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  61% 0.6109015158099579/1 [00:37<00:01,  4.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6258493032411125/1 [00:37<00:21, 58.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  69% 0.6891156176836669/1 [00:37<00:01,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  63% 0.6345872628450044/1 [00:37<00:01,  4.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6278943396311826/1 [00:37<00:20, 55.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  74% 0.7377129082868514/1 [00:37<00:00,  3.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | :  66% 0.6581140451348493/1 [00:37<00:01,  4.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6299280147079745/1 [00:37<00:20, 56.46s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  78% 0.7805751149058093/1 [00:37<00:00,  2.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  63% 0.6324729488822839/1 [00:37<00:18, 50.74s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  85% 0.8518108949204153/1 [00:37<00:00,  2.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.635063328309706/1 [00:37<00:17, 46.91s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  90% 0.904935883405884/1 [00:37<00:00,  2.26s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6372674230856704/1 [00:37<00:17, 46.88s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | :  98% 0.9782845890988894/1 [00:37<00:00,  1.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6394260726085222/1 [00:37<00:17, 47.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6419710067828316/1 [00:37<00:16, 44.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  64% 0.6446409154032009/1 [00:38<00:15, 42.44s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6470154298783378/1 [00:38<00:16, 45.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  65% 0.6505374369945696/1 [00:38<00:13, 38.99s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6565930169718327/1 [00:38<00:12, 36.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | : 100% 1.0/1 [00:38<00:00,  7.75s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6593765387249836/1 [00:38<00:12, 36.27s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  66% 0.6621600604781346/1 [00:38<00:12, 37.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6650685566773453/1 [00:38<00:12, 37.05s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6686019251068552/1 [00:38<00:11, 34.57s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  46% 0.4590751015509131/1 [00:38<00:21, 39.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6716808410052386/1 [00:38<00:11, 35.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :   0% 0.0007921420514148734/1 [00:38<13:39:10, 49189.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | :  61% 0.6112440512957612/1 [00:39<00:09, 24.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  67% 0.6745438919513367/1 [00:39<00:11, 35.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :  29% 0.2907161328692585/1 [00:39<00:55, 78.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6773387750177657/1 [00:39<00:13, 43.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | :  43% 0.4340938441753506/1 [00:39<00:24, 43.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6797928186858498/1 [00:39<00:13, 43.31s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  68% 0.6821900557875431/1 [00:39<00:14, 46.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6851894424929792/1 [00:39<00:13, 43.76s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  69% 0.6945284420076326/1 [00:39<00:11, 36.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | : 100% 1.0/1 [00:39<00:00, 11.50s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.6977323323520758/1 [00:40<00:10, 35.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.700606744611452/1 [00:40<00:10, 36.05s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | : 100% 1.0/1 [00:40<00:00, 10.72s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  70% 0.7034129889911592/1 [00:40<00:11, 39.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | :   0% 0.0009220207584104709/1 [00:40<12:07:08, 43668.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.706116981551363/1 [00:40<00:11, 38.86s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | :  18% 0.1779500063732209/1 [00:40<02:10, 159.20s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7087414449186197/1 [00:40<00:11, 39.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | :  43% 0.4333497564529213/1 [00:40<00:29, 52.42s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7114113535389889/1 [00:40<00:11, 39.23s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | :  66% 0.6610888837803076/1 [00:40<00:09, 28.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  71% 0.7139903716531328/1 [00:40<00:11, 40.15s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [00:40<00:00, 23.08s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [00:40<00:00, 23.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7170692875515161/1 [00:40<00:10, 37.69s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7205685720411916/1 [00:40<00:09, 35.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  72% 0.7233975390474552/1 [00:41<00:11, 40.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7259311119084865/1 [00:41<00:11, 40.73s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | :  72% 0.7238623491779904/1 [00:41<00:07, 28.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :   0% 0.000997983748775134/1 [00:41<11:26:26, 41227.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  19% 0.19061489601605058/1 [00:41<02:02, 151.87s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7284533234562396/1 [00:41<00:11, 42.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | : 100% 1.0/1 [00:41<00:00, 16.59s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :   0% 0.001016089426288399/1 [00:41<11:17:25, 40686.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7308391992446547/1 [00:41<00:13, 51.37s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  19% 0.19000872271593064/1 [00:41<02:04, 153.11s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  73% 0.7332023524065134/1 [00:41<00:13, 49.37s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  43% 0.4267575590411276/1 [00:41<00:31, 55.32s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  74% 0.7353382793028088/1 [00:41<00:13, 49.66s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | :  62% 0.623878907741077/1 [00:41<00:11, 31.65s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  74% 0.7374287609459915/1 [00:41<00:12, 49.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  74% 0.7419846475705365/1 [00:41<00:12, 50.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  74% 0.7440410452738848/1 [00:42<00:13, 51.49s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7460406364108422/1 [00:42<00:12, 51.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7480175049212433/1 [00:42<00:14, 56.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [00:42<00:00, 15.20s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  75% 0.7502784062635985/1 [00:42<00:13, 53.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  76% 0.7594015408259667/1 [00:42<00:12, 53.73s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | :  85% 0.8541208096260458/1 [00:47<00:05, 34.54s/it]\n",
            "pytorch-2.2.1        | 1.34 GB   | :  87% 0.8741053596823417/1 [00:48<00:03, 26.84s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [01:04<00:00, 20.26s/it]               \n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.2.0    | 177.1 MB  | : 100% 1.0/1 [01:18<00:00,  4.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-12.0.2.5 | 163.0 MB  | : 100% 1.0/1 [01:48<00:00,  7.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcublas-12.1.0.26  | 329.0 MB  | : 100% 1.0/1 [01:55<00:00, 274.51s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-11.0.2.4    | 102.9 MB  | : 100% 1.0/1 [02:15<00:00,  3.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnpp-12.0.2.50     | 139.8 MB  | : 100% 1.0/1 [02:41<00:00,  6.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.3 MB   | : 100% 1.0/1 [02:42<00:00,  7.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.5.147 | 51.8 MB   | : 100% 1.0/1 [02:50<00:00,  1.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.14       | 24.3 MB   | : 100% 1.0/1 [02:51<00:00, 11.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-12.1.105  | 19.7 MB   | : 100% 1.0/1 [02:56<00:00, 10.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.4.5 | 98.3 MB   | : 100% 1.0/1 [03:23<00:00, 23.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2023.1. | 17.2 MB   | : 100% 1.0/1 [03:24<00:00, 14.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wandb-0.19.7         | 16.9 MB   | : 100% 1.0/1 [03:25<00:00, 16.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnvjitlink-12.1.10 | 16.9 MB   | : 100% 1.0/1 [03:29<00:00, 17.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [03:30<00:00, 15.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-12.1.105  | 15.4 MB   | : 100% 1.0/1 [03:34<00:00, 19.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.8.0   | 682.5 MB  | : 100% 1.0/1 [04:17<00:00, 65.72s/it]\u001b[A\n",
            "\n",
            "pytorch-2.2.1        | 1.34 GB   | : 100% 1.0/1 [07:27<00:00, 20.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                         \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Installing pip dependencies: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ Ran pip subprocess with arguments:\n",
            "['/usr/local/miniconda/envs/graphany/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/GraphAny/condaenv.a2vkjskd.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting ogb (from -r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1))\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting rootutils (from -r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 2))\n",
            "  Downloading rootutils-1.0.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting hydra_colorlog (from -r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 3))\n",
            "  Downloading hydra_colorlog-1.2.0-py3-none-any.whl.metadata (949 bytes)\n",
            "Collecting codetiming (from -r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 4))\n",
            "  Downloading codetiming-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting humanfriendly (from -r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting torch_frame (from -r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading torch_frame-1.7.5-py3-none-any.whl.metadata (763 bytes)\n",
            "Collecting pytorch-frame[full] (from -r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading pytorch_frame-0.2.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (1.6.1)\n",
            "Collecting pandas>=0.24.0 (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1))\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2.3.0)\n",
            "Collecting outdated>=0.2.0 (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1))\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting python-dotenv>=0.20.0 (from rootutils->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 2))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting colorlog (from hydra_colorlog->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 3))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra_colorlog->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 3)) (1.3.2)\n",
            "Collecting termcolor (from torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opencv-python (from torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tabulate (from torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting transformers>=4.25.1 (from torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting accelerate>=0.16.0 (from torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diffusers (from torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6)) (6.0.2)\n",
            "Collecting pyarrow (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (9.4.0)\n",
            "Collecting xgboost<2.0.0,>=1.7.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting optuna>=3.0.0 (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting optuna-integration (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading optuna_integration-4.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (1.3.0)\n",
            "Collecting catboost (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting lightgbm (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting datasets (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6)) (7.0.0)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate>=0.16.0->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from hydra-core>=1.0.0->hydra_colorlog->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 3)) (4.9.3)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (75.8.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1))\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2025.1)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.24.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1))\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2025.2.0)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.25.1->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting graphviz (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting matplotlib (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy>=1.16.0 (from ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting plotly (from catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from diffusers->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6)) (8.6.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from torchmetrics->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (0.12.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from aiohttp->datasets->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (1.18.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (2025.1.31)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna>=3.0.0->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from importlib-metadata->diffusers->torch_frame->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 6)) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 1)) (3.0.2)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/miniconda/envs/graphany/lib/python3.10/site-packages (from matplotlib->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7)) (3.2.1)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost->pytorch-frame[full]->-r /content/GraphAny/condaenv.a2vkjskd.requirements.txt (line 7))\n",
            "  Downloading narwhals-1.29.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "Downloading rootutils-1.0.7-py3-none-any.whl (6.4 kB)\n",
            "Downloading hydra_colorlog-1.2.0-py3-none-any.whl (3.6 kB)\n",
            "Downloading codetiming-1.4.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading torch_frame-1.7.5-py3-none-any.whl (46 kB)\n",
            "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 153.0 MB/s eta 0:00:00\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.0/10.0 MB 160.0 MB/s eta 0:00:00\n",
            "Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.3/200.3 MB 70.9 MB/s eta 0:00:00\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.7/98.7 MB 62.3 MB/s eta 0:00:00\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 169.2 MB/s eta 0:00:00\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 49.0 MB/s eta 0:00:00\n",
            "Downloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 111.1 MB/s eta 0:00:00\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 130.6 MB/s eta 0:00:00\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.0/63.0 MB 61.7 MB/s eta 0:00:00\n",
            "Downloading optuna_integration-4.2.1-py3-none-any.whl (97 kB)\n",
            "Downloading pytorch_frame-0.2.5-py3-none-any.whl (144 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 kB 40.5 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 88.5 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 94.0 MB/s eta 0:00:00\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 121.0 MB/s eta 0:00:00\n",
            "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.8/14.8 MB 121.5 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 102.8 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 599.5/599.5 kB 29.1 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 71.4 MB/s eta 0:00:00\n",
            "Downloading narwhals-1.29.0-py3-none-any.whl (305 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: xxhash, tzdata, termcolor, tabulate, safetensors, regex, python-dotenv, pyarrow, numpy, narwhals, Mako, littleutils, kiwisolver, humanfriendly, greenlet, graphviz, fsspec, fonttools, dill, cycler, colorlog, codetiming, sqlalchemy, rootutils, plotly, pandas, outdated, opencv-python, multiprocess, huggingface-hub, contourpy, xgboost, tokenizers, pytorch-frame, matplotlib, lightgbm, hydra_colorlog, diffusers, alembic, accelerate, transformers, optuna, ogb, catboost, torch_frame, optuna-integration, datasets\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.3\n",
            "    Uninstalling numpy-2.2.3:\n",
            "      Successfully uninstalled numpy-2.2.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.2.0\n",
            "    Uninstalling fsspec-2025.2.0:\n",
            "      Successfully uninstalled fsspec-2025.2.0\n",
            "Successfully installed Mako-1.3.9 accelerate-1.4.0 alembic-1.14.1 catboost-1.2.7 codetiming-1.4.0 colorlog-6.9.0 contourpy-1.3.1 cycler-0.12.1 datasets-3.3.2 diffusers-0.32.2 dill-0.3.8 fonttools-4.56.0 fsspec-2024.12.0 graphviz-0.20.3 greenlet-3.1.1 huggingface-hub-0.29.1 humanfriendly-10.0 hydra_colorlog-1.2.0 kiwisolver-1.4.8 lightgbm-4.6.0 littleutils-0.2.4 matplotlib-3.10.1 multiprocess-0.70.16 narwhals-1.29.0 numpy-1.26.4 ogb-1.3.6 opencv-python-4.11.0.86 optuna-4.2.1 optuna-integration-4.2.1 outdated-0.2.2 pandas-2.2.3 plotly-6.0.0 pyarrow-19.0.1 python-dotenv-1.0.1 pytorch-frame-0.2.5 regex-2024.11.6 rootutils-1.0.7 safetensors-0.5.3 sqlalchemy-2.0.38 tabulate-0.9.0 termcolor-2.5.0 tokenizers-0.21.0 torch_frame-1.7.5 transformers-4.49.0 tzdata-2025.1 xgboost-1.7.6 xxhash-3.5.0\n",
            "\n",
            "\b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate graphany\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'name': 'graphany',\n",
        "    'channels': [\n",
        "        'pytorch',\n",
        "        'pyg',\n",
        "        'nvidia',\n",
        "        'conda-forge',\n",
        "        'defaults',\n",
        "        'dglteam/label/cu118'\n",
        "    ],\n",
        "    'dependencies': [\n",
        "        'python=3.10',\n",
        "        'cudatoolkit=11.8',\n",
        "        'pyg',\n",
        "        'pytorch=2.2.1',\n",
        "        'torchvision',\n",
        "        'torchaudio',\n",
        "        'torchdata=0.7.1',\n",
        "        'dgl',\n",
        "        'lightning=2.*',\n",
        "        'pydantic',\n",
        "        'wandb',\n",
        "        'rich',\n",
        "        'hydra-core',\n",
        "        'jupyter',\n",
        "        'einops',\n",
        "        'tensorboard',\n",
        "        'pip',\n",
        "        {\n",
        "            'pip': [\n",
        "                'ogb',\n",
        "                'rootutils',\n",
        "                'hydra_colorlog',\n",
        "                # For time logging\n",
        "                'codetiming',\n",
        "                'humanfriendly',\n",
        "                'torch_frame',\n",
        "                'pytorch-frame[full]'\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "sys.path.insert(0,'/content/GraphAny')\n",
        "\n",
        "\n",
        "with open('GraphAny/environment.yaml', 'w') as file:\n",
        "    yaml.dump(data, file)\n",
        "\n",
        "\n",
        "\n",
        "!wget -O Miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda.sh -b -p /usr/local/miniconda\n",
        "\n",
        "os.environ['PATH'] = '/usr/local/miniconda/bin:' + os.environ['PATH']\n",
        "\n",
        "!conda update conda -y -q\n",
        "!source /usr/local/etc/profile.d/conda.sh\n",
        "!conda init\n",
        "!conda install -n root _license -y -q\n",
        "\n",
        "!conda env create -f GraphAny/environment.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwHPwzzJfr1y",
        "outputId": "9f51362f-ec62-444f-f653-cd200c932f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '/env/python', '/usr/local/miniconda/envs/graphany/lib/python310.zip', '/usr/local/miniconda/envs/graphany/lib/python3.10', '/usr/local/miniconda/envs/graphany/lib/python3.10/lib-dynload', '/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages', '/usr/local/lib/python3.10/site-packages']\n",
            "Python version\n",
            "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate graphany\n",
        "\n",
        "python\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "# some simple python commands\n",
        "sys.path.append('/usr/local/lib/python3.10/site-packages')\n",
        "print(sys.path)\n",
        "\n",
        "print(\"Python version\")\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda config --add channels pytorch\n",
        "!source activate graphany && conda config --add channels pyg\n",
        "!source activate graphany && conda config --add channels nvidia\n",
        "!source activate graphany && conda config --add channels conda-forge\n",
        "!source activate graphany && conda config --add channels dglteam/label/cu118"
      ],
      "metadata": {
        "id": "ENRRADzupiU6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate graphany && conda list torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBhCyXx32AXi",
        "outputId": "22705860-f8d2-46bb-a894-4a4562c2b2de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# packages in environment at /usr/local/miniconda/envs/graphany:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "pytorch                   2.2.1           py3.10_cuda12.1_cudnn8.9.2_0    pytorch\n",
            "pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n",
            "pytorch-frame             0.2.5                    pypi_0    pypi\n",
            "pytorch-lightning         2.5.0.post0        pyh101cb37_0    conda-forge\n",
            "pytorch-mutex             1.0                        cuda    pytorch\n",
            "torch-frame               1.7.5                    pypi_0    pypi\n",
            "torchaudio                2.2.1               py310_cu121    pytorch\n",
            "torchdata                 0.7.1                     py310    pytorch\n",
            "torchmetrics              1.6.1              pyhd8ed1ab_0    conda-forge\n",
            "torchtriton               2.2.0                     py310    pytorch\n",
            "torchvision               0.17.1              py310_cu121    pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wg0WnaJhM3f"
      },
      "source": [
        "# F1 and H&M Datasets Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKbBdLDuhaLT"
      },
      "source": [
        "## Update `configs/data.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VIuYTpWCjgcK"
      },
      "outputs": [],
      "source": [
        "# leggiamo tutto il file yaml\n",
        "file_path = 'GraphAny/configs/data.yaml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# aggiungo i metadati del dataset F1 al file yaml\n",
        "data['_ds_meta_data']['F1'] = 'relbench, f1_3_classes'\n",
        "# aggiungo i metadati del dataset H&M al file yaml\n",
        "data['_ds_meta_data']['HM'] = 'relbench, hm_3_classes'\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "453-Ir-Okjtc"
      },
      "outputs": [],
      "source": [
        "with open(file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "# Aggiungo il nuovo elemento _dataset_lookup\n",
        "data['_dataset_lookup']['F1Debug'] = {\n",
        "    'train': ['Wisconsin'],\n",
        "    'eval': ['F1']\n",
        "}\n",
        "data['_dataset_lookup']['HMDebug'] = {\n",
        "    'train': ['Wisconsin'],\n",
        "    'eval': ['HM']\n",
        "}\n",
        "\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCjvqIMLmVON"
      },
      "source": [
        "## Implement the dataset interface and update `GraphDataset` class in `data.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l5Y0yWWBowc-"
      },
      "outputs": [],
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import os.path\n",
        "import os.path as osp\n",
        "import re\n",
        "import ssl\n",
        "import sys\n",
        "import urllib\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "#from torch_frame import TensorFrame\n",
        "import requests\n",
        "\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import OmegaConf\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.manifold._utils import (\n",
        "    _binary_search_perplexity as sklearn_binary_search_perplexity,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from graphany.utils import logger, timer\n",
        "\n",
        "\n",
        "def get_entropy_normed_cond_gaussian_prob(X, entropy, metric=\"euclidean\"):\n",
        "\n",
        "    #Parameters\n",
        "    #----------\n",
        "    #X:              The matrix for pairwise similarity\n",
        "    #entropy:     Perplexity of the conditional prob distribution\n",
        "    #Returns the entropy-normalized conditional gaussian probability based on distances.\n",
        "    #-------\n",
        "\n",
        "\n",
        "    # Compute pairwise distances\n",
        "    perplexity = np.exp2(entropy)\n",
        "    distances = pdist(X, metric=metric)\n",
        "    distances = squareform(distances)\n",
        "\n",
        "    # Compute the squared distances\n",
        "    distances **= 2\n",
        "    distances = distances.astype(np.float32)\n",
        "    return sklearn_binary_search_perplexity(distances, perplexity, verbose=0)\n",
        "\n",
        "\n",
        "def sample_k_nodes_per_label(label, visible_nodes, k, num_class):\n",
        "    ref_node_idx = [\n",
        "        (label[visible_nodes] == lbl).nonzero().view(-1) for lbl in range(num_class)\n",
        "    ]\n",
        "    sampled_indices = [\n",
        "        label_indices[torch.randperm(len(label_indices))[:k]]\n",
        "        for label_indices in ref_node_idx\n",
        "    ]\n",
        "    return visible_nodes[torch.cat(sampled_indices)]\n",
        "\n",
        "\n",
        "def get_data_split_masks(n_nodes, labels, num_train_nodes, label_idx=None, seed=42):\n",
        "    label_idx = np.arange(n_nodes)\n",
        "    test_rate_in_labeled_nodes = (len(labels) - num_train_nodes) / len(labels)\n",
        "    train_idx, test_and_valid_idx = train_test_split(\n",
        "        label_idx,\n",
        "        test_size=test_rate_in_labeled_nodes,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels,\n",
        "    )\n",
        "    valid_idx, test_idx = train_test_split(\n",
        "        test_and_valid_idx,\n",
        "        test_size=0.5,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "        stratify=labels[test_and_valid_idx],\n",
        "    )\n",
        "    train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[train_idx] = True\n",
        "    val_mask[valid_idx] = True\n",
        "    test_mask[test_idx] = True\n",
        "\n",
        "    return train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def download_url(url: str, folder: str, log: bool = True, filename=None):\n",
        "    #Modified from torch_geometric.data.download_url\n",
        "\n",
        "    #Downloads the content of an URL to a specific folder.\n",
        "\n",
        "    #Args:\n",
        "        #url (str): The URL.\n",
        "        #folder (str): The folder.\n",
        "        #log (bool, optional): If :obj:`False`, will not print anything to the\n",
        "            #console. (default: :obj:`True`)\n",
        "\n",
        "\n",
        "    if filename is None:\n",
        "        filename = url.rpartition(\"/\")[2]\n",
        "        filename = filename if filename[0] == \"?\" else filename.split(\"?\")[0]\n",
        "\n",
        "    path = osp.join(folder, filename)\n",
        "\n",
        "    if osp.exists(path):  # pragma: no cover\n",
        "        if log and \"pytest\" not in sys.modules:\n",
        "            print(f\"Using existing file {filename}\", file=sys.stderr)\n",
        "        return path\n",
        "\n",
        "    if log and \"pytest\" not in sys.modules:\n",
        "        print(f\"Downloading {url}\", file=sys.stderr)\n",
        "\n",
        "    os.makedirs(osp.expanduser(osp.normpath(folder)), exist_ok=True)\n",
        "\n",
        "    context = ssl._create_unverified_context()\n",
        "    data = urllib.request.urlopen(url, context=context)\n",
        "\n",
        "    with open(path, \"wb\") as f:\n",
        "        # workaround for https://bugs.python.org/issue42853\n",
        "        while True:\n",
        "            chunk = data.read(10 * 1024 * 1024)\n",
        "            if not chunk:\n",
        "                break\n",
        "            f.write(chunk)\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "def download_file_from_google_drive(url, destination, filename=\"data.pkl\"):\n",
        "    path = osp.join(destination, filename)\n",
        "    os.makedirs(osp.expanduser(osp.normpath(destination)), exist_ok=True)\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(url, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {'confirm' : token }\n",
        "        response = session.get(url, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, path)\n",
        "    return path\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 10 * 1024 * 1024\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "'''\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url, raw_dir)\n",
        "    download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "'''\n",
        "\n",
        "def load_relbench_dataset(url, raw_dir):\n",
        "    # Converts relbench dataset to DGL Graph format\n",
        "    # download_path = download_url(url[0], raw_dir)\n",
        "    # download_path = download_file_from_google_drive(url, raw_dir)\n",
        "\n",
        "    with open(raw_dir, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    graph = dgl.graph((edges[:, 0], edges[:, 1]),\n",
        "                      num_nodes=len(node_features), idtype=torch.int32)\n",
        "    num_classes = len(labels.unique())\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "def load_heterophilous_dataset(url, raw_dir):\n",
        "    # Wrap Heterophilous to DGL Graph Dataset format https://arxiv.org/pdf/2302.11640.pdf\n",
        "    download_path = download_url(url, raw_dir)\n",
        "    data = np.load(download_path)\n",
        "    node_features = torch.tensor(data[\"node_features\"])\n",
        "    labels = torch.tensor(data[\"node_labels\"])\n",
        "    edges = torch.tensor(data[\"edges\"])\n",
        "\n",
        "    #\n",
        "    '''\n",
        "    print(f\"node_features è un: {type(data['node_features'])} con size: {data['node_features'].shape}\")\n",
        "    print(data['node_features'][0])\n",
        "    print(f\"node_labels è un: {type(data['node_labels'])} con size: {data['node_labels'].shape}\")\n",
        "    print(data['node_labels'][0])\n",
        "    print(f\"edges è un: {type(data['edges'])} con size: {data['edges'].shape}\")\n",
        "    print(data['edges'][0])\n",
        "    '''\n",
        "    #\n",
        "\n",
        "    graph = dgl.graph(\n",
        "        (edges[:, 0], edges[:, 1]), num_nodes=len(node_features), idtype=torch.int\n",
        "    )\n",
        "    num_classes = len(labels.unique())\n",
        "    num_targets = 1 if num_classes == 2 else num_classes\n",
        "    if num_targets == 1:\n",
        "        labels = labels.float()\n",
        "    train_masks = torch.tensor(data[\"train_masks\"]).T\n",
        "    val_masks = torch.tensor(data[\"val_masks\"]).T\n",
        "    test_masks = torch.tensor(data[\"test_masks\"]).T\n",
        "\n",
        "    '''\n",
        "    print(f\"la size della train mask è: {data['train_masks'].shape}\")\n",
        "    print(data['train_masks'][0])\n",
        "    print(data['train_masks'][1])\n",
        "    print(data['train_masks'][2])\n",
        "    '''\n",
        "\n",
        "    return graph, labels, num_classes, node_features, train_masks, val_masks, test_masks\n",
        "\n",
        "\n",
        "class CombinedDataset(pl.LightningDataModule):\n",
        "    def __init__(self, train_ds_dict, eval_ds_dict, cfg):\n",
        "        super().__init__()\n",
        "        self.train_ds_dict = train_ds_dict\n",
        "        self.eval_ds_dict = eval_ds_dict\n",
        "        self.all_ds = list(self.train_ds_dict.values()) + list(\n",
        "            self.eval_ds_dict.values()\n",
        "        )\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def to(self, device):\n",
        "        for ds in self.all_ds:\n",
        "            ds.to(device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.train_dataloader() for name, ds in self.train_ds_dict.items()\n",
        "        }\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"min_size\")\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.val_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        sub_dataloaders = {\n",
        "            name: ds.test_dataloader() for name, ds in self.eval_ds_dict.items()\n",
        "        }\n",
        "        # Use max_size instead of max_size_cycle to avoid repeated evaluation on small datasets\n",
        "        return pl.utilities.combined_loader.CombinedLoader(sub_dataloaders, \"max_size\")\n",
        "\n",
        "\n",
        "class GraphDataset(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            cfg,\n",
        "            ds_name,\n",
        "            cache_dir,\n",
        "            train_batch_size=256,\n",
        "            val_test_batch_size=256,\n",
        "            n_hops=1,\n",
        "            preprocess_device=torch.device(\"cpu\"),\n",
        "            permute_label=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.name = ds_name\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.permute_label = permute_label  # For checking label equivariance\n",
        "        self.val_test_batch_size = val_test_batch_size\n",
        "        self.preprocess_device = preprocess_device\n",
        "\n",
        "        self.n_hops = n_hops\n",
        "\n",
        "        self.data_source, ds_alias = cfg[\"_ds_meta_data\"][ds_name].split(\", \")\n",
        "        self.gidtype = None\n",
        "        self.dist = None\n",
        "        self.unmasked_pred = None\n",
        "        if self.data_source == \"pyg\":\n",
        "            components = ds_alias.split(\".\")\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"torch_geometric.datasets.{ds_alias}\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}/\",\n",
        "            }\n",
        "            if len(components) == 2:  # If sub-dataset\n",
        "                ds_init_args[\"_target_\"] = f\"torch_geometric.datasets.{components[0]}\"\n",
        "                ds_init_args[\"name\"] = components[1]\n",
        "        elif self.data_source == \"dgl\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"dgl.data.{ds_alias}\",\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "            }\n",
        "        elif self.data_source == \"ogb\":\n",
        "            ds_init_args = {\n",
        "                \"_target_\": f\"ogb.nodeproppred.DglNodePropPredDataset\",\n",
        "                \"root\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"name\": ds_alias,\n",
        "            }\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            target = \"graphany.data.load_heterophilous_dataset\"\n",
        "            url = f\"https://raw.githubusercontent.com/yandex-research/heterophilous-graphs/main/data/{ds_alias}.npz\"\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/\",\n",
        "                \"url\": url,\n",
        "            }\n",
        "        elif self.data_source == \"relbench\":\n",
        "            target = \"graphany.data.load_relbench_dataset\"\n",
        "            # url = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}.pkl\"\n",
        "            '''\n",
        "            if ds_alias == \"f1_3_classes\":\n",
        "                url = \"https://drive.google.com/file/d/16pyMEgYqX-5hnctXVSa0oB1YCOxFsSa_/view?usp=sharing\"\n",
        "            else:\n",
        "                url1 = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}3.pkl\"\n",
        "                url2 = f\"https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/{ds_alias}3.pkl\"\n",
        "            '''\n",
        "            ds_init_args = {\n",
        "                \"_target_\": target,\n",
        "                \"raw_dir\": f\"{cfg.dirs.data_storage}{self.data_source}/{ds_alias}.pkl\",\n",
        "                # \"url\": url,\n",
        "                \"url\" : \"\",\n",
        "            }\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        self.data_init_args = OmegaConf.create(ds_init_args)\n",
        "        # self.cache_f_name = osp.join(\n",
        "        #     cache_dir, f'{self.name}_{n_hops}')\n",
        "        if cfg.get(\"feat_chn\"):\n",
        "            all_channels = \"+\".join([cfg.feat_chn, cfg.pred_chn])\n",
        "            all_hops = re.findall(r\"\\d+\", all_channels)\n",
        "            n_hops = max(max([int(_) for _ in all_hops]), n_hops)\n",
        "\n",
        "        self.split_index = 0\n",
        "        (\n",
        "            self.g,\n",
        "            self.label,\n",
        "            self.feat,\n",
        "            self.train_mask,\n",
        "            self.val_mask,\n",
        "            self.test_mask,\n",
        "            self.num_class,\n",
        "        ) = self.load_dataset(self.data_init_args)\n",
        "        self.n_nodes, self.n_edges = self.g.num_nodes(), self.g.num_edges()\n",
        "        self.cache_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}.pt\",\n",
        "        )\n",
        "\n",
        "        self.dist_f_name = osp.join(\n",
        "            cache_dir,\n",
        "            f\"{self.name}_{n_hops}hop_selfloop={cfg.add_self_loop}_bidirected={cfg.to_bidirected}_split=\"\n",
        "            f\"{self.split_index}_{cfg.feat_chn}_entropy={cfg.entropy}_dist.pt\",\n",
        "        )\n",
        "\n",
        "        self.gidtype = self.g.idtype\n",
        "        self.train_indices = self.train_mask.nonzero().view(-1)\n",
        "\n",
        "        (\n",
        "            self.features,\n",
        "            self.unmasked_pred,\n",
        "            self.dist,\n",
        "        ) = self.prepare_prop_features_logits_and_dist_features(\n",
        "            self.g, self.feat, n_hops=cfg.n_hops\n",
        "        )\n",
        "        # Remove the graph, as GraphAny doesn't use it in training\n",
        "        del self.g\n",
        "        del self.feat\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def to(self, device):  # Supports nested dictionary\n",
        "        def to_device(input):\n",
        "            if input is None:\n",
        "                return None\n",
        "            elif isinstance(input, dict):\n",
        "                return {key: to_device(value) for key, value in input.items()}\n",
        "            elif isinstance(input, list):\n",
        "                return [to_device(item) for item in input]\n",
        "            elif hasattr(input, \"to\"):\n",
        "                return input.to(device)\n",
        "            else:\n",
        "                return (\n",
        "                    input  # Return as is if it's not a tensor or any nested structure\n",
        "                )\n",
        "\n",
        "        # Apply to_device to all attributes that may contain tensors\n",
        "        attrs = [\n",
        "            \"label\",\n",
        "            \"feat\",\n",
        "            \"train_mask\",\n",
        "            \"val_mask\",\n",
        "            \"test_mask\",\n",
        "            \"train_indices\",\n",
        "            \"unmasked_pred\",\n",
        "        ]\n",
        "        for attr in attrs:\n",
        "            if hasattr(self, attr):\n",
        "                setattr(self, attr, to_device(getattr(self, attr)))\n",
        "\n",
        "    def load_dataset(self, data_init_args):\n",
        "        dataset = instantiate(data_init_args)\n",
        "\n",
        "        if self.data_source == \"ogb\":\n",
        "            split_idx = dataset.get_idx_split()\n",
        "            train_indices, valid_indices, test_indices = (\n",
        "                split_idx[\"train\"],\n",
        "                split_idx[\"valid\"],\n",
        "                split_idx[\"test\"],\n",
        "            )\n",
        "            # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)\n",
        "            g, label = dataset[0]\n",
        "            label = label.view(-1)\n",
        "\n",
        "            def to_mask(indices):\n",
        "                mask = torch.BoolTensor(g.number_of_nodes()).fill_(False)\n",
        "                mask[indices] = 1\n",
        "                return mask\n",
        "\n",
        "            train_mask, val_mask, test_mask = map(\n",
        "                to_mask, (train_indices, valid_indices, test_indices)\n",
        "            )\n",
        "\n",
        "            num_class = label.max().item() + 1\n",
        "\n",
        "            feat = g.ndata[\"feat\"]\n",
        "        elif self.data_source == \"heterophilous\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"relbench\":\n",
        "            g, label, num_class, feat, train_mask, val_mask, test_mask = dataset\n",
        "        elif self.data_source == \"dgl\":\n",
        "            g = dataset[0]\n",
        "            num_class = dataset.num_classes\n",
        "\n",
        "            # get node feature\n",
        "            feat = g.ndata[\"feat\"]\n",
        "\n",
        "            # get data split\n",
        "            train_mask = g.ndata[\"train_mask\"]\n",
        "            val_mask = g.ndata[\"val_mask\"]\n",
        "            test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "            label = g.ndata[\"label\"]\n",
        "        elif self.data_source == \"pyg\":\n",
        "            g = dgl.graph((dataset.edge_index[0], dataset.edge_index[1]))\n",
        "            n_nodes = dataset.x.shape[0]\n",
        "            num_class = dataset.num_classes\n",
        "            # get node feature\n",
        "            feat = dataset.x\n",
        "            label = dataset.y\n",
        "\n",
        "            if (\n",
        "                    hasattr(dataset, \"train_mask\")\n",
        "                    and hasattr(dataset, \"val_mask\")\n",
        "                    and hasattr(dataset, \"test_mask\")\n",
        "            ):\n",
        "                train_mask, val_mask, test_mask = (\n",
        "                    dataset.train_mask,\n",
        "                    dataset.val_mask,\n",
        "                    dataset.test_mask,\n",
        "                )\n",
        "            else:\n",
        "                if label.ndim > 1:\n",
        "                    raise NotImplementedError(\n",
        "                        \"Multi-Label classification currently unsupported.\"\n",
        "                    )\n",
        "                logging.warning(\n",
        "                    f\"No dataset split found for {self.name}, splitting with semi-supervised settings!!\"\n",
        "                )\n",
        "                train_mask, val_mask, test_mask = get_data_split_masks(\n",
        "                    n_nodes, label, 20 * num_class, seed=self.cfg.seed\n",
        "                )\n",
        "\n",
        "                self.split_index = self.cfg.seed\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Unsupported {self.data_source=}\")\n",
        "        if train_mask.ndim == 1:\n",
        "            pass  # only one train/val/test split\n",
        "        elif train_mask.ndim == 2:\n",
        "            # ! Multiple splits\n",
        "            # Modified: Use the ${seed} split if not specified!\n",
        "            split_index = self.data_init_args.get(\"split\", self.cfg.seed)\n",
        "            # Avoid invalid split index\n",
        "            self.split_index = split_index = (split_index % train_mask.ndim)\n",
        "            train_mask = train_mask[:, split_index].squeeze()\n",
        "            val_mask = val_mask[:, split_index].squeeze()\n",
        "            if test_mask.ndim == 2:\n",
        "                test_mask = test_mask[:, split_index].squeeze()\n",
        "        else:\n",
        "            raise ValueError(\"train/val/test masks have more than 2 dimensions\")\n",
        "        print(\n",
        "            f\"{self.name} {g.num_nodes()} {g.num_edges()} {feat.shape[1]} {num_class} {len(train_mask.nonzero())}\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.add_self_loop:\n",
        "            g = dgl.add_self_loop(g)\n",
        "        else:\n",
        "            g = dgl.remove_self_loop(g)\n",
        "        if self.cfg.to_bidirected:\n",
        "            g = dgl.to_bidirected(g)\n",
        "        g = dgl.to_simple(g)  # Remove duplicate edges.\n",
        "        return g, label, feat, train_mask, val_mask, test_mask, num_class\n",
        "\n",
        "    def compute_linear_gnn_logits(\n",
        "            self, features, n_per_label_examples, visible_nodes, bootstrap=False\n",
        "    ):\n",
        "        # Compute and save LinearGNN logits into a dict. Note the computation is on CPU as torch does not support\n",
        "        # the gelss driver on GPU currently.\n",
        "        preds = {}\n",
        "        label, num_class, device = self.label, self.num_class, torch.device(\"cpu\")\n",
        "        label = label.to(device)\n",
        "        visible_nodes = visible_nodes.to(device)\n",
        "        for channel, F in features.items():\n",
        "            F = F.to(device)\n",
        "            if bootstrap:\n",
        "                ref_nodes = sample_k_nodes_per_label(\n",
        "                    label, visible_nodes, n_per_label_examples, num_class\n",
        "                )\n",
        "            else:\n",
        "                ref_nodes = visible_nodes\n",
        "            Y_L = torch.nn.functional.one_hot(label[ref_nodes], num_class).float()\n",
        "            with timer(\n",
        "                    f\"Solving with CPU driver (N={len(ref_nodes)}, d={F.shape[1]}, k={num_class})\",\n",
        "                    logger.debug,\n",
        "            ):\n",
        "                W = torch.linalg.lstsq(\n",
        "                    F[ref_nodes.cpu()].cpu(), Y_L.cpu(), driver=\"gelss\"\n",
        "                )[0]\n",
        "            preds[channel] = F @ W\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def compute_channel_logits(self, features, visible_nodes, sample, device):\n",
        "        pred_logits = self.compute_linear_gnn_logits(\n",
        "            {\n",
        "                c: features[c]\n",
        "                for c in set(self.cfg.feat_channels + self.cfg.pred_channels)\n",
        "            },\n",
        "            self.cfg.n_per_label_examples,\n",
        "            visible_nodes,\n",
        "            bootstrap=sample,\n",
        "        )\n",
        "        return {c: logits.to(device) for c, logits in pred_logits.items()}\n",
        "\n",
        "    def prepare_prop_features_logits_and_dist_features(self, g, input_feats, n_hops):\n",
        "        # Calculate Low-pass features containing AX, A^2X and High-pass features\n",
        "        # (I-A)X, and (I-A)^2X\n",
        "        if not os.path.exists(self.cache_f_name):\n",
        "            g = g.to(self.preprocess_device)\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} message passing and normalized predictions to file {self.cache_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                dim = input_feats.size(1)\n",
        "                LP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "                HP = torch.zeros(n_hops, g.number_of_nodes(), dim).to(\n",
        "                    self.preprocess_device\n",
        "                )\n",
        "\n",
        "                g.ndata[\"LP\"] = input_feats.to(self.preprocess_device)\n",
        "                g.ndata[\"HP\"] = input_feats.to(self.preprocess_device)\n",
        "                for hop_idx in range(n_hops):\n",
        "                    # D^-1 A filter\n",
        "                    g.update_all(fn.copy_u(\"LP\", \"temp\"), fn.mean(\"temp\", \"LP\"))\n",
        "\n",
        "                    # (I - D^-1A) filter\n",
        "                    g.update_all(fn.copy_u(\"HP\", \"temp\"), fn.mean(\"temp\", \"HP_out\"))\n",
        "                    g.ndata[\"HP\"] = g.ndata[\"HP\"] - g.ndata[\"HP_out\"]\n",
        "\n",
        "                    LP[hop_idx] = g.ndata[\"LP\"].clone()\n",
        "                    HP[hop_idx] = g.ndata[\"HP\"].clone()\n",
        "                lp_feat_dict = {f\"L{l + 1}\": x for l, x in enumerate(LP)}\n",
        "                hp_feat_dict = {f\"H{l + 1}\": x for l, x in enumerate(HP)}\n",
        "\n",
        "                features = {\"X\": input_feats, **lp_feat_dict, **hp_feat_dict}\n",
        "                unmasked_pred = self.compute_channel_logits(\n",
        "                    features,\n",
        "                    self.train_indices,\n",
        "                    sample=False,\n",
        "                    device=self.preprocess_device,\n",
        "                )\n",
        "                torch.save((features, unmasked_pred), self.cache_f_name)\n",
        "        else:\n",
        "            features, unmasked_pred = torch.load(self.cache_f_name, map_location=\"cpu\")\n",
        "        if not os.path.exists(self.dist_f_name):\n",
        "            with timer(\n",
        "                    f\"Computing {self.name} conditional gaussian distances \"\n",
        "                    f\"and save to {self.dist_f_name}\",\n",
        "                    logger.info,\n",
        "            ):\n",
        "                # y_feat: n_nodes, n_channels, n_labels\n",
        "                y_feat = np.stack(\n",
        "                    [unmasked_pred[c].cpu().numpy() for c in self.cfg.feat_channels],\n",
        "                    axis=1,\n",
        "                )\n",
        "                # Conditional gaussian probability\n",
        "                bsz, n_channel, n_class = y_feat.shape\n",
        "                dist_feat_dim = n_channel * (n_channel - 1)\n",
        "                # Conditional gaussian probability\n",
        "                cond_gaussian_prob = np.zeros((bsz, n_channel, n_channel))\n",
        "                for i in range(bsz):\n",
        "                    cond_gaussian_prob[i, :, :] = get_entropy_normed_cond_gaussian_prob(\n",
        "                        y_feat[i, :, :], self.cfg.entropy\n",
        "                    )\n",
        "                dist = np.zeros((bsz, dist_feat_dim), dtype=np.float32)\n",
        "\n",
        "                # Compute pairwise distances between channels n_channels(n_channels-1)/2 total features\n",
        "                pair_index = 0\n",
        "                for c in range(n_channel):\n",
        "                    for c_prime in range(n_channel):\n",
        "                        if c != c_prime:  # Diagonal distances are useless\n",
        "                            dist[:, pair_index] = cond_gaussian_prob[:, c, c_prime]\n",
        "                            pair_index += 1\n",
        "\n",
        "                dist = torch.from_numpy(dist)\n",
        "                torch.save(dist, self.dist_f_name)\n",
        "        else:\n",
        "            dist = torch.load(self.dist_f_name, map_location=\"cpu\")\n",
        "        return features, unmasked_pred, dist\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_mask.nonzero().view(-1),\n",
        "            batch_size=self.train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_mask.nonzero().view(-1), batch_size=self.val_test_batch_size\n",
        "        )\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "riTRCN1OnR2k"
      },
      "outputs": [],
      "source": [
        "path_name = 'GraphAny/graphany/data.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFSPf9jrIEfg"
      },
      "source": [
        "# Testing GraphAny on F1 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XMxpGG22Lc10"
      },
      "outputs": [],
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqd5y77pmiyI",
        "outputId": "7e01d16a-abd1-475b-e022-e8d557fb5d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[09:53:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mMar4-9\u001b[0m:\u001b[1;36m53\u001b[0m-6ab428be/                                                          \u001b[2mexperiment.py:56\u001b[0m\n",
            "Done loading data from cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "F1 97605 455432 300 3 66303\n",
            "\u001b[2;36m[09:53:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 message passing and normalized predictions to file                                                            \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m09:53:37\u001b[0m                                            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[09:53:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 message passing and normalized predictions to file                                                           \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m09:53:50\u001b[0m, running time = \u001b[1;36m12.76\u001b[0m seconds.             \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing F1 conditional gaussian distances and save to                                                                    \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m09:53:50\u001b[0m               \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[09:53:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing F1 conditional gaussian distances and save to                                                                   \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mF1_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m09:53:55\u001b[0m, running time \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         = \u001b[1;36m4.83\u001b[0m seconds.                                                                                                                    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:28\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.21it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m98.98999786376953\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m98.98999786376953\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m98.98999786376953\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.03it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.98999786376953    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.98999786376953    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.98999786376953    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 108.53it/s]\u001b[2;36m[09:53:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m99.66000366210938\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m99.66000366210938\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m99.66000366210938\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 41.05it/s] \n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.66000366210938    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.66000366210938    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.66000366210938    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:289\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m98.99\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m98.99\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m98.99\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m99.66\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m99.66\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m99.66\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m03\u001b[0m-\u001b[1;36m04\u001b[0m \u001b[1;92m09:53:56\u001b[0m, running time = \u001b[1;36m19.64\u001b[0m seconds.                                                                     \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing GraphAny on H&M Dataset"
      ],
      "metadata": {
        "id": "kDmsHZrZERak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"HMDebug\" # we want to use the H&M dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ],
      "metadata": {
        "id": "r2Go5bLSEYCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFwz2SRNEbcR",
        "outputId": "b8f1b941-66d1-4c33-f0d2-a9af671f4299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "\u001b[2;36m[11:29:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mFeb20-11\u001b[0m:\u001b[1;36m29\u001b[0m-67b5ea93/                                                        \u001b[2mexperiment.py:56\u001b[0m\n",
            "Downloading /content/data/dgl/wisconsin.zip from https://data.dgl.ai/dataset/wisconsin.zip...\n",
            "/content/data/dgl/wisconsin.zip: 100% 41.2k/41.2k [00:00<00:00, 8.90MB/s]\n",
            "Extracting file to /content/data/dgl/wisconsin_5bfc48b0\n",
            "Done saving data into cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Wisconsin message passing and normalized predictions to file                                                     \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:00\u001b[0m                                     \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[11:29:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Wisconsin message passing and normalized predictions to file                                                    \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:01\u001b[0m, running time = \u001b[1;36m0.69\u001b[0m seconds.       \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing Wisconsin conditional gaussian distances and save to                                                             \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:01\u001b[0m        \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing Wisconsin conditional gaussian distances and save to                                                            \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mWisconsin_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:01\u001b[0m,       \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         running time = \u001b[1;36m0.02\u001b[0m seconds.                                                                                                       \u001b[2m              \u001b[0m\n",
            "Downloading https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/hm_3_classes.pkl\n",
            "HM 11147 5816 300 3 5957\n",
            "\u001b[2;36m[11:29:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing HM message passing and normalized predictions to file                                                            \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:02\u001b[0m                                            \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing HM message passing and normalized predictions to file                                                           \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0mpt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:02\u001b[0m, running time = \u001b[1;36m0.54\u001b[0m seconds.              \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started Computing HM conditional gaussian distances and save to                                                                    \u001b[2mlogging.py:116\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:02\u001b[0m               \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m[11:29:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished Computing HM conditional gaussian distances and save to                                                                   \u001b[2mlogging.py:122\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[35m/content/data_cache/\u001b[0m\u001b[95mHM_2hop_selfloop\u001b[0m=\u001b[35mFalse_bidirected\u001b[0m=\u001b[33mTrue_split\u001b[0m=\u001b[35m0_X\u001b[0m+L1+L2+H1+\u001b[33mH2_entropy\u001b[0m=\u001b[35m1_dist\u001b[0m.pt at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:03\u001b[0m, running time \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         = \u001b[1;36m0.46\u001b[0m seconds.                                                                                                                    \u001b[2m              \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:28\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.19it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.08it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/hm_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 111.66it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_test_acc'\u001b[0m: \u001b[1;36m99.97000122070312\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m99.97000122070312\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m99.97000122070312\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 52.62it/s] \n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/hm_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.97000122070312    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.97000122070312    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.97000122070312    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:289\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m100.0\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/hm_test_acc'\u001b[0m: \u001b[1;36m99.97\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m99.97\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m99.97\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[1;92m11:29:03\u001b[0m, running time = \u001b[1;36m3.97\u001b[0m seconds.                                                                      \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing GraphAny on F1 Dataset prediction files"
      ],
      "metadata": {
        "id": "j_34PmXAZ3_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_code = \"\"\"\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import rootutils\n",
        "\n",
        "root = rootutils.setup_root(__file__, dotenv=True, pythonpath=True, cwd=False)\n",
        "from graphany.utils import logger, timer\n",
        "from graphany.utils.experiment import init_experiment\n",
        "from graphany.data import GraphDataset, CombinedDataset\n",
        "from graphany.model import GraphAny\n",
        "\n",
        "import torch\n",
        "import hydra\n",
        "from omegaconf import DictConfig\n",
        "import wandb\n",
        "import numpy as np\n",
        "import torchmetrics\n",
        "from rich.pretty import pretty_repr\n",
        "\n",
        "import os\n",
        "\n",
        "mean = lambda input: np.round(np.mean(input).item(), 2)\n",
        "\n",
        "\n",
        "class InductiveNodeClassification(pl.LightningModule):\n",
        "    def __init__(self, cfg, combined_dataset, checkpoint=None):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if checkpoint:\n",
        "            # Initialize from previous checkpoint using previous graphany config\n",
        "            ckpt = torch.load(checkpoint, map_location=\"cpu\")\n",
        "            logger.critical(f\"Loaded checkpoint at {checkpoint}\")\n",
        "            self.gnn_model = GraphAny(**ckpt[\"graph_any_config\"])\n",
        "            self.load_state_dict(ckpt[\"state_dict\"])\n",
        "        else:\n",
        "            self.gnn_model = GraphAny(**cfg.graph_any)\n",
        "        self.combined_dataset = combined_dataset\n",
        "        self.attn_dict, self.loss_dict, self.res_dict = {}, {}, {}\n",
        "        # Initialize accuracy metrics for validation and testing\n",
        "        self.metrics = {}\n",
        "        held_out_datasets = list(\n",
        "            set(self.cfg._all_datasets) - set(self.cfg._trans_datasets)\n",
        "        )  # 27 datasets in total\n",
        "        self.heldout_metrics = [\n",
        "            f\"{setting}/{d.lower()[:4]}_{split}_acc\"\n",
        "            for split in [\"val\", \"test\"]\n",
        "            for d in held_out_datasets\n",
        "            for setting in [\"trans\", \"ind\"]\n",
        "        ]\n",
        "        for split in (\"val\", \"test\"):\n",
        "            self.metrics[split] = {\n",
        "                k: torchmetrics.Accuracy(task=\"multiclass\", num_classes=v.num_class)\n",
        "                for k, v in combined_dataset.eval_ds_dict.items()\n",
        "            }\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def on_train_end(self):\n",
        "        checkpoint_path = f\"{self.cfg.dirs.output}{self.cfg.dataset}_val_acc={self.res_dict['val_acc']}.pt\"\n",
        "        self.save_checkpoint(checkpoint_path)\n",
        "\n",
        "    def save_checkpoint(self, file_path):\n",
        "        checkpoint = {\n",
        "            \"state_dict\": self.state_dict(),\n",
        "            \"optimizer_state_dict\": [\n",
        "                opt.state_dict() for opt in self.trainer.optimizers\n",
        "            ],\n",
        "            \"graph_any_config\": self.cfg.graph_any,\n",
        "        }\n",
        "        torch.save(checkpoint, file_path)\n",
        "        logger.critical(f\"Checkpoint saved to {file_path}\")\n",
        "\n",
        "    def get_metric_name(self, ds_name, split):\n",
        "        if ds_name in self.cfg.train_datasets:\n",
        "            return f\"trans/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "        else:\n",
        "            return f\"ind/{ds_name.lower()[:4]}_{split}_acc\"\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # start with all the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {\"params\": decay_params, \"weight_decay\": self.cfg.weight_decay},\n",
        "            {\"params\": nodecay_params, \"weight_decay\": 0.0},\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        logger.info(\n",
        "            f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\"\n",
        "        )\n",
        "        logger.info(\n",
        "            f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\"\n",
        "        )\n",
        "\n",
        "        if self.cfg.optimizer == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=self.cfg.lr)\n",
        "        else:  # AdamW\n",
        "            optimizer = torch.optim.AdamW(\n",
        "                optim_groups,\n",
        "                lr=self.cfg.lr,\n",
        "                weight_decay=self.cfg.weight_decay,\n",
        "            )\n",
        "        return optimizer\n",
        "\n",
        "    def on_fit_start(self):\n",
        "        super().on_fit_start()\n",
        "        # move all datasets to the correct GPU device\n",
        "        print(f\"moving train and eval datasets to {self.device}\")\n",
        "        self.combined_dataset.to(self.device)\n",
        "        self.move_metrics_to_device()\n",
        "\n",
        "    def move_metrics_to_device(self):\n",
        "        for metrics_dict in self.metrics.values():\n",
        "            for metric in metrics_dict.values():\n",
        "                metric.to(self.device)\n",
        "\n",
        "    def predict(self, ds, nodes, input, is_training=False):\n",
        "        # Use preprocessed distance during evaluation\n",
        "        dist = ds.dist if not is_training else None\n",
        "        dist = dist.to(nodes.device)[nodes] if dist is not None else dist\n",
        "\n",
        "        preds, attn = self.gnn_model(\n",
        "            {c: chn_pred[nodes] for c, chn_pred in input.items()}, dist=dist\n",
        "        )\n",
        "\n",
        "        self.attn_dict.update(\n",
        "            {\n",
        "                f\"Attention/{ds.name}-{c}\": v\n",
        "                for c, v in zip(self.cfg.feat_channels, attn)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        def softmax(logits):\n",
        "          exp_logits = np.exp(logits - np.max(logits))  # Stabilizza l'esponenziale\n",
        "          return exp_logits / exp_logits.sum(axis=0)\n",
        "\n",
        "        # Scrittura delle predizioni in un file\n",
        "        with open(\"predizioni.txt\", \"a\") as file:  # Modalità append\n",
        "            for node, pred in zip(nodes.cpu().numpy(), preds.cpu().numpy()):\n",
        "                line = f\"Nodo:{node}\\tPredizione:{pred}\\tClasse:{np.argmax(softmax(pred))}\"\n",
        "                file.write(line + os.linesep)  # Scrive il nodo e la predizione\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        loss = {}\n",
        "        for ds_name, batch_nodes in batch.items():\n",
        "            ds = self.combined_dataset.train_ds_dict[ds_name]\n",
        "            train_target_idx = batch_nodes\n",
        "            # Batch nodes are not visible to avoid trivial solution and overfitting\n",
        "            visible_nodes = list(\n",
        "                set(ds.train_indices.tolist()) - set(batch_nodes.tolist())\n",
        "            )\n",
        "            ref_nodes = torch.tensor(visible_nodes, dtype=torch.long).to(self.device)\n",
        "            ds_too_small = len(visible_nodes) < len(batch_nodes)\n",
        "            if ds_too_small:\n",
        "                # Visible nodes are too few, add first half of the batch to visible nodes\n",
        "                ref_nodes = torch.cat((ref_nodes, batch_nodes[: len(batch_nodes) // 2]))\n",
        "\n",
        "            input = ds.compute_channel_logits(\n",
        "                ds.features, ref_nodes, sample=True, device=self.device\n",
        "            )\n",
        "\n",
        "            preds = self.predict(ds, train_target_idx, input, is_training=True)\n",
        "            loss[f\"loss/{ds_name}_loss\"] = self.criterion(\n",
        "                preds, ds.label[train_target_idx]\n",
        "            )\n",
        "\n",
        "        detached_loss = {k: v.detach().cpu() for k, v in loss.items()}\n",
        "        avg_loss = mean(list(detached_loss.values()))\n",
        "        self.loss_dict.update({\"loss/avg_loss\": avg_loss, **detached_loss})\n",
        "        return sum(loss.values())\n",
        "\n",
        "    def evaluation_step(self, split, batch, batch_idx):\n",
        "        self.move_metrics_to_device()\n",
        "        for ds_name, eval_idx in batch.items():\n",
        "            if eval_idx is None:  # Skip if dataset is already evaluated (empty batch)\n",
        "                continue\n",
        "            ds = self.combined_dataset.eval_ds_dict[ds_name]\n",
        "            ds.to(self.device)\n",
        "            eval_idx.to(self.device)\n",
        "            # Use unmasked feature for evaluation\n",
        "            processed_feat = ds.unmasked_pred\n",
        "            preds = self.predict(\n",
        "                ds, eval_idx, processed_feat, is_training=False\n",
        "            ).argmax(-1)\n",
        "            self.metrics[split][ds_name].update(preds, ds.label[eval_idx])\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"val\", batch, batch_idx)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self.evaluation_step(\"test\", batch, batch_idx)\n",
        "\n",
        "    def compute_and_log_metrics(self, split):\n",
        "        # Compute metrics from collected outputs\n",
        "        res = {}\n",
        "        for ds_name, metric in self.metrics[split].items():\n",
        "            metric_name = self.get_metric_name(ds_name, split)\n",
        "            accuracy = metric.compute().cpu().numpy()\n",
        "            res[metric_name] = np.round(accuracy * 100, 2)\n",
        "            metric.reset()  # Reset metrics for the next epoch\n",
        "\n",
        "        combined_res = {f\"{split}_acc\": np.round(sum(res.values()) / len(res), 2)}\n",
        "        combined_res[f\"trans_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"trans\")]\n",
        "        )\n",
        "        combined_res[f\"ind_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k.startswith(\"ind\")]\n",
        "        )\n",
        "\n",
        "        combined_res[f\"heldout_{split}_acc\"] = mean(\n",
        "            [v for k, v in res.items() if k in self.heldout_metrics]\n",
        "        )\n",
        "        self.log_dict(res, prog_bar=False, logger=True, add_dataloader_idx=False)\n",
        "        self.log_dict(\n",
        "            combined_res, prog_bar=True, logger=True, add_dataloader_idx=False\n",
        "        )\n",
        "        self.res_dict.update({**res, **combined_res})\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log_dict(self.loss_dict, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if len(self.attn_dict):\n",
        "            self.log_dict(self.attn_dict, on_epoch=True, prog_bar=False, logger=True)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"val\")\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.compute_and_log_metrics(\"test\")\n",
        "\n",
        "\n",
        "@timer()\n",
        "@hydra.main(config_path=f\"{root}/configs\", config_name=\"main\", version_base=None)\n",
        "def main(cfg: DictConfig):\n",
        "    cfg, logger = init_experiment(cfg)\n",
        "    # Define the default step metric for all metrics\n",
        "    wandb.define_metric(\"*\", step_metric=\"epoch\")\n",
        "    if torch.cuda.is_available() and cfg.preprocess_device == \"gpu\":\n",
        "        preprocess_device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        preprocess_device = torch.device(\"cpu\")\n",
        "\n",
        "    def construct_ds_dict(datasets):\n",
        "        datasets = [datasets] if isinstance(datasets, str) else datasets\n",
        "        ds_dict = {\n",
        "            dataset: GraphDataset(\n",
        "                cfg,\n",
        "                dataset,\n",
        "                cfg.dirs.data_cache,\n",
        "                cfg.train_batch_size,\n",
        "                cfg.val_test_batch_size,\n",
        "                cfg.n_hops,\n",
        "                preprocess_device,\n",
        "            )\n",
        "            for dataset in datasets\n",
        "        }\n",
        "        return ds_dict\n",
        "\n",
        "    train_ds_dict = construct_ds_dict(cfg.train_datasets)\n",
        "    eval_ds_dict = construct_ds_dict(cfg.eval_datasets)\n",
        "\n",
        "    combined_dataset = CombinedDataset(train_ds_dict, eval_ds_dict, cfg)\n",
        "\n",
        "    model = InductiveNodeClassification(cfg, combined_dataset, cfg.get(\"prev_ckpt\"))\n",
        "    # Set up the checkpoint callback to save only at the end of training\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=cfg.dirs.output,  # specify where to save\n",
        "        filename=\"final_checkpoint.pt\",  # set a filename\n",
        "        save_top_k=0,  # do not save based on metric, just save last\n",
        "        save_last=True,  # ensures only the last checkpoint is kept\n",
        "        save_on_train_epoch_end=True,  # save at the end of training epoch\n",
        "    )\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=cfg.total_steps,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        limit_train_batches=cfg.limit_train_batches,\n",
        "        check_val_every_n_epoch=cfg.eval_freq,\n",
        "        logger=logger,\n",
        "        accelerator=\"gpu\" if torch.cuda.is_available() and cfg.gpus > 0 else \"cpu\",\n",
        "        default_root_dir=cfg.dirs.lightning_root,\n",
        "    )\n",
        "    dataloaders = {\n",
        "        \"train\": combined_dataset.train_dataloader(),\n",
        "        \"val\": combined_dataset.val_dataloader(),\n",
        "        \"test\": combined_dataset.test_dataloader(),\n",
        "    }\n",
        "    if cfg.total_steps > 0:\n",
        "        trainer.fit(\n",
        "            model,\n",
        "            train_dataloaders=dataloaders[\"train\"],\n",
        "            val_dataloaders=dataloaders[\"val\"],\n",
        "        )\n",
        "    trainer.validate(model, dataloaders=dataloaders[\"val\"])\n",
        "    trainer.test(model, dataloaders=dataloaders[\"test\"])\n",
        "    final_results = model.res_dict\n",
        "    logger.critical(pretty_repr(final_results))\n",
        "    logger.wandb_summary_update(final_results, finish_wandb=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AVs-Ye68aWpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_name = 'GraphAny/graphany/run.py'\n",
        "with open(path_name, 'w') as file:\n",
        "    file.write(new_code)"
      ],
      "metadata": {
        "id": "mXAnRZB-becd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"GraphAny/graphany/run.py\"\n",
        "dataset = \"F1Debug\" # we want to use the F1 dataset\n",
        "# dataset = \"Debug\"\n",
        "steps = 0 # we want to perform zero-shot, thus we impose zero training epochs\n",
        "checkpoint_path = \"GraphAny/checkpoints/graph_any_wisconsin.pt\""
      ],
      "metadata": {
        "id": "PsPPVWujbv5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "!source activate graphany && python {script_path} prev_ckpt={checkpoint_path} dataset={dataset} total_steps={steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulyl08LlbwbJ",
        "outputId": "2ab8f322-2bc6-44d6-a1c1-744af6e1e046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[09:20:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Logger initialized.                                                                                                                 \u001b[2mlogging.py:53\u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mLocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworking_dir\u001b[0m=\u001b[35m/content/temp/working_dir/\u001b[0m\u001b[95mFeb25-9\u001b[0m:\u001b[1;36m20\u001b[0m-13783a79/                                                         \u001b[2mexperiment.py:56\u001b[0m\n",
            "Done loading data from cached files.\n",
            "Wisconsin 251 515 1703 5 120\n",
            "Using existing file f1_9_classes3.pkl\n",
            "F1 12553 11362 300 9 9720\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Loaded checkpoint at GraphAny/checkpoints/graph_any_wisconsin.pt                                                                        \u001b[2mrun.py:32\u001b[0m\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                                                                            \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                                                                                          \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                                                                               \u001b[2mrank_zero.py:63\u001b[0m\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m `\u001b[1;35mTrainer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlimit_train_batches\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m` was configured so \u001b[1;36m1\u001b[0m batch per epoch will be used.                                                \u001b[2mrank_zero.py:63\u001b[0m\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.55it/s]/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/miniconda/envs/graphany/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "\u001b[2;36m[09:20:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m91.33000183105469\u001b[0m,                                                                                            \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m91.33000183105469\u001b[0m,                                                                                                   \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m91.33000183105469\u001b[0m,                                                                                               \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                         \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.26it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m     heldout_val_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    91.33000183105469    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       ind_val_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    91.33000183105469    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      trans_val_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    91.33000183105469    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00,  2.67it/s]\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m                                                                                                                                   \u001b[2mlogging.py:79\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.37999725341797\u001b[0m,                                                                                           \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.37999725341797\u001b[0m,                                                                                                  \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                          \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.37999725341797\u001b[0m,                                                                                              \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan,                                                                                                        \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'epoch'\u001b[0m: \u001b[1;36m0\u001b[0m                                                                                                                      \u001b[2m             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                   \u001b[2m             \u001b[0m\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00,  2.55it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m    heldout_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     ind/f1_test_acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    90.37999725341797    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      ind_test_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    90.37999725341797    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    90.37999725341797    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     trans_test_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m \u001b[1m{\u001b[0m                                                                                                                                      \u001b[2mrun.py:304\u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_val_acc'\u001b[0m: \u001b[1;36m91.33\u001b[0m,                                                                                                           \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m91.33\u001b[0m,                                                                                                                  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_val_acc'\u001b[0m: nan,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_val_acc'\u001b[0m: \u001b[1;36m91.33\u001b[0m,                                                                                                              \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_val_acc'\u001b[0m: nan,                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind/f1_test_acc'\u001b[0m: \u001b[1;36m90.38\u001b[0m,                                                                                                          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m90.38\u001b[0m,                                                                                                                 \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'trans_test_acc'\u001b[0m: nan,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'ind_test_acc'\u001b[0m: \u001b[1;36m90.38\u001b[0m,                                                                                                             \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m             \u001b[32m'heldout_test_acc'\u001b[0m: nan                                                                                                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         \u001b[1m}\u001b[0m                                                                                                                                      \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished main at \u001b[1;36m02\u001b[0m-\u001b[1;36m25\u001b[0m \u001b[1;92m09:20:24\u001b[0m, running time = \u001b[1;36m1.59\u001b[0m seconds.                                                                      \u001b[2mlogging.py:122\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "def build_comparison_file(download_path, output_file):\n",
        "    with open(download_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    node_features = torch.tensor(data['node_features'])\n",
        "    labels = torch.tensor(data['labels'])\n",
        "    edges = torch.tensor(data['edges'])\n",
        "\n",
        "    train_mask, val_mask, test_mask = torch.tensor(data['train_mask']), torch.tensor(data['val_mask']), torch.tensor(\n",
        "        data['test_mask'])\n",
        "\n",
        "    # Scrittura dei nodi e delle rispettive classi nel test set\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"Nodo,Classe\\n\")  # Header del file\n",
        "        for node in range(len(test_mask)):\n",
        "            if test_mask[node]:  # Controllo se il nodo è nel test set\n",
        "                f.write(f\"{node},{labels[node].item()}\\n\")  # Scrivo nodo e classe\n",
        "\n",
        "    return labels, node_features, train_mask, val_mask, test_mask"
      ],
      "metadata": {
        "id": "qr4Mo4bMatiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "output_file = \"true_labels.txt\"\n",
        "\n",
        "# URL del file da scaricare\n",
        "download_url = 'https://raw.githubusercontent.com/RiccardoRomeo01/BDATM_project_public_data/main/GraphAny_datasets/f1_9_classes3.pkl'\n",
        "local_file_path = 'f1_9_classes3.pkl'\n",
        "\n",
        "\n",
        "response = requests.get(download_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(local_file_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(\"File scaricato e salvato come:\", local_file_path)\n",
        "else:\n",
        "    print(\"Errore nel download del file:\", response.status_code)\n",
        "\n",
        "labels, node_features, train_mask, val_mask, test_mask = build_comparison_file(local_file_path, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsIbiBPybzba",
        "outputId": "d3d8c9f7-4bf6-46a2-ea01-198c279c7e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File scaricato e salvato come: f1_9_classes3.pkl\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}